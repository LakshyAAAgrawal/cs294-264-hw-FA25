{
  "psf__requests-1921": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "psf__requests-1921",
    "model_patch": "diff --git a/requests/models.py b/requests/models.py\nindex cd232e6..7708b85 100644\n--- a/requests/models.py\n+++ b/requests/models.py\n@@ -376,7 +376,6 @@ class PreparedRequest(RequestEncodingMixin, RequestHooksMixin):\n                 query = query.encode('utf-8')\n             if isinstance(fragment, str):\n                 fragment = fragment.encode('utf-8')\n-\n         enc_params = self._encode_params(params)\n         if enc_params:\n             if query:\n@@ -391,10 +390,9 @@ class PreparedRequest(RequestEncodingMixin, RequestHooksMixin):\n         \"\"\"Prepares the given HTTP headers.\"\"\"\n \n         if headers:\n-            self.headers = CaseInsensitiveDict((to_native_string(name), value) for name, value in headers.items())\n+            self.headers = CaseInsensitiveDict((to_native_string(name), value) for name, value in headers.items() if value is not None)\n         else:\n             self.headers = CaseInsensitiveDict()\n-\n     def prepare_body(self, data, files):\n         \"\"\"Prepares the given HTTP body data.\"\"\""
  },
  "pytest-dev__pytest-7490": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "pytest-dev__pytest-7490",
    "model_patch": "diff --git a/src/_pytest/skipping.py b/src/_pytest/skipping.py\nindex 335e10996..7fd204430 100644\n--- a/src/_pytest/skipping.py\n+++ b/src/_pytest/skipping.py\n@@ -253,10 +253,12 @@ def pytest_runtest_call(item: Item) -> Generator[None, None, None]:\n     if not item.config.option.runxfail:\n         if xfailed and not xfailed.run:\n             xfail(\"[NOTRUN] \" + xfailed.reason)\n-\n-    yield\n-\n-\n+    outcome = yield\n+    rep = outcome.get_result()\n+    # Re-evaluate xfail marks to account for marks added dynamically during setup or call.\n+    # Cache the result for later use by other hooks/reporting.\n+    xfailed = evaluate_xfail_marks(item)\n+    item._store[xfailed_key] = xfailed\n @hookimpl(hookwrapper=True)\n def pytest_runtest_makereport(item: Item, call: CallInfo[None]):\n     outcome = yield"
  },
  "astropy__astropy-7166": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "astropy__astropy-7166",
    "model_patch": "diff --git a/astropy/utils/misc.py b/astropy/utils/misc.py\nindex de3fb01d1..3ca453ef4 100644\n--- a/astropy/utils/misc.py\n+++ b/astropy/utils/misc.py\n@@ -528,6 +528,7 @@ class InheritDocstrings(type):\n                 not key.startswith('_'))\n \n         for key, val in dct.items():\n+            # Handle regular functions/methods\n             if (inspect.isfunction(val) and\n                 is_public_member(key) and\n                 val.__doc__ is None):\n@@ -537,6 +538,21 @@ class InheritDocstrings(type):\n                         val.__doc__ = super_method.__doc__\n                         break\n \n+            # Handle properties: inspect.isfunction returns False for property objects,\n+            # so detect property instances and copy the docstring from the base.\n+            if (isinstance(val, property) and\n+                is_public_member(key) and\n+                val.__doc__ is None):\n+                for base in cls.__mro__[1:]:\n+                    super_method = getattr(base, key, None)\n+                    if super_method is not None:\n+                        # super_method may itself be a property or a function; use its __doc__\n+                        super_doc = getattr(super_method, '__doc__', None)\n+                        if super_doc:\n+                            # Recreate the property with the inherited docstring.\n+                            setattr(cls, key, property(val.fget, val.fset, val.fdel, super_doc))\n+                            break\n+\n         super().__init__(name, bases, dct)"
  },
  "psf__requests-2931": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "psf__requests-2931",
    "model_patch": "diff --git a/requests/models.py b/requests/models.py\nindex 9c624d3..57fc9ae 100644\n--- a/requests/models.py\n+++ b/requests/models.py\n@@ -53,24 +53,6 @@ class RequestEncodingMixin(object):\n     @property\n     def path_url(self):\n         \"\"\"Build the path URL to use.\"\"\"\n-\n-        url = []\n-\n-        p = urlsplit(self.url)\n-\n-        path = p.path\n-        if not path:\n-            path = '/'\n-\n-        url.append(path)\n-\n-        query = p.query\n-        if query:\n-            url.append('?')\n-            url.append(query)\n-\n-        return ''.join(url)\n-\n     @staticmethod\n     def _encode_params(data):\n         \"\"\"Encode parameters in a piece of data.\n@@ -81,7 +63,9 @@ class RequestEncodingMixin(object):\n         \"\"\"\n \n         if isinstance(data, (str, bytes)):\n-            return to_native_string(data)\n+            # If it's a native str, return it; if it's bytes, leave unchanged\n+            # so binary payloads (e.g., UTF-8 encoded bytes) are preserved.\n+            return data if isinstance(data, bytes) else to_native_string(data)\n         elif hasattr(data, 'read'):\n             return data\n         elif hasattr(data, '__iter__'):\n@@ -98,6 +82,8 @@ class RequestEncodingMixin(object):\n         else:\n             return data\n \n+            return data\n+\n     @staticmethod\n     def _encode_files(files, data):\n         \"\"\"Build the body for a multipart/form-data request."
  },
  "sphinx-doc__sphinx-9230": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-9230",
    "model_patch": "diff --git a/sphinx/util/docfields.py b/sphinx/util/docfields.py\nindex 3a3367ebe..6998e1998 100644\n--- a/sphinx/util/docfields.py\n+++ b/sphinx/util/docfields.py\n@@ -238,7 +238,8 @@ class DocFieldTransformer:\n             field_body = cast(nodes.field_body, field[1])\n             try:\n                 # split into field type and argument\n-                fieldtype_name, fieldarg = field_name.astext().split(None, 1)\n+                fieldtype_name, fieldarg = field_name.astext().rsplit(None, 1)\n+\n             except ValueError:\n                 # maybe an argument-less field type?\n                 fieldtype_name, fieldarg = field_name.astext(), ''"
  },
  "sympy__sympy-17655": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "sympy__sympy-17655",
    "model_patch": "diff --git a/sympy/geometry/point.py b/sympy/geometry/point.py\nindex 7c978c47be..f076f6cc22 100644\n--- a/sympy/geometry/point.py\n+++ b/sympy/geometry/point.py\n@@ -167,11 +167,31 @@ def __new__(cls, *args, **kwargs):\n                  for f in coords.atoms(Float)]))\n \n         # return 2D or 3D instances\n-        if len(coords) == 2:\n-            kwargs['_nocheck'] = True\n-            return Point2D(*coords, **kwargs)\n-        elif len(coords) == 3:\n-            kwargs['_nocheck'] = True\n+        try:\n+            s, o = Point._normalize_dimension(self, Point(other, evaluate=False))\n+        except TypeError:\n+            # If other is a Mul like 2*Point, try to extract the Point and\n+            # scale it using Point.__mul__ so that scalar*Point behaves\n+            # the same as Point*scalar.\n+            from sympy.core.mul import Mul\n+            if isinstance(other, Mul):\n+                point_part = None\n+                factor = None\n+                for a in other.args:\n+                    if isinstance(a, Point):\n+                        point_part = a\n+                    else:\n+                        factor = a if factor is None else factor * a\n+                if point_part is not None:\n+                    if factor is None:\n+                        factor = 1\n+                    # Use the Point.__mul__ implementation to get a Point\n+                    other = point_part.__mul__(factor)\n+                    s, o = Point._normalize_dimension(self, Point(other, evaluate=False))\n+                else:\n+                    raise GeometryError(\"Don't know how to add {} and a Point object\".format(other))\n+            else:\n+                raise GeometryError(\"Don't know how to add {} and a Point object\".format(other))\n             return Point3D(*coords, **kwargs)\n \n         # the general Point"
  },
  "sphinx-doc__sphinx-9658": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-9658",
    "model_patch": "diff --git a/sphinx/ext/autodoc/mock.py b/sphinx/ext/autodoc/mock.py\nindex b562f47fd..ea1417d2b 100644\n--- a/sphinx/ext/autodoc/mock.py\n+++ b/sphinx/ext/autodoc/mock.py\n@@ -28,8 +28,8 @@ class _MockObject:\n     __display_name__ = '_MockObject'\n     __sphinx_mock__ = True\n     __sphinx_decorator_args__: Tuple[Any, ...] = ()\n-\n-    def __new__(cls, *args: Any, **kwargs: Any) -> Any:\n+    def __init__(self, *args: Any, **kwargs: Any) -> None:\n+        pass\n         if len(args) == 3 and isinstance(args[1], tuple):\n             superclass = args[1][-1].__class__\n             if superclass is cls:"
  },
  "sphinx-doc__sphinx-7590": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-7590",
    "model_patch": "diff --git a/sphinx/domains/cpp.py b/sphinx/domains/cpp.py\nindex fe52d881d..93b826934 100644\n--- a/sphinx/domains/cpp.py\n+++ b/sphinx/domains/cpp.py\n@@ -4650,7 +4650,6 @@ class DefinitionParser(BaseParser):\n         #  | string-literal\n         #  | boolean-literal -> \"false\" | \"true\"\n         #  | pointer-literal -> \"nullptr\"\n-        #  | user-defined-literal\n         self.skip_ws()\n         if self.skip_word('nullptr'):\n             return ASTPointerLiteral()\n@@ -4658,22 +4657,42 @@ class DefinitionParser(BaseParser):\n             return ASTBooleanLiteral(True)\n         if self.skip_word('false'):\n             return ASTBooleanLiteral(False)\n+            return ASTBooleanLiteral(False)\n+\n         for regex in [float_literal_re, binary_literal_re, hex_literal_re,\n                       integer_literal_re, octal_literal_re]:\n             pos = self.pos\n             if self.match(regex):\n+                # consume standard C/C++ suffixes (u, U, l, L, f, F)\n                 while self.current_char in 'uUlLfF':\n                     self.pos += 1\n+                # user-defined literal suffix: identifier characters starting with letter or underscore\n+                if self.current_char is not None and re.match(r'[A-Za-z_]', self.current_char):\n+                    while self.current_char is not None and (self.current_char.isalnum() or self.current_char == '_'):\n+                        self.pos += 1\n+                    return ASTUserDefinedLiteral(self.definition[pos:self.pos])\n                 return ASTNumberLiteral(self.definition[pos:self.pos])\n-\n+        \n+        pos = self.pos\n         string = self._parse_string()\n         if string is not None:\n+            # if there's an ud-suffix after the string literal, consume it\n+            if self.current_char is not None and re.match(r'[A-Za-z_]', self.current_char):\n+                while self.current_char is not None and (self.current_char.isalnum() or self.current_char == '_'):\n+                    self.pos += 1\n+                return ASTUserDefinedLiteral(self.definition[pos:self.pos])\n             return ASTStringLiteral(string)\n-\n+        \n         # character-literal\n+        pos = self.pos\n         if self.match(char_literal_re):\n             prefix = self.last_match.group(1)  # may be None when no prefix\n             data = self.last_match.group(2)\n+            # if there's an ud-suffix after the character literal, consume it\n+            if self.current_char is not None and re.match(r'[A-Za-z_]', self.current_char):\n+                while self.current_char is not None and (self.current_char.isalnum() or self.current_char == '_'):\n+                    self.pos += 1\n+                return ASTUserDefinedLiteral(self.definition[pos:self.pos])\n             try:\n                 return ASTCharLiteral(prefix, data)\n             except UnicodeDecodeError as e:\n@@ -4681,8 +4700,8 @@ class DefinitionParser(BaseParser):\n             except UnsupportedMultiCharacterCharLiteral:\n                 self.fail(\"Can not handle character literal\"\n                           \" resulting in multiple decoded characters.\")\n-\n-        # TODO: user-defined lit\n+        \n+        return None\n         return None\n \n     def _parse_fold_or_paren_expression(self) -> ASTExpression:"
  },
  "sympy__sympy-24213": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "sympy__sympy-24213",
    "model_patch": "diff --git a/sympy/physics/units/unitsystem.py b/sympy/physics/units/unitsystem.py\nindex a436880c4b..5705c821c2 100644\n--- a/sympy/physics/units/unitsystem.py\n+++ b/sympy/physics/units/unitsystem.py\n@@ -175,7 +175,7 @@ def _collect_factor_and_dimension(self, expr):\n             for addend in expr.args[1:]:\n                 addend_factor, addend_dim = \\\n                     self._collect_factor_and_dimension(addend)\n-                if dim != addend_dim:\n+                if not self.get_dimension_system().equivalent_dims(dim, addend_dim):\n                     raise ValueError(\n                         'Dimension of \"{}\" is {}, '\n                         'but it should be {}'.format("
  },
  "django__django-11179": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-11179",
    "model_patch": "diff --git a/django/db/models/deletion.py b/django/db/models/deletion.py\nindex 92fe4affb9..776d6f72f7 100644\n--- a/django/db/models/deletion.py\n+++ b/django/db/models/deletion.py\n@@ -262,22 +262,25 @@ class Collector:\n     def delete(self):\n         # sort instance collections\n         for model, instances in self.data.items():\n-            self.data[model] = sorted(instances, key=attrgetter(\"pk\"))\n-\n-        # if possible, bring the models in an order suitable for databases that\n-        # don't support transactions or cannot defer constraint checks until the\n-        # end of a transaction.\n-        self.sort()\n-        # number of objects deleted for each model label\n-        deleted_counter = Counter()\n-\n-        # Optimize for the case with a single obj and no dependencies\n-        if len(self.data) == 1 and len(instances) == 1:\n-            instance = list(instances)[0]\n-            if self.can_fast_delete(instance):\n-                with transaction.mark_for_rollback_on_error():\n-                    count = sql.DeleteQuery(model).delete_batch([instance.pk], self.using)\n-                return count, {model._meta.label: count}\n+          # if possible, bring the models in an order suitable for databases that\n+          # don't support transactions or cannot defer constraint checks until the\n+          # end of a transaction.\n+          # Optimize for the case with a single obj and no dependencies\n+          if len(self.data) == 1 and len(instances) == 1:\n+              instance = list(instances)[0]\n+              if self.can_fast_delete(instance):\n+                  # send pre_delete signal for non-auto-created models\n+                  if not model._meta.auto_created:\n+                      signals.pre_delete.send(sender=model, instance=instance, using=self.using)\n+                  with transaction.mark_for_rollback_on_error():\n+                      count = sql.DeleteQuery(model).delete_batch([instance.pk], self.using)\n+                  # send post_delete signal for non-auto-created models\n+                  if not model._meta.auto_created:\n+                      signals.post_delete.send(sender=model, instance=instance, using=self.using)\n+                  # clear primary key on the in-memory instance\n+                  setattr(instance, model._meta.pk.attname, None)\n+                  return count, {model._meta.label: count}\n+\n \n         with transaction.atomic(using=self.using, savepoint=False):\n             # send pre_delete signals"
  },
  "django__django-13810": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-13810",
    "model_patch": "diff --git a/django/core/handlers/base.py b/django/core/handlers/base.py\nindex 8e8c3da06a..100227fb5a 100644\n--- a/django/core/handlers/base.py\n+++ b/django/core/handlers/base.py\n@@ -50,12 +50,12 @@ class BaseHandler:\n             else:\n                 middleware_is_async = middleware_can_async\n             try:\n-                # Adapt handler, if needed.\n-                handler = self.adapt_method_mode(\n-                    middleware_is_async, handler, handler_is_async,\n-                    debug=settings.DEBUG, name='middleware %s' % middleware_path,\n-                )\n-                mw_instance = middleware(handler)\n+                  # Adapt handler, if needed.\n+                  adapted_handler = self.adapt_method_mode(\n+                      middleware_is_async, handler, handler_is_async,\n+                      debug=settings.DEBUG, name='middleware %s' % middleware_path,\n+                  )\n+                  mw_instance = middleware(adapted_handler)\n             except MiddlewareNotUsed as exc:\n                 if settings.DEBUG:\n                     if str(exc):"
  },
  "django__django-7530": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-7530",
    "model_patch": "diff --git a/django/core/management/commands/makemigrations.py b/django/core/management/commands/makemigrations.py\nindex 0b39536f5b..56f00f8707 100644\n--- a/django/core/management/commands/makemigrations.py\n+++ b/django/core/management/commands/makemigrations.py\n@@ -77,7 +77,6 @@ class Command(BaseCommand):\n                 \"The --exit option is deprecated in favor of the --check option.\",\n                 RemovedInDjango20Warning\n             )\n-\n         # Make sure the app they asked for exists\n         app_labels = set(app_labels)\n         bad_app_labels = set()\n@@ -105,7 +104,7 @@ class Command(BaseCommand):\n                     # At least one model must be migrated to the database.\n                     router.allow_migrate(connection.alias, app_label, model_name=model._meta.object_name)\n                     for app_label in consistency_check_labels\n-                    for model in apps.get_models(app_label)\n+                    for model in apps.get_app_config(app_label).get_models()\n             )):\n                 loader.check_consistent_history(connection)"
  },
  "django__django-12406": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-12406",
    "model_patch": "diff --git a/django/forms/models.py b/django/forms/models.py\nindex dafc11f995..c8b66bc244 100644\n--- a/django/forms/models.py\n+++ b/django/forms/models.py\n@@ -1180,25 +1180,28 @@ class ModelChoiceField(ChoiceField):\n                             ' the available choices.'),\n     }\n     iterator = ModelChoiceIterator\n-\n     def __init__(self, queryset, *, empty_label=\"---------\",\n                  required=True, widget=None, label=None, initial=None,\n                  help_text='', to_field_name=None, limit_choices_to=None,\n-                 **kwargs):\n-        if required and (initial is not None):\n-            self.empty_label = None\n-        else:\n-            self.empty_label = empty_label\n-\n+                 blank=False, **kwargs):\n         # Call Field instead of ChoiceField __init__() because we don't need\n         # ChoiceField.__init__().\n         Field.__init__(\n             self, required=required, widget=widget, label=label,\n             initial=initial, help_text=help_text, **kwargs\n         )\n+        if (\n+            (required and initial is not None) or\n+            (isinstance(self.widget, RadioSelect) and not blank)\n+        ):\n+            self.empty_label = None\n+        else:\n+            self.empty_label = empty_label\n+\n         self.queryset = queryset\n         self.limit_choices_to = limit_choices_to   # limit the queryset later.\n         self.to_field_name = to_field_name\n+        self.to_field_name = to_field_name\n \n     def get_limit_choices_to(self):\n         \"\"\""
  },
  "django__django-14053": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-14053",
    "model_patch": "diff --git a/django/contrib/staticfiles/storage.py b/django/contrib/staticfiles/storage.py\nindex 494890cc23..83a93c87d2 100644\n--- a/django/contrib/staticfiles/storage.py\n+++ b/django/contrib/staticfiles/storage.py\n@@ -188,9 +188,6 @@ class HashedFilesMixin:\n                 self._stored_name, unquote(target_name),\n                 force=True, hashed_files=hashed_files,\n             )\n-\n-            transformed_url = '/'.join(url_path.split('/')[:-1] + hashed_url.split('/')[-1:])\n-\n             # Restore the fragment that was stripped off earlier.\n             if fragment:\n                 transformed_url += ('?#' if '?#' in url else '#') + fragment\n@@ -226,13 +223,59 @@ class HashedFilesMixin:\n             path for path in paths\n             if matches_patterns(path, self._patterns)\n         ]\n+\n+        # Keep a copy of the original paths so we can yield results\n+        # for each original name exactly once at the end.\n+        original_paths = dict(paths)\n+\n+        # Collect results per original name to avoid yielding the same\n+        # original filename multiple times across multiple passes.\n+        results = {}\n+\n         # Do a single pass first. Post-process all files once, then repeat for\n         # adjustable files.\n         for name, hashed_name, processed, _ in self._post_process(paths, adjustable_paths, hashed_files):\n-            yield name, hashed_name, processed\n+            results[name] = (hashed_name, processed)\n \n         paths = {path: paths[path] for path in adjustable_paths}\n \n+        for i in range(self.max_post_process_passes):\n+            substitutions = False\n+            for name, hashed_name, processed, subst in self._post_process(paths, adjustable_paths, hashed_files):\n+                # update the latest result for this name\n+                results[name] = (hashed_name, processed)\n+                substitutions = substitutions or subst\n+\n+            if not substitutions:\n+                break\n+\n+        if substitutions:\n+            # Preserve original behavior for max passes exceeded.\n+            yield 'All', None, RuntimeError('Max post-process passes exceeded.')\n+\n+        # Yield each original name exactly once, using the latest processed result.\n+        for name in original_paths:\n+            if name in results:\n+                hashed_name, processed = results[name]\n+                yield name, hashed_name, processed\n+\n+                substitutions = substitutions or subst\n+\n+            if not substitutions:\n+                break\n+\n+        if substitutions:\n+            # Preserve original behavior for max passes exceeded.\n+            yield 'All', None, RuntimeError('Max post-process passes exceeded.')\n+\n+        # Yield each original name exactly once, using the latest processed result.\n+        for name in original_paths:\n+            if name in results:\n+                hashed_name, processed = results[name]\n+                yield name, hashed_name, processed\n+\n+        # Store the processed paths\n+        self.hashed_files.update(hashed_files)\n         for i in range(self.max_post_process_passes):\n             substitutions = False\n             for name, hashed_name, processed, subst in self._post_process(paths, adjustable_paths, hashed_files):"
  },
  "django__django-13297": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-13297",
    "model_patch": "diff --git a/django/views/generic/base.py b/django/views/generic/base.py\nindex ea5baca08d..698d4811c0 100644\n--- a/django/views/generic/base.py\n+++ b/django/views/generic/base.py\n@@ -9,9 +9,7 @@ from django.http import (\n )\n from django.template.response import TemplateResponse\n from django.urls import reverse\n-from django.utils.decorators import classonlymethod\n-from django.utils.deprecation import RemovedInDjango40Warning\n-from django.utils.functional import SimpleLazyObject\n+from django.utils.functional import SimpleLazyObject, empty\n \n logger = logging.getLogger('django.request')\n \n@@ -27,9 +25,17 @@ class ContextMixin:\n         kwargs.setdefault('view', self)\n         if self.extra_context is not None:\n             kwargs.update(self.extra_context)\n+        # Evaluate any SimpleLazyObject values so callers receive concrete values\n+        # (avoids errors like \"Error binding parameter ... unsupported type\").\n+        for key, value in list(kwargs.items()):\n+            if isinstance(value, SimpleLazyObject):\n+                if getattr(value, '_wrapped', None) is empty:\n+                    value._setup()\n+                kwargs[key] = value._wrapped\n         return kwargs\n \n \n+\n class View:\n     \"\"\"\n     Intentionally simple parent class for all views. Only implements"
  },
  "scikit-learn__scikit-learn-26323": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "scikit-learn__scikit-learn-26323",
    "model_patch": "diff --git a/sklearn/compose/_column_transformer.py b/sklearn/compose/_column_transformer.py\nindex 4eddd12b1..753321a53 100644\n--- a/sklearn/compose/_column_transformer.py\n+++ b/sklearn/compose/_column_transformer.py\n@@ -261,7 +261,6 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n             return [(name, trans) for name, trans, _ in self.transformers]\n         except (TypeError, ValueError):\n             return self.transformers\n-\n     @_transformers.setter\n     def _transformers(self, value):\n         try:\n@@ -271,7 +270,6 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n             ]\n         except (TypeError, ValueError):\n             self.transformers = value\n-\n     def set_output(self, *, transform=None):\n         \"\"\"Set the output container when `\"transform\"` and `\"fit_transform\"` are called.\n \n@@ -303,6 +301,21 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n         for trans in transformers:\n             _safe_set_output(trans, transform=transform)\n \n+        # Also ensure the remainder estimator (if any and not a string specifier)\n+        # receives the same output configuration. This fixes the case where a\n+        # remainder estimator was ignored by set_output.\n+        if hasattr(self, \"_remainder\"):\n+            remainder = self.remainder\n+            if (\n+                remainder is not None\n+                and remainder not in {\"passthrough\", \"drop\"}\n+                and not isinstance(remainder, str)\n+            ):\n+                _safe_set_output(remainder, transform=transform)\n+        return self\n+\n+\n+\n         return self\n \n     def get_params(self, deep=True):"
  },
  "django__django-14011": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-14011",
    "model_patch": "diff --git a/django/core/servers/basehttp.py b/django/core/servers/basehttp.py\nindex 14dab517c9..f5b6c2504b 100644\n--- a/django/core/servers/basehttp.py\n+++ b/django/core/servers/basehttp.py\n@@ -59,7 +59,7 @@ def is_broken_pipe_error():\n     ))\n \n \n-class WSGIServer(simple_server.WSGIServer):\n+    daemon_threads = False\n     \"\"\"BaseHTTPServer that implements the Python WSGI protocol\"\"\"\n \n     request_queue_size = 10\ndiff --git a/tests/test_runner_apps/tagged/tests_syntax_error.py b/tests/test_runner_apps/tagged/tests_syntax_error.py\nindex 2714768a30..8845e34046 100644\n--- a/tests/test_runner_apps/tagged/tests_syntax_error.py\n+++ b/tests/test_runner_apps/tagged/tests_syntax_error.py\n@@ -2,10 +2,6 @@ from unittest import TestCase\n \n from django.test import tag\n \n-\n @tag('syntax_error')\n class SyntaxErrorTestCase(TestCase):\n     pass\n-\n-\n-1syntax_error  # NOQA"
  },
  "django__django-16631": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-16631",
    "model_patch": "diff --git a/docs/ref/settings.txt b/docs/ref/settings.txt\nindex 41387886c0..31a8378223 100644\n--- a/docs/ref/settings.txt\n+++ b/docs/ref/settings.txt\n@@ -2295,16 +2295,25 @@ passwords of users and key rotation will not affect them.\n \n ``SECRET_KEY_FALLBACKS``\n ------------------------\n-\n-Default: ``[]``\n-\n-A list of fallback secret keys for a particular Django installation. These are\n-used to allow rotation of the ``SECRET_KEY``.\n-\n In order to rotate your secret keys, set a new ``SECRET_KEY`` and move the\n previous value to the beginning of ``SECRET_KEY_FALLBACKS``. Then remove the\n old values from the end of the ``SECRET_KEY_FALLBACKS`` when you are ready to\n-expire the sessions, password reset tokens, and so on, that make use of them.\n+expire the signatures that make use of them (for example, signed cookies and\n+other objects produced by :mod:`django.core.signing`).\n+\n+.. note::\n+\n+    Not all code that uses the secret key will consult ``SECRET_KEY_FALLBACKS``.\n+    Some HMAC-based values, such as the per-user session authentication hash\n+    returned by :meth:`django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash`,\n+    call :func:`django.utils.crypto.salted_hmac` without supplying an alternate\n+    secret. Those use only ``settings.SECRET_KEY`` and will therefore be\n+    invalidated immediately when ``SECRET_KEY`` changes; rotating ``SECRET_KEY``\n+    will therefore log users out in those cases.\n+\n+    ``SECRET_KEY_FALLBACKS`` is still useful for allowing rotation without\n+    invalidating signed cookies and objects created using the signing utilities,\n+    but be aware that some authentication-related values may not be covered.\n \n .. note::\n \ndiff --git a/tests/test_runner_apps/tagged/tests_syntax_error.py b/tests/test_runner_apps/tagged/tests_syntax_error.py\nindex 2714768a30..1ae06f3cfb 100644\n--- a/tests/test_runner_apps/tagged/tests_syntax_error.py\n+++ b/tests/test_runner_apps/tagged/tests_syntax_error.py\n@@ -8,4 +8,4 @@ class SyntaxErrorTestCase(TestCase):\n     pass\n \n \n-1syntax_error  # NOQA\n+"
  }
}