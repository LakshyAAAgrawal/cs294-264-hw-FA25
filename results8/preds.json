{
  "psf__requests-1921": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "psf__requests-1921",
    "model_patch": "Setting session.headers['Accept-Encoding'] = None leaves the header key in the session dict; when requests builds the outgoing headers it converts values to strings, so None becomes \"None\" and you get the header \"Accept-Encoding: None\".\n\nTo remove the header entirely:\n- del session.headers['Accept-Encoding']\n- or session.headers.pop('Accept-Encoding', None)\n\nTo omit the session header for a single request:\n- session.get(url, headers={'Accept-Encoding': None})  # requests treats None in per-request headers as \"drop this header from session defaults\"\n\nNotes:\n- Setting the value to '' will send an empty header value, not remove it.\n- If you want to request \"no encoding\" semantically, use \"Accept-Encoding: identity\" (different from removing the header).\n\nNo changes detected to generate a patch."
  },
  "sympy__sympy-17655": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "sympy__sympy-17655",
    "model_patch": "diff --git a/sympy/geometry/point.py b/sympy/geometry/point.py\nindex 7c978c47be..0f09f61dd3 100644\n--- a/sympy/geometry/point.py\n+++ b/sympy/geometry/point.py\n@@ -145,34 +145,63 @@ def __new__(cls, *args, **kwargs):\n                 raise ValueError(message)\n             elif on_morph == 'warn':\n                 warnings.warn(message)\n-            else:\n-                raise ValueError(filldedent('''\n-                        on_morph value should be 'error',\n-                        'warn' or 'ignore'.'''))\n-        if any(coords[dim:]):\n-            raise ValueError('Nonzero coordinates cannot be removed.')\n-        if any(a.is_number and im(a) for a in coords):\n-            raise ValueError('Imaginary coordinates are not permitted.')\n-        if not all(isinstance(a, Expr) for a in coords):\n-            raise TypeError('Coordinates must be valid SymPy expressions.')\n-\n-        # pad with zeros appropriately\n-        coords = coords[:dim] + (S.Zero,)*(dim - len(coords))\n-\n-        # Turn any Floats into rationals and simplify\n-        # any expressions before we instantiate\n-        if evaluate:\n-            coords = coords.xreplace(dict(\n-                [(f, simplify(nsimplify(f, rational=True)))\n-                 for f in coords.atoms(Float)]))\n-\n-        # return 2D or 3D instances\n-        if len(coords) == 2:\n-            kwargs['_nocheck'] = True\n-            return Point2D(*coords, **kwargs)\n-        elif len(coords) == 3:\n-            kwargs['_nocheck'] = True\n-            return Point3D(*coords, **kwargs)\n+def __add__(self, other):\n+        \"\"\"Add other to self by incrementing self's coordinates by\n+        those of other.\n+\n+        Notes\n+        =====\n+\n+        >>> from sympy.geometry.point import Point\n+\n+        When sequences of coordinates are passed to Point methods, they\n+        are converted to a Point internally. This __add__ method does\n+        not do that so if floating point values are used, a floating\n+        point result (in terms of SymPy Floats) will be returned.\n+\n+        >>> Point(1, 2) + (.1, .2)\n+        Point2D(1.1, 2.2)\n+\n+        If this is not desired, the `translate` method can be used or\n+        another Point can be added:\n+\n+        >>> Point(1, 2).translate(.1, .2)\n+        Point2D(11/10, 11/5)\n+        >>> Point(1, 2) + Point(.1, .2)\n+        Point2D(11/10, 11/5)\n+\n+        See Also\n+        ========\n+        sympy.geometry.point.Point.translate\n+\n+        \"\"\"\n+        # Handle expressions like `2*Point(...)` where `other` is a Mul\n+        # containing a Point. In that case extract the Point and scalar\n+        # and perform the scaled addition.\n+        if getattr(other, 'is_Mul', False):\n+            point_args = [arg for arg in other.args if isinstance(arg, Point)]\n+            if len(point_args) == 1:\n+                p = point_args[0]\n+                factor = S.One\n+                for a in other.args:\n+                    if a is not p:\n+                        factor = factor * a\n+                try:\n+                    s, o = Point._normalize_dimension(self, p*factor)\n+                except TypeError:\n+                    # fall through to the original handling\n+                    pass\n+                else:\n+                    coords = [simplify(a + b) for a, b in zip(s, o)]\n+                    return Point(coords, evaluate=False)\n+\n+        try:\n+            s, o = Point._normalize_dimension(self, Point(other, evaluate=False))\n+        except TypeError:\n+            raise GeometryError(\"Don't know how to add {} and a Point object\".format(other))\n+\n+        coords = [simplify(a + b) for a, b in zip(s, o)]\n+        return Point(coords, evaluate=False)\n \n         # the general Point\n         return GeometryEntity.__new__(cls, *coords)"
  },
  "sphinx-doc__sphinx-9658": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-9658",
    "model_patch": "Recommended fixes (pick one):\n\n1) Best / permanent fix \u2014 upgrade Sphinx\n- Pin Sphinx to a version that includes the autodoc fixes (>= 4.3.0).\n  Example requirements line to add/update in requirements/docs.txt or your RTD config:\n    sphinx>=4.3.0\n\n2) Temporary workaround \u2014 add a minimal shim to docs/conf.py\n- If you cannot upgrade immediately or you must mock torch on the docs build, add this near the top of docs/conf.py (before extensions run and before importing your package) to ensure autodoc sees a class named torch.nn.Module:\n\n# conf.py \u2014 add near the top (before importing your package and before extensions that import it)\nimport sys\nimport types\n\n# Only inject dummy torch/torch.nn if torch is not importable in the build env\nif 'torch' not in sys.modules:\n    torch_mod = types.ModuleType('torch')\n    torch_nn = types.ModuleType('torch.nn')\n\n    # create a minimal Module class so autodoc can pick up \"torch.nn.Module\"\n    class Module:\n        \"\"\"Dummy torch.nn.Module used for docs builds when torch isn't installed.\"\"\"\n        pass\n\n    Module.__module__ = 'torch.nn'\n    Module.__name__ = 'Module'\n    torch_nn.Module = Module\n    torch_mod.nn = torch_nn\n\n    sys.modules['torch'] = torch_mod\n    sys.modules['torch.nn'] = torch_nn\n\nNotes:\n- The shim only provides a class object named torch.nn.Module for name-resolution during documentation; it does not implement any torch functionality.\n- Prefer upgrading to Sphinx >=4.3.0 which contains the upstream fix for mocked external bases (this removes the need for the shim).\n- If you want, I can produce a tiny patch that inserts the shim into your repo's docs/conf.py and/or update requirements/docs.txt to pin sphinx>=4.3.0.\n\nNo changes detected to generate a patch."
  },
  "django__django-16662": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-16662",
    "model_patch": "diff --git a/django/db/migrations/writer.py b/django/db/migrations/writer.py\nindex a59f0c8dcb..30f8767d31 100644\n--- a/django/db/migrations/writer.py\n+++ b/django/db/migrations/writer.py\n@@ -148,10 +148,12 @@ class MigrationWriter:\n         for dependency in self.migration.dependencies:\n             if dependency[0] == \"__setting__\":\n                 dependencies.append(\n-                    \"        migrations.swappable_dependency(settings.%s),\"\n-                    % dependency[1]\n-                )\n-                imports.add(\"from django.conf import settings\")\n+# Sort imports by placing 'import ...' lines before 'from ... import ...'\n+          # and then by the package/module name (the part after \"from\" or \"import\").\n+          sorted_imports = sorted(\n+              imports, key=lambda i: (i.startswith(\"from \"), i.split()[1])\n+          )\n+          items[\"imports\"] = \"\\n\".join(sorted_imports) + \"\\n\" if imports else \"\"\n             else:\n                 dependencies.append(\"        %s,\" % self.serialize(dependency)[0])\n         items[\"dependencies\"] = \"\\n\".join(dependencies) + \"\\n\" if dependencies else \"\""
  },
  "astropy__astropy-7166": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "astropy__astropy-7166",
    "model_patch": "diff --git a/astropy/utils/misc.py b/astropy/utils/misc.py\nindex de3fb01d1..6a0a3dbf8 100644\n--- a/astropy/utils/misc.py\n+++ b/astropy/utils/misc.py\n@@ -517,15 +517,23 @@ class InheritDocstrings(type):\n         ...     def wiggle(self):\n         ...         pass\n         >>> B.wiggle.__doc__\n-        u'Wiggle the thingamajig'\n-    \"\"\"\n-\n-    def __init__(cls, name, bases, dct):\n-        def is_public_member(key):\n-            return (\n-                (key.startswith('__') and key.endswith('__')\n-                 and len(key) > 4) or\n-                not key.startswith('_'))\n+if is_public_member(key):\n+                # Functions: inherit docstrings for overridden methods\n+                if inspect.isfunction(val) and val.__doc__ is None:\n+                    for base in cls.__mro__[1:]:\n+                        super_method = getattr(base, key, None)\n+                        if super_method is not None:\n+                            val.__doc__ = super_method.__doc__\n+                            break\n+                # Properties: inherit docstrings from base property's fget\n+                elif isinstance(val, property):\n+                    fget = val.fget\n+                    if fget is not None and fget.__doc__ is None:\n+                        for base in cls.__mro__[1:]:\n+                            super_prop = getattr(base, key, None)\n+                            if isinstance(super_prop, property) and getattr(super_prop, 'fget', None) is not None:\n+                                fget.__doc__ = super_prop.fget.__doc__\n+                                break\n \n         for key, val in dct.items():\n             if (inspect.isfunction(val) and"
  },
  "sympy__sympy-24213": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "sympy__sympy-24213",
    "model_patch": "diff --git a/sympy/physics/units/unitsystem.py b/sympy/physics/units/unitsystem.py\nindex a436880c4b..14af2b56c2 100644\n--- a/sympy/physics/units/unitsystem.py\n+++ b/sympy/physics/units/unitsystem.py\n@@ -136,18 +136,18 @@ def get_dimensional_expr(self, expr):\n         elif isinstance(expr, Add):\n             return self.get_dimensional_expr(expr.args[0])\n         elif isinstance(expr, Derivative):\n-            dim = self.get_dimensional_expr(expr.expr)\n-            for independent, count in expr.variable_count:\n-                dim /= self.get_dimensional_expr(independent)**count\n-            return dim\n-        elif isinstance(expr, Function):\n-            args = [self.get_dimensional_expr(arg) for arg in expr.args]\n-            if all(i == 1 for i in args):\n-                return S.One\n-            return expr.func(*args)\n-        elif isinstance(expr, Quantity):\n-            return self.get_quantity_dimension(expr).name\n-        return S.One\n+elif isinstance(expr, Add):\n+              factor, dim = self._collect_factor_and_dimension(expr.args[0])\n+              for addend in expr.args[1:]:\n+                  addend_factor, addend_dim = \\\n+                      self._collect_factor_and_dimension(addend)\n+                  if not self.get_dimension_system().equivalent_dims(dim, addend_dim):\n+                      raise ValueError(\n+                          'Dimension of \"{}\" is {}, '\n+                          'but it should be {}'.format(\n+                              addend, addend_dim, dim))\n+                  factor += addend_factor\n+              return factor, dim\n \n     def _collect_factor_and_dimension(self, expr):\n         \"\"\""
  },
  "django__django-14053": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-14053",
    "model_patch": "diff --git a/django/contrib/staticfiles/storage.py b/django/contrib/staticfiles/storage.py\nindex 494890cc23..de0d983860 100644\n--- a/django/contrib/staticfiles/storage.py\n+++ b/django/contrib/staticfiles/storage.py\n@@ -219,21 +219,35 @@ class HashedFilesMixin:\n             return\n \n         # where to store the new paths\n-        hashed_files = {}\n-\n-        # build a list of adjustable files\n-        adjustable_paths = [\n-            path for path in paths\n-            if matches_patterns(path, self._patterns)\n-        ]\n-        # Do a single pass first. Post-process all files once, then repeat for\n+# Do a single pass first. Post-process all files once, then repeat for\n         # adjustable files.\n+        yielded = set()\n+        # First pass: post-process all files once.\n         for name, hashed_name, processed, _ in self._post_process(paths, adjustable_paths, hashed_files):\n+            if name in yielded:\n+                continue\n+            yielded.add(name)\n             yield name, hashed_name, processed\n \n         paths = {path: paths[path] for path in adjustable_paths}\n \n+        # Subsequent passes: only yield each original file once (avoid duplicate\n+        # yields across passes), but continue processing until no substitutions.\n         for i in range(self.max_post_process_passes):\n+            substitutions = False\n+            for name, hashed_name, processed, subst in self._post_process(paths, adjustable_paths, hashed_files):\n+                # Always update substitutions (it reflects whether another pass is needed)\n+                substitutions = substitutions or subst\n+                if name in yielded:\n+                    continue\n+                yielded.add(name)\n+                yield name, hashed_name, processed\n+\n+            if not substitutions:\n+                break\n+\n+        if substitutions:\n+            yield 'All', None, RuntimeError('Max post-process passes exceeded.')\n             substitutions = False\n             for name, hashed_name, processed, subst in self._post_process(paths, adjustable_paths, hashed_files):\n                 yield name, hashed_name, processed"
  },
  "django__django-12406": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-12406",
    "model_patch": "diff --git a/django/forms/models.py b/django/forms/models.py\nindex dafc11f995..dc53157690 100644\n--- a/django/forms/models.py\n+++ b/django/forms/models.py\n@@ -13,8 +13,8 @@ from django.forms.forms import BaseForm, DeclarativeFieldsMetaclass\n from django.forms.formsets import BaseFormSet, formset_factory\n from django.forms.utils import ErrorList\n from django.forms.widgets import (\n-    HiddenInput, MultipleHiddenInput, SelectMultiple,\n-)\n+\t    HiddenInput, MultipleHiddenInput, SelectMultiple, RadioSelect,\n+\t)\n from django.utils.text import capfirst, get_text_list\n from django.utils.translation import gettext, gettext_lazy as _\n \n@@ -1181,15 +1181,17 @@ class ModelChoiceField(ChoiceField):\n     }\n     iterator = ModelChoiceIterator\n \n-    def __init__(self, queryset, *, empty_label=\"---------\",\n+def __init__(self, queryset, *, empty_label=\"---------\",\n                  required=True, widget=None, label=None, initial=None,\n                  help_text='', to_field_name=None, limit_choices_to=None,\n                  **kwargs):\n-        if required and (initial is not None):\n+        # Don't show an empty choice for radio widgets when the field is required\n+        if isinstance(widget, RadioSelect) and required:\n+            self.empty_label = None\n+        elif required and (initial is not None):\n             self.empty_label = None\n         else:\n             self.empty_label = empty_label\n-\n         # Call Field instead of ChoiceField __init__() because we don't need\n         # ChoiceField.__init__().\n         Field.__init__("
  },
  "django__django-14011": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-14011",
    "model_patch": "diff --git a/django/test/testcases.py b/django/test/testcases.py\nindex 92f566b7b0..137c51a1fa 100644\n--- a/django/test/testcases.py\n+++ b/django/test/testcases.py\n@@ -1468,10 +1468,19 @@ class _MediaFilesHandler(FSFilesHandler):\n     \"\"\"\n     def get_base_dir(self):\n         return settings.MEDIA_ROOT\n+class ClosingThreadedWSGIServer(ThreadedWSGIServer):\n+    # Make worker threads daemon so they don't need to be joined at shutdown\n+    daemon_threads = True\n \n-    def get_base_url(self):\n-        return settings.MEDIA_URL\n+    def server_close(self):\n+        # First perform normal server close\n+        super().server_close()\n+        # Then ensure all Django DB connections are closed (closes per-thread connections)\n+        connections.close_all()\n \n+class LiveServerThread(threading.Thread):\n+    \"\"\"Thread for running a live http server while the tests are running.\"\"\"\n+    server_class = ClosingThreadedWSGIServer\n \n class LiveServerThread(threading.Thread):\n     \"\"\"Thread for running a live http server while the tests are running.\"\"\""
  },
  "sphinx-doc__sphinx-9230": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-9230",
    "model_patch": "Recommended fixes (two options):\n\n1) Recommended (fast): upgrade Sphinx to >= 4.1.0 which contains the upstream bugfix.\n   Command:\n     pip install -U \"sphinx>=4.1.0\"\n\n2) Automated patch (when you cannot upgrade immediately): run the small Python script below in your project root to convert docstrings of the form\n     :param dict(str, str) name:\n   into\n     :param name:\n     :type name: dict(str, str)\n   This preserves the existing description and fixes rendering on older Sphinx.\n\nScript (save/run as fix_docstrings.py or run with python3 -c):\npython3 - <<'PY'\nimport re, glob, io, os\npattern = re.compile(r'(:param)\\s+dict\\(\\s*([^)]+?)\\s*\\)\\s+(\\w+)\\s*:(?P<rest>.*)')\nfor path in glob.glob(\"**/*.py\", recursive=True) + glob.glob(\"**/*.rst\", recursive=True) + glob.glob(\"**/*.txt\", recursive=True):\n    try:\n        with open(path, \"r\", encoding=\"utf-8\") as f:\n            s = f.read()\n    except Exception:\n        continue\n    def repl(m):\n        rest = m.group('rest')\n        return f\":param {m.group(3)}:{rest}\\n:type {m.group(3)}: dict({m.group(2)})\"\n    new = pattern.sub(repl, s)\n    if new != s:\n        with open(path, \"w\", encoding=\"utf-8\") as f:\n            f.write(new)\n        print(\"Patched:\", path)\nprint(\"Done.\")\nPY\n\nAfter applying either option, rebuild your docs (e.g., make html) and verify the parameter now renders like:\n  opc_meta (dict(str,str)) \u2014 (optional)\n\nIf you want, I can prepare a narrower patch (targeting only the files in your attached project) instead of the global script; I chose a safe global script to avoid missing files.\n\nNo changes detected to generate a patch."
  },
  "django__django-11179": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-11179",
    "model_patch": "diff --git a/django/db/models/deletion.py b/django/db/models/deletion.py\nindex 92fe4affb9..226c892eca 100644\n--- a/django/db/models/deletion.py\n+++ b/django/db/models/deletion.py\n@@ -265,17 +265,21 @@ class Collector:\n             self.data[model] = sorted(instances, key=attrgetter(\"pk\"))\n \n         # if possible, bring the models in an order suitable for databases that\n-        # don't support transactions or cannot defer constraint checks until the\n-        # end of a transaction.\n-        self.sort()\n-        # number of objects deleted for each model label\n-        deleted_counter = Counter()\n-\n-        # Optimize for the case with a single obj and no dependencies\n-        if len(self.data) == 1 and len(instances) == 1:\n-            instance = list(instances)[0]\n-            if self.can_fast_delete(instance):\n-                with transaction.mark_for_rollback_on_error():\n+self.sort()\n+          # number of objects deleted for each model label\n+          deleted_counter = Counter()\n+    \n+          # Optimize for the case with a single obj and no dependencies\n+          if len(self.data) == 1 and len(instances) == 1:\n+              instance = list(instances)[0]\n+              if self.can_fast_delete(instance):\n+                  with transaction.mark_for_rollback_on_error():\n+                      count = sql.DeleteQuery(model).delete_batch([instance.pk], self.using)\n+                  # Clear the primary key on the instance to reflect that it has been deleted,\n+                  # mirroring the behavior performed for the general delete path below.\n+                  if not model._meta.auto_created:\n+                      setattr(instance, model._meta.pk.attname, None)\n+                  return count, {model._meta.label: count}\n                     count = sql.DeleteQuery(model).delete_batch([instance.pk], self.using)\n                 return count, {model._meta.label: count}"
  },
  "psf__requests-2931": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "psf__requests-2931",
    "model_patch": "diff --git a/requests/models.py b/requests/models.py\nindex 9c624d3..5b68f1b 100644\n--- a/requests/models.py\n+++ b/requests/models.py\n@@ -49,25 +49,19 @@ CONTENT_CHUNK_SIZE = 10 * 1024\n ITER_CHUNK_SIZE = 512\n \n \n-class RequestEncodingMixin(object):\n-    @property\n-    def path_url(self):\n-        \"\"\"Build the path URL to use.\"\"\"\n-\n-        url = []\n-\n-        p = urlsplit(self.url)\n-\n-        path = p.path\n+path = p.path\n         if not path:\n             path = '/'\n-\n+        \n         url.append(path)\n-\n+        \n         query = p.query\n         if query:\n             url.append('?')\n             url.append(query)\n+        \n+\n+            url.append(query)\n \n         return ''.join(url)\n \n@@ -75,10 +69,12 @@ class RequestEncodingMixin(object):\n     def _encode_params(data):\n         \"\"\"Encode parameters in a piece of data.\n \n-        Will successfully encode parameters when passed as a dict or a list of\n-        2-tuples. Order is retained if data is a list of 2-tuples but arbitrary\n-        if parameters are supplied as a dict.\n-        \"\"\"\n+if isinstance(data, str):\n+            return to_native_string(data)\n+        elif isinstance(data, bytes):\n+            return data\n+        elif hasattr(data, 'read'):\n+            return data\n \n         if isinstance(data, (str, bytes)):\n             return to_native_string(data)"
  },
  "django__django-10973": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-10973",
    "model_patch": "diff --git a/django/db/backends/postgresql/client.py b/django/db/backends/postgresql/client.py\nindex 7fca6eff30..df498e344f 100644\n--- a/django/db/backends/postgresql/client.py\n+++ b/django/db/backends/postgresql/client.py\n@@ -11,54 +11,39 @@ def _escape_pgpass(txt):\n     Escape a fragment of a PostgreSQL .pgpass file.\n     \"\"\"\n     return txt.replace('\\\\', '\\\\\\\\').replace(':', '\\\\:')\n-\n-\n-class DatabaseClient(BaseDatabaseClient):\n-    executable_name = 'psql'\n-\n-    @classmethod\n-    def runshell_db(cls, conn_params):\n-        args = [cls.executable_name]\n-\n-        host = conn_params.get('host', '')\n-        port = conn_params.get('port', '')\n-        dbname = conn_params.get('database', '')\n-        user = conn_params.get('user', '')\n-        passwd = conn_params.get('password', '')\n-\n-        if user:\n-            args += ['-U', user]\n-        if host:\n-            args += ['-h', host]\n-        if port:\n-            args += ['-p', str(port)]\n-        args += [dbname]\n-\n-        temp_pgpass = None\n-        sigint_handler = signal.getsignal(signal.SIGINT)\n-        try:\n-            if passwd:\n-                # Create temporary .pgpass file.\n-                temp_pgpass = NamedTemporaryFile(mode='w+')\n-                try:\n-                    print(\n-                        _escape_pgpass(host) or '*',\n-                        str(port) or '*',\n-                        _escape_pgpass(dbname) or '*',\n-                        _escape_pgpass(user) or '*',\n-                        _escape_pgpass(passwd),\n-                        file=temp_pgpass,\n-                        sep=':',\n-                        flush=True,\n-                    )\n-                    os.environ['PGPASSFILE'] = temp_pgpass.name\n-                except UnicodeEncodeError:\n-                    # If the current locale can't encode the data, let the\n-                    # user input the password manually.\n-                    pass\n-            # Allow SIGINT to pass to psql to abort queries.\n-            signal.signal(signal.SIGINT, signal.SIG_IGN)\n-            subprocess.check_call(args)\n+def runshell_db(cls, conn_params):\n+            args = [cls.executable_name]\n+\n+            host = conn_params.get('host', '')\n+            port = conn_params.get('port', '')\n+            dbname = conn_params.get('database', '')\n+            user = conn_params.get('user', '')\n+            passwd = conn_params.get('password', '')\n+\n+            if user:\n+                args += ['-U', user]\n+            if host:\n+                args += ['-h', host]\n+            if port:\n+                args += ['-p', str(port)]\n+            args += [dbname]\n+\n+            sigint_handler = signal.getsignal(signal.SIGINT)\n+            try:\n+                env = os.environ.copy()\n+                if passwd:\n+                    try:\n+                        env['PGPASSWORD'] = passwd\n+                    except UnicodeEncodeError:\n+                        # If the current locale can't encode the data, let the\n+                        # user input the password manually.\n+                        pass\n+                # Allow SIGINT to pass to psql to abort queries.\n+                signal.signal(signal.SIGINT, signal.SIG_IGN)\n+                subprocess.run(args, env=env, check=True)\n+            finally:\n+                # Restore the original SIGINT handler.\n+                signal.signal(signal.SIGINT, sigint_handler)\n         finally:\n             # Restore the original SIGINT handler.\n             signal.signal(signal.SIGINT, sigint_handler)"
  },
  "django__django-7530": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-7530",
    "model_patch": "diff --git a/django/core/management/commands/makemigrations.py b/django/core/management/commands/makemigrations.py\nindex 0b39536f5b..7bf4dda7ec 100644\n--- a/django/core/management/commands/makemigrations.py\n+++ b/django/core/management/commands/makemigrations.py\n@@ -79,8 +79,7 @@ class Command(BaseCommand):\n             )\n \n         # Make sure the app they asked for exists\n-        app_labels = set(app_labels)\n-        bad_app_labels = set()\n+bad_app_labels = set()\n         for app_label in app_labels:\n             try:\n                 apps.get_app_config(app_label)\n@@ -90,11 +89,11 @@ class Command(BaseCommand):\n             for app_label in bad_app_labels:\n                 self.stderr.write(\"App '%s' could not be found. Is it in INSTALLED_APPS?\" % app_label)\n             sys.exit(2)\n-\n+        \n         # Load the current graph state. Pass in None for the connection so\n         # the loader doesn't try to resolve replaced migrations from DB.\n         loader = MigrationLoader(None, ignore_no_migrations=True)\n-\n+        \n         # Raise an error if any migrations are applied before their dependencies.\n         consistency_check_labels = set(config.label for config in apps.get_app_configs())\n         # Non-default databases are only checked if database routers used.\n@@ -105,9 +104,11 @@ class Command(BaseCommand):\n                     # At least one model must be migrated to the database.\n                     router.allow_migrate(connection.alias, app_label, model_name=model._meta.object_name)\n                     for app_label in consistency_check_labels\n-                    for model in apps.get_models(app_label)\n+                    for model in apps.get_app_config(app_label).get_models()\n             )):\n                 loader.check_consistent_history(connection)\n+                loader.check_consistent_history(connection)\n+                loader.check_consistent_history(connection)\n \n         # Before anything else, see if there's conflicting apps and drop out\n         # hard if there are any and they don't want to merge"
  },
  "django__django-16631": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-16631",
    "model_patch": "diff --git a/docs/ref/settings.txt b/docs/ref/settings.txt\nindex 41387886c0..0e12d9f85b 100644\n--- a/docs/ref/settings.txt\n+++ b/docs/ref/settings.txt\n@@ -2302,9 +2302,13 @@ A list of fallback secret keys for a particular Django installation. These are\n used to allow rotation of the ``SECRET_KEY``.\n \n In order to rotate your secret keys, set a new ``SECRET_KEY`` and move the\n-previous value to the beginning of ``SECRET_KEY_FALLBACKS``. Then remove the\n-old values from the end of the ``SECRET_KEY_FALLBACKS`` when you are ready to\n-expire the sessions, password reset tokens, and so on, that make use of them.\n+previous value to the beginning of ``SECRET_KEY_FALLBACKS``. Note that not all\n+code paths that derive session, per-user, or token values necessarily consult\n+``SECRET_KEY_FALLBACKS`` (for example, older implementations of\n+``AbstractBaseUser.get_session_auth_hash()`` use only the current\n+``SECRET_KEY``). Then remove the old values from the end of ``SECRET_KEY_FALLBACKS``\n+when you are ready to expire the sessions, password reset tokens, and so on,\n+that make use of them.\n \n .. note::"
  },
  "django__django-13297": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-13297",
    "model_patch": "diff --git a/django/views/generic/base.py b/django/views/generic/base.py\nindex ea5baca08d..3110d0743d 100644\n--- a/django/views/generic/base.py\n+++ b/django/views/generic/base.py\n@@ -12,10 +12,6 @@ from django.urls import reverse\n from django.utils.decorators import classonlymethod\n from django.utils.deprecation import RemovedInDjango40Warning\n from django.utils.functional import SimpleLazyObject\n-\n-logger = logging.getLogger('django.request')\n-\n-\n class ContextMixin:\n     \"\"\"\n     A default context mixin that passes the keyword arguments received by\n@@ -24,6 +20,16 @@ class ContextMixin:\n     extra_context = None\n \n     def get_context_data(self, **kwargs):\n+        kwargs.setdefault('view', self)\n+        if self.extra_context is not None:\n+            kwargs.update(self.extra_context)\n+        # Resolve SimpleLazyObject values (e.g. URL kwargs wrapped by\n+        # _wrap_url_kwargs_with_deprecation_warning) so callers that expect\n+        # native types (such as ORM filters) receive concrete values.\n+        for key, value in list(kwargs.items()):\n+            if isinstance(value, SimpleLazyObject):\n+                kwargs[key] = str(value)\n+        return kwargs\n         kwargs.setdefault('view', self)\n         if self.extra_context is not None:\n             kwargs.update(self.extra_context)"
  },
  "django__django-13810": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-13810",
    "model_patch": "diff --git a/django/core/handlers/base.py b/django/core/handlers/base.py\nindex 8e8c3da06a..e5b6bab55a 100644\n--- a/django/core/handlers/base.py\n+++ b/django/core/handlers/base.py\n@@ -34,54 +34,61 @@ class BaseHandler:\n         self._exception_middleware = []\n \n         get_response = self._get_response_async if is_async else self._get_response\n-        handler = convert_exception_to_response(get_response)\n-        handler_is_async = is_async\n-        for middleware_path in reversed(settings.MIDDLEWARE):\n-            middleware = import_string(middleware_path)\n-            middleware_can_sync = getattr(middleware, 'sync_capable', True)\n-            middleware_can_async = getattr(middleware, 'async_capable', False)\n-            if not middleware_can_sync and not middleware_can_async:\n-                raise RuntimeError(\n-                    'Middleware %s must have at least one of '\n-                    'sync_capable/async_capable set to True.' % middleware_path\n-                )\n-            elif not handler_is_async and middleware_can_sync:\n-                middleware_is_async = False\n-            else:\n-                middleware_is_async = middleware_can_async\n-            try:\n-                # Adapt handler, if needed.\n-                handler = self.adapt_method_mode(\n-                    middleware_is_async, handler, handler_is_async,\n-                    debug=settings.DEBUG, name='middleware %s' % middleware_path,\n-                )\n-                mw_instance = middleware(handler)\n-            except MiddlewareNotUsed as exc:\n-                if settings.DEBUG:\n-                    if str(exc):\n-                        logger.debug('MiddlewareNotUsed(%r): %s', middleware_path, exc)\n-                    else:\n-                        logger.debug('MiddlewareNotUsed: %r', middleware_path)\n-                continue\n-\n-            if mw_instance is None:\n-                raise ImproperlyConfigured(\n-                    'Middleware factory %s returned None.' % middleware_path\n-                )\n+for middleware_path in reversed(settings.MIDDLEWARE):\n+                middleware = import_string(middleware_path)\n+                middleware_can_sync = getattr(middleware, 'sync_capable', True)\n+                middleware_can_async = getattr(middleware, 'async_capable', False)\n+                if not middleware_can_sync and not middleware_can_async:\n+                    raise RuntimeError(\n+                        'Middleware %s must have at least one of '\n+                        'sync_capable/async_capable set to True.' % middleware_path\n+                    )\n+                elif not handler_is_async and middleware_can_sync:\n+                    middleware_is_async = False\n+                else:\n+                    middleware_is_async = middleware_can_async\n+                try:\n+                    # Adapt handler, if needed, but don't overwrite `handler` until the\n+                    # middleware is successfully instantiated. Use a temporary\n+                    # `adapted_handler` so that a MiddlewareNotUsed exception does\n+                    # not \"poison\" the remaining middleware chain by replacing the\n+                    # original handler prematurely.\n+                    adapted_handler = self.adapt_method_mode(\n+                        middleware_is_async, handler, handler_is_async,\n+                        debug=settings.DEBUG, name='middleware %s' % middleware_path,\n+                    )\n+                    mw_instance = middleware(adapted_handler)\n+                except MiddlewareNotUsed as exc:\n+                    if settings.DEBUG:\n+                        if str(exc):\n+                            logger.debug('MiddlewareNotUsed(%r): %s', middleware_path, exc)\n+                        else:\n+                            logger.debug('MiddlewareNotUsed: %r', middleware_path)\n+                    continue\n+\n+                if mw_instance is None:\n+                    raise ImproperlyConfigured(\n+                        'Middleware factory %s returned None.' % middleware_path\n+                    )\n \n-            if hasattr(mw_instance, 'process_view'):\n-                self._view_middleware.insert(\n-                    0,\n-                    self.adapt_method_mode(is_async, mw_instance.process_view),\n-                )\n-            if hasattr(mw_instance, 'process_template_response'):\n-                self._template_response_middleware.append(\n-                    self.adapt_method_mode(is_async, mw_instance.process_template_response),\n-                )\n-            if hasattr(mw_instance, 'process_exception'):\n-                # The exception-handling stack is still always synchronous for\n-                # now, so adapt that way.\n-                self._exception_middleware.append(\n+                if hasattr(mw_instance, 'process_view'):\n+                    self._view_middleware.insert(\n+                        0,\n+                        self.adapt_method_mode(is_async, mw_instance.process_view),\n+                    )\n+                if hasattr(mw_instance, 'process_template_response'):\n+                    self._template_response_middleware.append(\n+                        self.adapt_method_mode(is_async, mw_instance.process_template_response),\n+                    )\n+                if hasattr(mw_instance, 'process_exception'):\n+                    # The exception-handling stack is still always synchronous for\n+                    # now, so adapt that way.\n+                    self._exception_middleware.append(\n+                        self.adapt_method_mode(False, mw_instance.process_exception),\n+                    )\n+\n+                handler = convert_exception_to_response(mw_instance)\n+                handler_is_async = middleware_is_async\n                     self.adapt_method_mode(False, mw_instance.process_exception),\n                 )"
  },
  "pytest-dev__pytest-7490": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "pytest-dev__pytest-7490",
    "model_patch": "diff --git a/src/_pytest/skipping.py b/src/_pytest/skipping.py\nindex 335e10996..832ff13a5 100644\n--- a/src/_pytest/skipping.py\n+++ b/src/_pytest/skipping.py\n@@ -191,12 +191,6 @@ def evaluate_skip_marks(item: Item) -> Optional[Skip]:\n class Xfail:\n     \"\"\"The result of evaluate_xfail_marks().\"\"\"\n \n-    reason = attr.ib(type=str)\n-    run = attr.ib(type=bool)\n-    strict = attr.ib(type=bool)\n-    raises = attr.ib(type=Optional[Tuple[\"Type[BaseException]\", ...]])\n-\n-\n def evaluate_xfail_marks(item: Item) -> Optional[Xfail]:\n     \"\"\"Evaluate xfail marks on item, returning Xfail if triggered.\"\"\"\n     for mark in item.iter_markers(name=\"xfail\"):\n@@ -209,6 +203,11 @@ def evaluate_xfail_marks(item: Item) -> Optional[Xfail]:\n             conditions = (mark.kwargs[\"condition\"],)\n \n         # Unconditional.\n+        if not conditions:\n+\n+            xfail(\"[NOTRUN] \" + xfailed.reason)\n+\n+    yield\n         if not conditions:\n             reason = mark.kwargs.get(\"reason\", \"\")\n             return Xfail(reason, run, strict, raises)\n@@ -235,9 +234,13 @@ def pytest_runtest_setup(item: Item) -> None:\n \n     skipped = evaluate_skip_marks(item)\n     if skipped:\n-        item._store[skipped_by_mark_key] = True\n-        skip(skipped.reason)\n-\n+@hookimpl(hookwrapper=True)\n+def pytest_runtest_call(item: Item) -> Generator[None, None, None]:\n+    # Execute the test call first, then re-evaluate xfail marks to pick up markers\n+    # added during the test execution (e.g., via request.node.add_marker).\n+    outcome = yield\n+    xfailed = evaluate_xfail_marks(item)\n+    item._store[xfailed_key] = xfailed\n     if not item.config.option.runxfail:\n         item._store[xfailed_key] = xfailed = evaluate_xfail_marks(item)\n         if xfailed and not xfailed.run:"
  },
  "scikit-learn__scikit-learn-26323": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "scikit-learn__scikit-learn-26323",
    "model_patch": "diff --git a/sklearn/compose/_column_transformer.py b/sklearn/compose/_column_transformer.py\nindex 4eddd12b1..492dec617 100644\n--- a/sklearn/compose/_column_transformer.py\n+++ b/sklearn/compose/_column_transformer.py\n@@ -269,10 +269,7 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n                 (name, trans, col)\n                 for ((name, trans), (_, _, col)) in zip(value, self.transformers)\n             ]\n-        except (TypeError, ValueError):\n-            self.transformers = value\n-\n-    def set_output(self, *, transform=None):\n+def set_output(self, *, transform=None):\n         \"\"\"Set the output container when `\"transform\"` and `\"fit_transform\"` are called.\n \n         Calling `set_output` will set the output of all estimators in `transformers`\n@@ -293,12 +290,27 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n             Estimator instance.\n         \"\"\"\n         super().set_output(transform=transform)\n-        transformers = (\n+        transformers = [\n             trans\n             for _, trans, _ in chain(\n                 self.transformers, getattr(self, \"transformers_\", [])\n             )\n             if trans not in {\"passthrough\", \"drop\"}\n+        ]\n+        # Include remainder estimator if present and it's an actual estimator\n+        # (i.e. not \"drop\" or \"passthrough\") and not already included.\n+        if hasattr(self, \"_remainder\"):\n+            rem = self._remainder[1]\n+            if rem not in {\"passthrough\", \"drop\"} and rem not in transformers:\n+                transformers.append(rem)\n+\n+        for trans in transformers:\n+            _safe_set_output(trans, transform=transform)\n+\n+        return self\n+                self.transformers, getattr(self, \"transformers_\", [])\n+            )\n+            if trans not in {\"passthrough\", \"drop\"}\n         )\n         for trans in transformers:\n             _safe_set_output(trans, transform=transform)"
  },
  "sphinx-doc__sphinx-7590": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-7590",
    "model_patch": "diff --git a/sphinx/domains/cpp.py b/sphinx/domains/cpp.py\nindex fe52d881d..22e81defb 100644\n--- a/sphinx/domains/cpp.py\n+++ b/sphinx/domains/cpp.py\n@@ -882,6 +882,27 @@ class ASTCharLiteral(ASTLiteral):\n         signode.append(nodes.Text(txt, txt))\n \n \n+  class ASTUserDefinedLiteral(ASTLiteral):\n+      \"\"\"Represents a literal with a user-defined-literal suffix, e.g. 123_km or \"s\"_mysuf.\"\"\"\n+      def __init__(self, literal: ASTLiteral, suffix: str) -> None:\n+          self.literal = literal\n+          self.suffix = suffix\n+\n+      def _stringify(self, transform: StringifyTransform) -> str:\n+          return transform(self.literal) + self.suffix\n+\n+      def get_id(self, version: int) -> str:\n+          try:\n+              base = self.literal.get_id(version)\n+          except Exception:\n+              base = str(self.literal)\n+          return \"%s_udl_%s\" % (base, self.suffix)\n+\n+      def describe_signature(self, signode: TextElement, mode: str,\n+                             env: \"BuildEnvironment\", symbol: \"Symbol\") -> None:\n+          txt = str(self)\n+          signode.append(nodes.Text(txt, txt))\n+\n class ASTThisLiteral(ASTExpression):\n     def _stringify(self, transform: StringifyTransform) -> str:\n         return \"this\"\n@@ -4659,18 +4680,27 @@ class DefinitionParser(BaseParser):\n         if self.skip_word('false'):\n             return ASTBooleanLiteral(False)\n         for regex in [float_literal_re, binary_literal_re, hex_literal_re,\n-                      integer_literal_re, octal_literal_re]:\n-            pos = self.pos\n-            if self.match(regex):\n-                while self.current_char in 'uUlLfF':\n-                    self.pos += 1\n-                return ASTNumberLiteral(self.definition[pos:self.pos])\n-\n-        string = self._parse_string()\n-        if string is not None:\n-            return ASTStringLiteral(string)\n-\n-        # character-literal\n+              integer_literal_re, octal_literal_re]:\n+    pos = self.pos\n+    if self.match(regex):\n+        # consume integer/float suffix characters (u, l, f, etc.)\n+        while self.current_char in 'uUlLfF':\n+            self.pos += 1\n+        num_node = ASTNumberLiteral(self.definition[pos:self.pos])\n+        pos_after_num = self.pos\n+        if self.match(identifier_re):\n+            return ASTUserDefinedLiteral(num_node, self.matched_text)\n+        self.pos = pos_after_num\n+        return num_node\n+string = self._parse_string()\n+if string is not None:\n+    str_node = ASTStringLiteral(string)\n+    pos_after_str = self.pos\n+    if self.match(identifier_re):\n+        return ASTUserDefinedLiteral(str_node, self.matched_text)\n+    self.pos = pos_after_str\n+    return str_node\n+# character-literal\n         if self.match(char_literal_re):\n             prefix = self.last_match.group(1)  # may be None when no prefix\n             data = self.last_match.group(2)"
  }
}