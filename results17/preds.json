{
  "sympy__sympy-24213": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "sympy__sympy-24213",
    "model_patch": "diff --git a/sympy/physics/units/unitsystem.py b/sympy/physics/units/unitsystem.py\nindex a436880c4b..617c5c6645 100644\n--- a/sympy/physics/units/unitsystem.py\n+++ b/sympy/physics/units/unitsystem.py\n@@ -136,18 +136,18 @@ def get_dimensional_expr(self, expr):\n         elif isinstance(expr, Add):\n             return self.get_dimensional_expr(expr.args[0])\n         elif isinstance(expr, Derivative):\n-            dim = self.get_dimensional_expr(expr.expr)\n-            for independent, count in expr.variable_count:\n-                dim /= self.get_dimensional_expr(independent)**count\n-            return dim\n-        elif isinstance(expr, Function):\n-            args = [self.get_dimensional_expr(arg) for arg in expr.args]\n-            if all(i == 1 for i in args):\n-                return S.One\n-            return expr.func(*args)\n-        elif isinstance(expr, Quantity):\n-            return self.get_quantity_dimension(expr).name\n-        return S.One\n+elif isinstance(expr, Add):\n+                factor, dim = self._collect_factor_and_dimension(expr.args[0])\n+                for addend in expr.args[1:]:\n+                    addend_factor, addend_dim = \\\n+                        self._collect_factor_and_dimension(addend)\n+                    if not self.get_dimension_system().equivalent_dims(dim, addend_dim):\n+                        raise ValueError(\n+                            'Dimension of \"{}\" is {}, '\n+                            'but it should be {}'.format(\n+                                addend, addend_dim, dim))\n+                    factor += addend_factor\n+                return factor, dim\n \n     def _collect_factor_and_dimension(self, expr):\n         \"\"\""
  },
  "django__django-11179": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-11179",
    "model_patch": "diff --git a/django/db/models/deletion.py b/django/db/models/deletion.py\nindex 92fe4affb9..cd06304d7d 100644\n--- a/django/db/models/deletion.py\n+++ b/django/db/models/deletion.py\n@@ -267,13 +267,14 @@ class Collector:\n         # if possible, bring the models in an order suitable for databases that\n         # don't support transactions or cannot defer constraint checks until the\n         # end of a transaction.\n-        self.sort()\n-        # number of objects deleted for each model label\n-        deleted_counter = Counter()\n-\n-        # Optimize for the case with a single obj and no dependencies\n-        if len(self.data) == 1 and len(instances) == 1:\n-            instance = list(instances)[0]\n+# Optimize for the case with a single obj and no dependencies\n+          if len(self.data) == 1 and len(instances) == 1:\n+              instance = list(instances)[0]\n+              if self.can_fast_delete(instance):\n+                  with transaction.mark_for_rollback_on_error():\n+                      count = sql.DeleteQuery(model).delete_batch([instance.pk], self.using)\n+                  setattr(instance, model._meta.pk.attname, None)\n+                  return count, {model._meta.label: count}\n             if self.can_fast_delete(instance):\n                 with transaction.mark_for_rollback_on_error():\n                     count = sql.DeleteQuery(model).delete_batch([instance.pk], self.using)"
  },
  "django__django-14011": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-14011",
    "model_patch": "diff --git a/django/core/servers/basehttp.py b/django/core/servers/basehttp.py\nindex 14dab517c9..155f0f68ef 100644\n--- a/django/core/servers/basehttp.py\n+++ b/django/core/servers/basehttp.py\n@@ -57,9 +57,9 @@ def is_broken_pipe_error():\n         ConnectionAbortedError,\n         ConnectionResetError,\n     ))\n-\n-\n-class WSGIServer(simple_server.WSGIServer):\n+class ThreadedWSGIServer(socketserver.ThreadingMixIn, WSGIServer):\n+    \"\"\"A threaded version of the WSGIServer\"\"\"\n+    daemon_threads = False\n     \"\"\"BaseHTTPServer that implements the Python WSGI protocol\"\"\"\n \n     request_queue_size = 10"
  },
  "django__django-14053": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-14053",
    "model_patch": "diff --git a/django/contrib/staticfiles/storage.py b/django/contrib/staticfiles/storage.py\nindex 494890cc23..34a76d5b88 100644\n--- a/django/contrib/staticfiles/storage.py\n+++ b/django/contrib/staticfiles/storage.py\n@@ -193,11 +193,14 @@ class HashedFilesMixin:\n \n             # Restore the fragment that was stripped off earlier.\n             if fragment:\n-                transformed_url += ('?#' if '?#' in url else '#') + fragment\n-\n-            # Return the hashed version to the file\n-            return template % unquote(transformed_url)\n-\n+# Do a single pass first. Post-process only non-adjustable files once;\n+          # adjustable files will be handled in the subsequent passes to avoid\n+          # yielding the same original name multiple times.\n+          non_adjustable_paths = {path: paths[path] for path in paths if path not in adjustable_paths}\n+          for name, hashed_name, processed, _ in self._post_process(non_adjustable_paths, adjustable_paths, hashed_files):\n+              yield name, hashed_name, processed\n+\n+          paths = {path: paths[path] for path in adjustable_paths}\n         return converter\n \n     def post_process(self, paths, dry_run=False, **options):"
  },
  "django__django-7530": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-7530",
    "model_patch": "diff --git a/django/core/management/commands/makemigrations.py b/django/core/management/commands/makemigrations.py\nindex 0b39536f5b..285b33cffb 100644\n--- a/django/core/management/commands/makemigrations.py\n+++ b/django/core/management/commands/makemigrations.py\n@@ -90,15 +90,27 @@ class Command(BaseCommand):\n             for app_label in bad_app_labels:\n                 self.stderr.write(\"App '%s' could not be found. Is it in INSTALLED_APPS?\" % app_label)\n             sys.exit(2)\n-\n-        # Load the current graph state. Pass in None for the connection so\n+# Load the current graph state. Pass in None for the connection so\n         # the loader doesn't try to resolve replaced migrations from DB.\n         loader = MigrationLoader(None, ignore_no_migrations=True)\n-\n+        \n         # Raise an error if any migrations are applied before their dependencies.\n         consistency_check_labels = set(config.label for config in apps.get_app_configs())\n         # Non-default databases are only checked if database routers used.\n         aliases_to_check = connections if settings.DATABASE_ROUTERS else [DEFAULT_DB_ALIAS]\n+        for alias in sorted(aliases_to_check):\n+            connection = connections[alias]\n+            if (connection.settings_dict['ENGINE'] != 'django.db.backends.dummy' and any(\n+                    # At least one model in this app must be migrated to the database.\n+                    router.allow_migrate(connection.alias, app_label, model_name=model._meta.object_name)\n+                    for app_label in consistency_check_labels\n+                    for model in apps.get_app_config(app_label).get_models()\n+            )):\n+                loader.check_consistent_history(connection)\n+                    for app_label in consistency_check_labels\n+                    for model in apps.get_app_config(app_label).get_models()\n+            )):\n+                loader.check_consistent_history(connection)\n         for alias in sorted(aliases_to_check):\n             connection = connections[alias]\n             if (connection.settings_dict['ENGINE'] != 'django.db.backends.dummy' and any("
  },
  "astropy__astropy-7166": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "astropy__astropy-7166",
    "model_patch": "diff --git a/astropy/utils/misc.py b/astropy/utils/misc.py\nindex de3fb01d1..4b04ddb23 100644\n--- a/astropy/utils/misc.py\n+++ b/astropy/utils/misc.py\n@@ -511,22 +511,49 @@ class InheritDocstrings(type):\n         >>> from astropy.utils.misc import InheritDocstrings\n         >>> class A(metaclass=InheritDocstrings):\n         ...     def wiggle(self):\n-        ...         \"Wiggle the thingamajig\"\n-        ...         pass\n-        >>> class B(A):\n-        ...     def wiggle(self):\n-        ...         pass\n-        >>> B.wiggle.__doc__\n-        u'Wiggle the thingamajig'\n-    \"\"\"\n-\n-    def __init__(cls, name, bases, dct):\n+def __init__(cls, name, bases, dct):\n         def is_public_member(key):\n             return (\n                 (key.startswith('__') and key.endswith('__')\n                  and len(key) > 4) or\n                 not key.startswith('_'))\n \n+        for key, val in dct.items():\n+            if not is_public_member(key):\n+                continue\n+\n+            # Functions, staticmethods, and classmethods: copy docstring to the\n+            # underlying function object if missing.\n+            if inspect.isfunction(val) or isinstance(val, (staticmethod, classmethod)):\n+                func = val.__func__ if isinstance(val, (staticmethod, classmethod)) else val\n+                if func.__doc__ is None:\n+                    for base in cls.__mro__[1:]:\n+                        super_method = getattr(base, key, None)\n+                        if super_method is not None:\n+                            super_func = getattr(super_method, '__func__', super_method)\n+                            func.__doc__ = getattr(super_func, '__doc__', None)\n+                            break\n+\n+            # Properties: copy the fget docstring from the first base property that has one.\n+            elif isinstance(val, property):\n+                fget = val.fget\n+                if fget is not None and fget.__doc__ is None:\n+                    for base in cls.__mro__[1:]:\n+                        super_prop = getattr(base, key, None)\n+                        if isinstance(super_prop, property) and super_prop.fget is not None:\n+                            fget.__doc__ = super_prop.fget.__doc__\n+                            break\n+\n+        super().__init__(name, bases, dct)\n+            elif isinstance(val, property):\n+                fget = val.fget\n+                if fget is not None and fget.__doc__ is None:\n+                    for base in cls.__mro__[1:]:\n+                        super_prop = getattr(base, key, None)\n+                        if isinstance(super_prop, property) and super_prop.fget is not None:\n+                            fget.__doc__ = super_prop.fget.__doc__\n+                            break\n+\n         for key, val in dct.items():\n             if (inspect.isfunction(val) and\n                 is_public_member(key) and"
  },
  "django__django-16662": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-16662",
    "model_patch": "diff --git a/django/db/migrations/writer.py b/django/db/migrations/writer.py\nindex a59f0c8dcb..7cbab10136 100644\n--- a/django/db/migrations/writer.py\n+++ b/django/db/migrations/writer.py\n@@ -170,13 +170,18 @@ class MigrationWriter:\n         if \"from django.db import models\" in imports:\n             imports.discard(\"from django.db import models\")\n             imports.add(\"from django.db import migrations, models\")\n-        else:\n-            imports.add(\"from django.db import migrations\")\n-\n-        # Sort imports by the package / module to be imported (the part after\n-        # \"from\" in \"from ... import ...\" or after \"import\" in \"import ...\").\n-        sorted_imports = sorted(imports, key=lambda i: i.split()[1])\n-        items[\"imports\"] = \"\\n\".join(sorted_imports) + \"\\n\" if imports else \"\"\n+# Sort imports: module imports (\"import ...\") should come before \"from ...\"\n+          # imports, but both groups are sorted alphabetically by the module/package name.\n+          module_imports = sorted(\n+              [i for i in imports if i.startswith(\"import \")],\n+              key=lambda i: i.split()[1],\n+          )\n+          from_imports = sorted(\n+              [i for i in imports if i.startswith(\"from \")],\n+              key=lambda i: i.split()[1],\n+          )\n+          sorted_imports = module_imports + from_imports\n+          items[\"imports\"] = \"\\n\".join(sorted_imports) + \"\\n\" if imports else \"\"\n         if migration_imports:\n             items[\"imports\"] += (\n                 \"\\n\\n# Functions from the following migrations need manual \""
  },
  "django__django-13810": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-13810",
    "model_patch": "diff --git a/django/core/handlers/base.py b/django/core/handlers/base.py\nindex 8e8c3da06a..a4cdff5129 100644\n--- a/django/core/handlers/base.py\n+++ b/django/core/handlers/base.py\n@@ -27,13 +27,7 @@ class BaseHandler:\n         \"\"\"\n         Populate middleware lists from settings.MIDDLEWARE.\n \n-        Must be called after the environment is fixed (see __call__ in subclasses).\n-        \"\"\"\n-        self._view_middleware = []\n-        self._template_response_middleware = []\n-        self._exception_middleware = []\n-\n-        get_response = self._get_response_async if is_async else self._get_response\n+get_response = self._get_response_async if is_async else self._get_response\n         handler = convert_exception_to_response(get_response)\n         handler_is_async = is_async\n         for middleware_path in reversed(settings.MIDDLEWARE):\n@@ -50,12 +44,13 @@ class BaseHandler:\n             else:\n                 middleware_is_async = middleware_can_async\n             try:\n-                # Adapt handler, if needed.\n-                handler = self.adapt_method_mode(\n+                # Adapt handler for the middleware call, but don't overwrite the\n+                # outer handler until we know the middleware wants to be used.\n+                adapted_handler = self.adapt_method_mode(\n                     middleware_is_async, handler, handler_is_async,\n                     debug=settings.DEBUG, name='middleware %s' % middleware_path,\n                 )\n-                mw_instance = middleware(handler)\n+                mw_instance = middleware(adapted_handler)\n             except MiddlewareNotUsed as exc:\n                 if settings.DEBUG:\n                     if str(exc):\n@@ -74,17 +69,18 @@ class BaseHandler:\n                     0,\n                     self.adapt_method_mode(is_async, mw_instance.process_view),\n                 )\n-            if hasattr(mw_instance, 'process_template_response'):\n-                self._template_response_middleware.append(\n-                    self.adapt_method_mode(is_async, mw_instance.process_template_response),\n-                )\n-            if hasattr(mw_instance, 'process_exception'):\n-                # The exception-handling stack is still always synchronous for\n+handler = convert_exception_to_response(mw_instance)\n+            handler_is_async = middleware_is_async\n                 # now, so adapt that way.\n                 self._exception_middleware.append(\n                     self.adapt_method_mode(False, mw_instance.process_exception),\n                 )\n \n+            handler = convert_exception_to_response(mw_instance)\n+            handler_is_async = middleware_is_async\n+                    self.adapt_method_mode(False, mw_instance.process_exception),\n+                )\n+\n             handler = convert_exception_to_response(mw_instance)\n             handler_is_async = middleware_is_async"
  },
  "scikit-learn__scikit-learn-26323": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "scikit-learn__scikit-learn-26323",
    "model_patch": "diff --git a/sklearn/compose/_column_transformer.py b/sklearn/compose/_column_transformer.py\nindex 4eddd12b1..a3c5e6998 100644\n--- a/sklearn/compose/_column_transformer.py\n+++ b/sklearn/compose/_column_transformer.py\n@@ -225,44 +225,7 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n         ],\n         \"sparse_threshold\": [Interval(Real, 0, 1, closed=\"both\")],\n         \"n_jobs\": [Integral, None],\n-        \"transformer_weights\": [dict, None],\n-        \"verbose\": [\"verbose\"],\n-        \"verbose_feature_names_out\": [\"boolean\"],\n-    }\n-\n-    def __init__(\n-        self,\n-        transformers,\n-        *,\n-        remainder=\"drop\",\n-        sparse_threshold=0.3,\n-        n_jobs=None,\n-        transformer_weights=None,\n-        verbose=False,\n-        verbose_feature_names_out=True,\n-    ):\n-        self.transformers = transformers\n-        self.remainder = remainder\n-        self.sparse_threshold = sparse_threshold\n-        self.n_jobs = n_jobs\n-        self.transformer_weights = transformer_weights\n-        self.verbose = verbose\n-        self.verbose_feature_names_out = verbose_feature_names_out\n-\n-    @property\n-    def _transformers(self):\n-        \"\"\"\n-        Internal list of transformer only containing the name and\n-        transformers, dropping the columns. This is for the implementation\n-        of get_params via BaseComposition._get_params which expects lists\n-        of tuples of len 2.\n-        \"\"\"\n-        try:\n-            return [(name, trans) for name, trans, _ in self.transformers]\n-        except (TypeError, ValueError):\n-            return self.transformers\n-\n-    @_transformers.setter\n+@_transformers.setter\n     def _transformers(self, value):\n         try:\n             self.transformers = [\n@@ -303,6 +266,53 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n         for trans in transformers:\n             _safe_set_output(trans, transform=transform)\n \n+        # If the user provided an estimator for `remainder`, make sure we also set\n+        # its output configuration. This covers the case where `remainder` is an\n+        # estimator but is not part of `self.transformers`.\n+        if getattr(self, \"remainder\", None) not in {\"passthrough\", \"drop\", None}:\n+            _safe_set_output(self.remainder, transform=transform)\n+\n+        return self\n+\n+        Parameters\n+        ----------\n+        transform : {\"default\", \"pandas\"}, default=None\n+            Configure output of `transform` and `fit_transform`.\n+\n+            - `\"default\"`: Default output format of a transformer\n+            - `\"pandas\"`: DataFrame output\n+            - `None`: Transform configuration is unchanged\n+\n+        Returns\n+        -------\n+        self : estimator instance\n+            Estimator instance.\n+        \"\"\"\n+        super().set_output(transform=transform)\n+        transformers = (\n+            trans\n+            for _, trans, _ in chain(\n+                self.transformers, getattr(self, \"transformers_\", [])\n+            )\n+            if trans not in {\"passthrough\", \"drop\"}\n+        )\n+        for trans in transformers:\n+            _safe_set_output(trans, transform=transform)\n+\n+        # If the user provided an estimator for `remainder`, make sure we also set\n+        # its output configuration. This covers the case where `remainder` is an\n+        # estimator but is not part of `self.transformers`.\n+        if getattr(self, \"remainder\", None) not in {\"passthrough\", \"drop\", None}:\n+            _safe_set_output(self.remainder, transform=transform)\n+\n+        return self\n+                self.transformers, getattr(self, \"transformers_\", [])\n+            )\n+            if trans not in {\"passthrough\", \"drop\"}\n+        )\n+        for trans in transformers:\n+            _safe_set_output(trans, transform=transform)\n+\n         return self\n \n     def get_params(self, deep=True):"
  },
  "sphinx-doc__sphinx-7590": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-7590",
    "model_patch": "diff --git a/sphinx/domains/cpp.py b/sphinx/domains/cpp.py\nindex fe52d881d..de50cf501 100644\n--- a/sphinx/domains/cpp.py\n+++ b/sphinx/domains/cpp.py\n@@ -4655,19 +4655,28 @@ class DefinitionParser(BaseParser):\n         if self.skip_word('nullptr'):\n             return ASTPointerLiteral()\n         if self.skip_word('true'):\n-            return ASTBooleanLiteral(True)\n-        if self.skip_word('false'):\n-            return ASTBooleanLiteral(False)\n-        for regex in [float_literal_re, binary_literal_re, hex_literal_re,\n+for regex in [float_literal_re, binary_literal_re, hex_literal_re,\n                       integer_literal_re, octal_literal_re]:\n             pos = self.pos\n             if self.match(regex):\n+                # consume builtin suffix letters like u, U, l, L, f, F\n                 while self.current_char in 'uUlLfF':\n                     self.pos += 1\n+                # support user-defined literal suffix (identifier) starting\n+                # with a letter or underscore (e.g. 12_km, 0.5_Pa)\n+                if (self.current_char.isalpha() or self.current_char == '_'):\n+                    while (self.current_char.isalnum() or self.current_char == '_'):\n+                        self.pos += 1\n                 return ASTNumberLiteral(self.definition[pos:self.pos])\n-\n+        \n         string = self._parse_string()\n         if string is not None:\n+            # support user-defined string literal suffix immediately after\n+            # the closing quote (e.g. \"abc\"_s)\n+            if (self.current_char.isalpha() or self.current_char == '_'):\n+                # compute start of the original string slice and extend it with the suffix\n+                start = self.pos - len(string)\n+                while (self.current_char.isalnum() or self.current_char == '_'):\n             return ASTStringLiteral(string)\n \n         # character-literal"
  },
  "django__django-13297": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-13297",
    "model_patch": "diff --git a/django/views/generic/base.py b/django/views/generic/base.py\nindex ea5baca08d..67aab6848f 100644\n--- a/django/views/generic/base.py\n+++ b/django/views/generic/base.py\n@@ -12,10 +12,6 @@ from django.urls import reverse\n from django.utils.decorators import classonlymethod\n from django.utils.deprecation import RemovedInDjango40Warning\n from django.utils.functional import SimpleLazyObject\n-\n-logger = logging.getLogger('django.request')\n-\n-\n class ContextMixin:\n     \"\"\"\n     A default context mixin that passes the keyword arguments received by\n@@ -24,6 +20,15 @@ class ContextMixin:\n     extra_context = None\n \n     def get_context_data(self, **kwargs):\n+        kwargs.setdefault('view', self)\n+        if self.extra_context is not None:\n+            kwargs.update(self.extra_context)\n+        # Resolve any SimpleLazyObject URL kwargs so view code receives real values\n+        for key, value in list(kwargs.items()):\n+            if isinstance(value, SimpleLazyObject):\n+                # Force evaluation to avoid passing lazy objects to downstream code\n+                kwargs[key] = str(value)\n+        return kwargs\n         kwargs.setdefault('view', self)\n         if self.extra_context is not None:\n             kwargs.update(self.extra_context)"
  },
  "django__django-16631": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-16631",
    "model_patch": "diff --git a/docs/ref/settings.txt b/docs/ref/settings.txt\nindex 41387886c0..6f570ef9d0 100644\n--- a/docs/ref/settings.txt\n+++ b/docs/ref/settings.txt\n@@ -2293,12 +2293,9 @@ passwords of users and key rotation will not affect them.\n \n .. setting:: SECRET_KEY_FALLBACKS\n \n-``SECRET_KEY_FALLBACKS``\n-------------------------\n-\n-Default: ``[]``\n+A list of fallback secret keys for a particular Django installation. These are used to allow rotation of the ``SECRET_KEY`` for signing operations that support fallback keys (for example, cookie signing via :func:`django.core.signing.get_cookie_signer`, functions in :mod:`django.core.signing`, and the password reset tokens generated by :mod:`django.contrib.auth.tokens`). Note that some parts of Django use ``settings.SECRET_KEY`` directly and do not consult ``SECRET_KEY_FALLBACKS`` (for example, :meth:`django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash`); rotating ``SECRET_KEY`` may therefore invalidate sessions.\n \n-A list of fallback secret keys for a particular Django installation. These are\n+In order to rotate your secret keys, set a new ``SECRET_KEY`` and move the previous value to the beginning of ``SECRET_KEY_FALLBACKS``. Then remove the old values from the end of the ``SECRET_KEY_FALLBACKS`` when you are ready to expire the signing tokens that make use of them.\n used to allow rotation of the ``SECRET_KEY``.\n \n In order to rotate your secret keys, set a new ``SECRET_KEY`` and move the"
  },
  "psf__requests-2931": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "psf__requests-2931",
    "model_patch": "diff --git a/requests/models.py b/requests/models.py\nindex 9c624d3..3b25ea4 100644\n--- a/requests/models.py\n+++ b/requests/models.py\n@@ -40,15 +40,6 @@ REDIRECT_STATI = (\n     codes.moved,              # 301\n     codes.found,              # 302\n     codes.other,              # 303\n-    codes.temporary_redirect, # 307\n-    codes.permanent_redirect, # 308\n-)\n-\n-DEFAULT_REDIRECT_LIMIT = 30\n-CONTENT_CHUNK_SIZE = 10 * 1024\n-ITER_CHUNK_SIZE = 512\n-\n-\n class RequestEncodingMixin(object):\n     @property\n     def path_url(self):\n@@ -70,12 +61,12 @@ class RequestEncodingMixin(object):\n             url.append(query)\n \n         return ''.join(url)\n-\n-    @staticmethod\n-    def _encode_params(data):\n-        \"\"\"Encode parameters in a piece of data.\n-\n-        Will successfully encode parameters when passed as a dict or a list of\n+if isinstance(data, str):\n+            return to_native_string(data)\n+        elif isinstance(data, (bytes, bytearray)):\n+            return data\n+        elif hasattr(data, 'read'):\n+            return data\n         2-tuples. Order is retained if data is a list of 2-tuples but arbitrary\n         if parameters are supplied as a dict.\n         \"\"\"\n@@ -95,6 +86,24 @@ class RequestEncodingMixin(object):\n                             (k.encode('utf-8') if isinstance(k, str) else k,\n                              v.encode('utf-8') if isinstance(v, str) else v))\n             return urlencode(result, doseq=True)\n+        else:\n+            return data\n+                    if v is not None:\n+                        result.append(\n+                            (k.encode('utf-8') if isinstance(k, str) else k,\n+                             v.encode('utf-8') if isinstance(v, str) else v))\n+            return urlencode(result, doseq=True)\n+        else:\n+            return data\n+            for k, vs in to_key_val_list(data):\n+                if isinstance(vs, basestring) or not hasattr(vs, '__iter__'):\n+                    vs = [vs]\n+                for v in vs:\n+                    if v is not None:\n+                        result.append(\n+                            (k.encode('utf-8') if isinstance(k, str) else k,\n+                             v.encode('utf-8') if isinstance(v, str) else v))\n+            return urlencode(result, doseq=True)\n         else:\n             return data"
  },
  "psf__requests-1921": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "psf__requests-1921",
    "model_patch": "diff --git a/requests/adapters.py b/requests/adapters.py\nindex ca46223..2c4e727 100644\n--- a/requests/adapters.py\n+++ b/requests/adapters.py\n@@ -330,18 +330,23 @@ class HTTPAdapter(BaseAdapter):\n                     timeout=timeout\n                 )\n \n-            # Send the request.\n-            else:\n-                if hasattr(conn, 'proxy_pool'):\n-                    conn = conn.proxy_pool\n+if hasattr(conn, 'proxy_pool'):\n+                      conn = conn.proxy_pool\n+\n+                  low_conn = conn._get_conn(timeout=timeout)\n \n-                low_conn = conn._get_conn(timeout=timeout)\n+                  try:\n+                      low_conn.putrequest(request.method,\n+                                          url,\n+                                          skip_accept_encoding=True)\n \n-                try:\n-                    low_conn.putrequest(request.method,\n-                                        url,\n-                                        skip_accept_encoding=True)\n+                      for header, value in request.headers.items():\n+                          # Skip headers with value of None to avoid sending the literal \"None\".\n+                          if value is None:\n+                              continue\n+                          low_conn.putheader(header, value)\n \n+                      low_conn.endheaders()\n                     for header, value in request.headers.items():\n                         low_conn.putheader(header, value)"
  },
  "django__django-10973": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-10973",
    "model_patch": "diff --git a/django/db/backends/postgresql/client.py b/django/db/backends/postgresql/client.py\nindex 7fca6eff30..449a1c09d6 100644\n--- a/django/db/backends/postgresql/client.py\n+++ b/django/db/backends/postgresql/client.py\n@@ -37,28 +37,38 @@ class DatabaseClient(BaseDatabaseClient):\n         temp_pgpass = None\n         sigint_handler = signal.getsignal(signal.SIGINT)\n         try:\n+            env = None\n             if passwd:\n-                # Create temporary .pgpass file.\n-                temp_pgpass = NamedTemporaryFile(mode='w+')\n+                # Prefer PGPASSWORD in the subprocess environment. If the current\n+                # locale can't encode the password, fall back to a temporary .pgpass file.\n                 try:\n-                    print(\n-                        _escape_pgpass(host) or '*',\n-                        str(port) or '*',\n-                        _escape_pgpass(dbname) or '*',\n-                        _escape_pgpass(user) or '*',\n-                        _escape_pgpass(passwd),\n-                        file=temp_pgpass,\n-                        sep=':',\n-                        flush=True,\n-                    )\n-                    os.environ['PGPASSFILE'] = temp_pgpass.name\n+                    env = os.environ.copy()\n+                    env['PGPASSWORD'] = passwd\n                 except UnicodeEncodeError:\n-                    # If the current locale can't encode the data, let the\n-                    # user input the password manually.\n-                    pass\n+                    # Create temporary .pgpass file as a fallback.\n+                    temp_pgpass = NamedTemporaryFile(mode='w+')\n+                    try:\n+                        print(\n+                            _escape_pgpass(host) or '*',\n+                            str(port) or '*',\n+                            _escape_pgpass(dbname) or '*',\n+                            _escape_pgpass(user) or '*',\n+                            _escape_pgpass(passwd),\n+                            file=temp_pgpass,\n+                            sep=':',\n+                            flush=True,\n+                        )\n+                        env = os.environ.copy()\n+                        env['PGPASSFILE'] = temp_pgpass.name\n+                    except UnicodeEncodeError:\n+                        # If even writing to a file fails, let the user input the password manually.\n+                        env = None\n             # Allow SIGINT to pass to psql to abort queries.\n             signal.signal(signal.SIGINT, signal.SIG_IGN)\n-            subprocess.check_call(args)\n+            if env is not None:\n+                subprocess.run(args, check=True, env=env)\n+            else:\n+                subprocess.run(args, check=True)\n         finally:\n             # Restore the original SIGINT handler.\n             signal.signal(signal.SIGINT, sigint_handler)\n@@ -67,5 +77,13 @@ class DatabaseClient(BaseDatabaseClient):\n                 if 'PGPASSFILE' in os.environ:  # unit tests need cleanup\n                     del os.environ['PGPASSFILE']\n \n+    def runshell(self):\n+        DatabaseClient.runshell_db(self.connection.get_connection_params())\n+            signal.signal(signal.SIGINT, sigint_handler)\n+            if temp_pgpass:\n+                temp_pgpass.close()\n+                if 'PGPASSFILE' in os.environ:  # unit tests need cleanup\n+                    del os.environ['PGPASSFILE']\n+\n     def runshell(self):\n         DatabaseClient.runshell_db(self.connection.get_connection_params())"
  },
  "sympy__sympy-17655": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "sympy__sympy-17655",
    "model_patch": "diff --git a/sympy/geometry/point.py b/sympy/geometry/point.py\nindex 7c978c47be..463bafcdfd 100644\n--- a/sympy/geometry/point.py\n+++ b/sympy/geometry/point.py\n@@ -101,11 +101,7 @@ class Point(GeometryEntity):\n     >>> Point(0.5, 0.25, evaluate=False)\n     Point2D(0.5, 0.25)\n \n-    \"\"\"\n-\n-    is_Point = True\n-\n-    def __new__(cls, *args, **kwargs):\n+def __new__(cls, *args, **kwargs):\n         evaluate = kwargs.get('evaluate', global_evaluate[0])\n         on_morph = kwargs.get('on_morph', 'ignore')\n \n@@ -216,22 +212,30 @@ def __add__(self, other):\n         try:\n             s, o = Point._normalize_dimension(self, Point(other, evaluate=False))\n         except TypeError:\n-            raise GeometryError(\"Don't know how to add {} and a Point object\".format(other))\n+            # Attempt to handle scalar * Point (e.g. 2*Point2D(1,1)) where the\n+            # left multiplication produces a Mul containing a Point. Extract\n+            # the Point and scalar factor and rebuild a Point so normalization\n+            # succeeds.\n+            try:\n+                if getattr(other, 'is_Mul', False):\n+                    # find Point factor inside the Mul\n+                    point_factors = [a for a in other.args if getattr(a, 'is_Point', False)]\n+                    if len(point_factors) == 1:\n+                        pt = point_factors[0]\n+                        # scalar = other / pt\n+                        scalar = other/pt\n+                        # use Point.__mul__ to produce a Point\n+                        other = pt * scalar\n+                        s, o = Point._normalize_dimension(self, Point(other, evaluate=False))\n+                    else:\n+                        raise TypeError\n+                else:\n+                    raise TypeError\n+            except TypeError:\n+                raise GeometryError(\"Don't know how to add {} and a Point object\".format(other))\n \n         coords = [simplify(a + b) for a, b in zip(s, o)]\n         return Point(coords, evaluate=False)\n-\n-    def __contains__(self, item):\n-        return item in self.args\n-\n-    def __div__(self, divisor):\n-        \"\"\"Divide point's coordinates by a factor.\"\"\"\n-        divisor = sympify(divisor)\n-        coords = [simplify(x/divisor) for x in self.args]\n-        return Point(coords, evaluate=False)\n-\n-    def __eq__(self, other):\n-        if not isinstance(other, Point) or len(self.args) != len(other.args):\n             return False\n         return self.args == other.args"
  },
  "pytest-dev__pytest-7490": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "pytest-dev__pytest-7490",
    "model_patch": "diff --git a/src/_pytest/nodes.py b/src/_pytest/nodes.py\nindex 560548aea..9dd904b29 100644\n--- a/src/_pytest/nodes.py\n+++ b/src/_pytest/nodes.py\n@@ -204,27 +204,40 @@ class Node(metaclass=NodeMeta):\n \n     def warn(self, warning: \"PytestWarning\") -> None:\n         \"\"\"Issue a warning for this item.\n-\n-        Warnings will be displayed after the test session, unless explicitly suppressed\n-\n-        :param Warning warning: the warning instance to issue. Must be a subclass of PytestWarning.\n-\n-        :raise ValueError: if ``warning`` instance is not a subclass of PytestWarning.\n-\n-        Example usage:\n-\n-        .. code-block:: python\n-\n-            node.warn(PytestWarning(\"some message\"))\n-\n+def add_marker(\n+        self, marker: Union[str, MarkDecorator], append: bool = True\n+    ) -> None:\n+        \"\"\"dynamically add a marker object to the node.\n+    \n+        :type marker: ``str`` or ``pytest.mark.*``  object\n+        :param marker:\n+            ``append=True`` whether to append the marker,\n+            if ``False`` insert at position ``0``.\n         \"\"\"\n-        from _pytest.warning_types import PytestWarning\n-\n-        if not isinstance(warning, PytestWarning):\n-            raise ValueError(\n-                \"warning must be an instance of PytestWarning or subclass, got {!r}\".format(\n-                    warning\n-                )\n+        from _pytest.mark import MARK_GEN\n+    \n+        if isinstance(marker, MarkDecorator):\n+            marker_ = marker\n+        elif isinstance(marker, str):\n+            marker_ = getattr(MARK_GEN, marker)\n+        else:\n+            raise ValueError(\"is not a string or pytest.mark.* Marker\")\n+        self.keywords[marker_.name] = marker_\n+        if append:\n+            self.own_markers.append(marker_.mark)\n+        else:\n+            self.own_markers.insert(0, marker_.mark)\n+    \n+        # Invalidate cached xfail evaluation (if present) so dynamically added\n+        # xfail/skip marks during test execution are re-evaluated by the skipping\n+        # plugin's logic (pytest_runtest_call will re-evaluate when the store\n+        # value is None).\n+        try:\n+            from _pytest.skipping import xfailed_key  # type: ignore\n+            self._store[xfailed_key] = None\n+        except Exception:\n+            # skipping plugin may not be loaded; ignore.\n+            pass\n             )\n         path, lineno = get_fslocation_from_item(self)\n         assert lineno is not None"
  },
  "sphinx-doc__sphinx-9658": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-9658",
    "model_patch": "diff --git a/sphinx/ext/autodoc/mock.py b/sphinx/ext/autodoc/mock.py\nindex b562f47fd..96f3c62cd 100644\n--- a/sphinx/ext/autodoc/mock.py\n+++ b/sphinx/ext/autodoc/mock.py\n@@ -48,13 +48,19 @@ class _MockObject:\n     def __contains__(self, key: str) -> bool:\n         return False\n \n-    def __iter__(self) -> Iterator:\n-        return iter([])\n-\n-    def __mro_entries__(self, bases: Tuple) -> Tuple:\n-        return (self.__class__,)\n-\n-    def __getitem__(self, key: Any) -> \"_MockObject\":\n+def _make_subclass(name: str, module: str, superclass: Any = _MockObject,\n+                   attributes: Any = None, decorator_args: Tuple = ()) -> Any:\n+    # If a display-name (like \"torch.nn.Module\") was passed as the module,\n+    # strip the trailing class name to recover the real module (\"torch.nn\").\n+    if '.' in module:\n+        head, tail = module.rsplit('.', 1)\n+        if tail and tail[0].isupper():\n+            module = head\n+    attrs = {'__module__': module,\n+             '__display_name__': module + '.' + name,\n+             '__sphinx_decorator_args__': decorator_args}\n+    attrs.update(attributes or {})\n+    return type(name, (superclass,), attrs)\n         return _make_subclass(str(key), self.__display_name__, self.__class__)()\n \n     def __getattr__(self, key: str) -> \"_MockObject\":\n@@ -62,13 +68,6 @@ class _MockObject:\n \n     def __call__(self, *args: Any, **kwargs: Any) -> Any:\n         call = self.__class__()\n-        call.__sphinx_decorator_args__ = args\n-        return call\n-\n-    def __repr__(self) -> str:\n-        return self.__display_name__\n-\n-\n def _make_subclass(name: str, module: str, superclass: Any = _MockObject,\n                    attributes: Any = None, decorator_args: Tuple = ()) -> Any:\n     attrs = {'__module__': module,"
  },
  "sphinx-doc__sphinx-9230": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-9230",
    "model_patch": "diff --git a/sphinx/ext/napoleon/docstring.py b/sphinx/ext/napoleon/docstring.py\nindex d8cb75a5f..072a33abc 100644\n--- a/sphinx/ext/napoleon/docstring.py\n+++ b/sphinx/ext/napoleon/docstring.py\n@@ -1157,13 +1157,35 @@ class NumpyDocstring(GoogleDocstring):\n \n         return \":\".join([filepath, \"docstring of %s\" % name])\n \n-    def _escape_args_and_kwargs(self, name: str) -> str:\n+def _escape_args_and_kwargs(self, name: str) -> str:\n         func = super()._escape_args_and_kwargs\n-\n+        # Split on top-level commas only (ignore commas inside parentheses/braces)\n         if \", \" in name:\n-            return \", \".join(func(param) for param in name.split(\", \"))\n+            parts = []\n+            current = []\n+            level = 0\n+            i = 0\n+            while i < len(name):\n+                ch = name[i]\n+                if ch in \"([{\":\n+                    level += 1\n+                elif ch in \")]}\":\n+                    if level:\n+                        level -= 1\n+                # split on comma + space only at top level\n+                if name[i:i+2] == \", \" and level == 0:\n+                    parts.append(\"\".join(current))\n+                    current = []\n+                    i += 2\n+                    continue\n+                current.append(ch)\n+                i += 1\n+            if current:\n+                parts.append(\"\".join(current))\n+            return \", \".join(func(p) for p in parts)\n         else:\n             return func(name)\n+            return func(name)\n \n     def _consume_field(self, parse_type: bool = True, prefer_type: bool = False\n                        ) -> Tuple[str, str, List[str]]:"
  },
  "django__django-12406": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-12406",
    "model_patch": "diff --git a/django/forms/models.py b/django/forms/models.py\nindex dafc11f995..66a2c2640c 100644\n--- a/django/forms/models.py\n+++ b/django/forms/models.py\n@@ -6,14 +6,12 @@ and database field objects.\n from itertools import chain\n \n from django.core.exceptions import (\n-    NON_FIELD_ERRORS, FieldError, ImproperlyConfigured, ValidationError,\n-)\n from django.forms.fields import ChoiceField, Field\n from django.forms.forms import BaseForm, DeclarativeFieldsMetaclass\n from django.forms.formsets import BaseFormSet, formset_factory\n from django.forms.utils import ErrorList\n from django.forms.widgets import (\n-    HiddenInput, MultipleHiddenInput, SelectMultiple,\n+    HiddenInput, MultipleHiddenInput, SelectMultiple, RadioSelect,\n )\n from django.utils.text import capfirst, get_text_list\n from django.utils.translation import gettext, gettext_lazy as _\n@@ -1169,8 +1167,6 @@ class ModelChoiceIterator:\n             ModelChoiceIteratorValue(self.field.prepare_value(obj), obj),\n             self.field.label_from_instance(obj),\n         )\n-\n-\n class ModelChoiceField(ChoiceField):\n     \"\"\"A ChoiceField whose choices are a model QuerySet.\"\"\"\n     # This class is a subclass of ChoiceField for purity, but it doesn't\n@@ -1187,6 +1183,34 @@ class ModelChoiceField(ChoiceField):\n                  **kwargs):\n         if required and (initial is not None):\n             self.empty_label = None\n+        else:\n+            # If a RadioSelect widget is being used for a required field, don't\n+            # provide an empty choice. Radio buttons have an inherent unselected\n+            # state, and showing the empty \"---------\" choice makes it look like\n+            # a valid selectable option.\n+            is_radio = False\n+            if widget is not None:\n+                if isinstance(widget, type):\n+                    try:\n+                        is_radio = issubclass(widget, RadioSelect)\n+                    except Exception:\n+                        is_radio = False\n+                else:\n+                    is_radio = isinstance(widget, RadioSelect)\n+            if required and is_radio:\n+                self.empty_label = None\n+            else:\n+                self.empty_label = empty_label\n+\n+        # Call Field instead of ChoiceField __init__() because we don't need\n+        # ChoiceField.__init__().\n+        Field.__init__(\n+            self, required=required, widget=widget, label=label,\n+            initial=initial, help_text=help_text, **kwargs\n+        )\n+        self.queryset = queryset\n+        self.limit_choices_to = limit_choices_to   # limit the queryset later.\n+        self.to_field_name = to_field_name\n         else:\n             self.empty_label = empty_label"
  }
}