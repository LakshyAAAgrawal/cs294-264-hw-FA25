{
  "psf__requests-2931": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "psf__requests-2931",
    "model_patch": "diff --git a/requests/utils.py b/requests/utils.py\nindex 132cd2b..e288738 100644\n--- a/requests/utils.py\n+++ b/requests/utils.py\n@@ -683,7 +683,7 @@ def get_auth_from_url(url):\n     return auth\n \n \n-def to_native_string(string, encoding='ascii'):\n+def to_native_string(string, encoding='utf-8'):\n     \"\"\"\n     Given a string object, regardless of type, returns a representation of that\n     string in the native string type, encoding and decoding where necessary."
  },
  "sympy__sympy-24213": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "sympy__sympy-24213",
    "model_patch": "diff --git a/sympy/physics/units/unitsystem.py b/sympy/physics/units/unitsystem.py\nindex a436880c4b..5705c821c2 100644\n--- a/sympy/physics/units/unitsystem.py\n+++ b/sympy/physics/units/unitsystem.py\n@@ -175,7 +175,7 @@ def _collect_factor_and_dimension(self, expr):\n             for addend in expr.args[1:]:\n                 addend_factor, addend_dim = \\\n                     self._collect_factor_and_dimension(addend)\n-                if dim != addend_dim:\n+                if not self.get_dimension_system().equivalent_dims(dim, addend_dim):\n                     raise ValueError(\n                         'Dimension of \"{}\" is {}, '\n                         'but it should be {}'.format("
  },
  "django__django-16631": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-16631",
    "model_patch": "diff --git a/docs/ref/settings.txt b/docs/ref/settings.txt\nindex 41387886c0..9368d5874f 100644\n--- a/docs/ref/settings.txt\n+++ b/docs/ref/settings.txt\n@@ -2293,10 +2293,17 @@ passwords of users and key rotation will not affect them.\n \n .. setting:: SECRET_KEY_FALLBACKS\n \n-``SECRET_KEY_FALLBACKS``\n-------------------------\n-\n-Default: ``[]``\n+In order to rotate your secret key, set a new ``SECRET_KEY`` and move the\n+previous value to the beginning of ``SECRET_KEY_FALLBACKS``. Then remove the\n+old values from the end of ``SECRET_KEY_FALLBACKS`` when you are ready to\n+expire the tokens and signed values that make use of them (for example, values\n+created via the signing framework or cookie signing which explicitly support\n+fallback keys). Note that not all uses of the SECRET_KEY consult\n+``SECRET_KEY_FALLBACKS``: Django's session authentication hash\n+(`AbstractBaseUser.get_session_auth_hash`) is derived using the current\n+``SECRET_KEY`` only and does *not* check fallback keys, so rotating the\n+``SECRET_KEY`` will invalidate existing session hashes and log users out even\n+if the old key is present in ``SECRET_KEY_FALLBACKS``.\n \n A list of fallback secret keys for a particular Django installation. These are\n used to allow rotation of the ``SECRET_KEY``."
  },
  "django__django-7530": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-7530",
    "model_patch": "diff --git a/django/core/management/commands/makemigrations.py b/django/core/management/commands/makemigrations.py\nindex 0b39536f5b..e648880ef0 100644\n--- a/django/core/management/commands/makemigrations.py\n+++ b/django/core/management/commands/makemigrations.py\n@@ -105,7 +105,7 @@ class Command(BaseCommand):\n                     # At least one model must be migrated to the database.\n                     router.allow_migrate(connection.alias, app_label, model_name=model._meta.object_name)\n                     for app_label in consistency_check_labels\n-                    for model in apps.get_models(app_label)\n+                    for model in apps.get_app_config(app_label).get_models()\n             )):\n                 loader.check_consistent_history(connection)"
  },
  "django__django-14011": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-14011",
    "model_patch": "diff --git a/django/core/servers/basehttp.py b/django/core/servers/basehttp.py\nindex 14dab517c9..ee811758cb 100644\n--- a/django/core/servers/basehttp.py\n+++ b/django/core/servers/basehttp.py\n@@ -88,9 +88,12 @@ class ServerHandler(simple_server.ServerHandler):\n     def __init__(self, stdin, stdout, stderr, environ, **kwargs):\n         \"\"\"\n         Use a LimitedStream so that unread request data will be ignored at\n-        the end of the request. WSGIRequest uses a LimitedStream but it\n-        shouldn't discard the data since the upstream servers usually do this.\n-        This fix applies only for testserver/runserver.\n+    def close(self):\n+        self.get_stdin()._read_limited()\n+        super().close()\n+        # Ensure any DB connections opened while handling this request are closed.\n+        from django.db import connections\n+        connections.close_all()\n         \"\"\"\n         try:\n             content_length = int(environ.get('CONTENT_LENGTH'))"
  },
  "django__django-13297": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-13297",
    "model_patch": "diff --git a/django/views/generic/base.py b/django/views/generic/base.py\nindex ea5baca08d..6c0528331e 100644\n--- a/django/views/generic/base.py\n+++ b/django/views/generic/base.py\n@@ -11,11 +11,8 @@ from django.template.response import TemplateResponse\n from django.urls import reverse\n from django.utils.decorators import classonlymethod\n from django.utils.deprecation import RemovedInDjango40Warning\n-from django.utils.functional import SimpleLazyObject\n-\n logger = logging.getLogger('django.request')\n-\n-\n+from django.utils.functional import SimpleLazyObject\n class ContextMixin:\n     \"\"\"\n     A default context mixin that passes the keyword arguments received by\n@@ -27,6 +24,10 @@ class ContextMixin:\n         kwargs.setdefault('view', self)\n         if self.extra_context is not None:\n             kwargs.update(self.extra_context)\n+        # Resolve SimpleLazyObject values (e.g., URL kwargs wrapped for deprecation warnings)\n+        for key, value in list(kwargs.items()):\n+            if isinstance(value, SimpleLazyObject):\n+                kwargs[key] = str(value)\n         return kwargs"
  },
  "django__django-11179": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-11179",
    "model_patch": "diff --git a/django/db/models/deletion.py b/django/db/models/deletion.py\nindex 92fe4affb9..baf0ab8ee9 100644\n--- a/django/db/models/deletion.py\n+++ b/django/db/models/deletion.py\n@@ -277,6 +277,8 @@ class Collector:\n             if self.can_fast_delete(instance):\n                 with transaction.mark_for_rollback_on_error():\n                     count = sql.DeleteQuery(model).delete_batch([instance.pk], self.using)\n+                # Clear the in-memory primary key so the instance reflects that it was deleted.\n+                setattr(instance, model._meta.pk.attname, None)\n                 return count, {model._meta.label: count}\n \n         with transaction.atomic(using=self.using, savepoint=False):"
  },
  "scikit-learn__scikit-learn-26323": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "scikit-learn__scikit-learn-26323",
    "model_patch": "diff --git a/sklearn/compose/_column_transformer.py b/sklearn/compose/_column_transformer.py\nindex 4eddd12b1..0a6175646 100644\n--- a/sklearn/compose/_column_transformer.py\n+++ b/sklearn/compose/_column_transformer.py\n@@ -271,26 +271,11 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n             ]\n         except (TypeError, ValueError):\n             self.transformers = value\n-\n     def set_output(self, *, transform=None):\n         \"\"\"Set the output container when `\"transform\"` and `\"fit_transform\"` are called.\n \n         Calling `set_output` will set the output of all estimators in `transformers`\n         and `transformers_`.\n-\n-        Parameters\n-        ----------\n-        transform : {\"default\", \"pandas\"}, default=None\n-            Configure output of `transform` and `fit_transform`.\n-\n-            - `\"default\"`: Default output format of a transformer\n-            - `\"pandas\"`: DataFrame output\n-            - `None`: Transform configuration is unchanged\n-\n-        Returns\n-        -------\n-        self : estimator instance\n-            Estimator instance.\n         \"\"\"\n         super().set_output(transform=transform)\n         transformers = (\n@@ -302,6 +287,12 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n         )\n         for trans in transformers:\n             _safe_set_output(trans, transform=transform)\n+        # Include remainder estimator if it's an estimator (not 'drop' or\n+        if not isinstance(self.remainder, str) and self.remainder not in {\n+            \"passthrough\",\n+            \"drop\",\n+        }:\n+            _safe_set_output(self.remainder, transform=transform)\n \n         return self"
  },
  "pytest-dev__pytest-7490": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "pytest-dev__pytest-7490",
    "model_patch": "diff --git a/src/_pytest/skipping.py b/src/_pytest/skipping.py\nindex 335e10996..82e378ec7 100644\n--- a/src/_pytest/skipping.py\n+++ b/src/_pytest/skipping.py\n@@ -261,7 +261,12 @@ def pytest_runtest_call(item: Item) -> Generator[None, None, None]:\n def pytest_runtest_makereport(item: Item, call: CallInfo[None]):\n     outcome = yield\n     rep = outcome.get_result()\n-    xfailed = item._store.get(xfailed_key, None)\n+    # Refresh xfail evaluation in case markers were added during test execution\n+    if not item.config.option.runxfail:\n+        xfailed = evaluate_xfail_marks(item)\n+        item._store[xfailed_key] = xfailed\n+    else:\n+        xfailed = item._store.get(xfailed_key, None)\n     # unittest special case, see setting of unexpectedsuccess_key\n     if unexpectedsuccess_key in item._store and rep.when == \"call\":\n         reason = item._store[unexpectedsuccess_key]"
  },
  "django__django-12406": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-12406",
    "model_patch": "diff --git a/django/forms/models.py b/django/forms/models.py\nindex dafc11f995..305918147e 100644\n--- a/django/forms/models.py\n+++ b/django/forms/models.py\n@@ -1169,8 +1169,6 @@ class ModelChoiceIterator:\n             ModelChoiceIteratorValue(self.field.prepare_value(obj), obj),\n             self.field.label_from_instance(obj),\n         )\n-\n-\n class ModelChoiceField(ChoiceField):\n     \"\"\"A ChoiceField whose choices are a model QuerySet.\"\"\"\n     # This class is a subclass of ChoiceField for purity, but it doesn't\n@@ -1191,11 +1189,21 @@ class ModelChoiceField(ChoiceField):\n             self.empty_label = empty_label\n \n         # Call Field instead of ChoiceField __init__() because we don't need\n-        # ChoiceField.__init__().\n         Field.__init__(\n             self, required=required, widget=widget, label=label,\n             initial=initial, help_text=help_text, **kwargs\n         )\n+\n+        # If the widget is a RadioSelect, don't show an empty label for required\n+        # ModelChoiceFields because RadioSelect already has an inherent unselected\n+        # state that makes the empty option confusing.\n+        from django.forms.widgets import RadioSelect\n+        if required and initial is None and isinstance(getattr(self, 'widget', None), RadioSelect):\n+            self.empty_label = None\n+\n+        self.queryset = queryset\n+        self.limit_choices_to = limit_choices_to   # limit the queryset later.\n+        self.to_field_name = to_field_name\n         self.queryset = queryset\n         self.limit_choices_to = limit_choices_to   # limit the queryset later.\n         self.to_field_name = to_field_name"
  },
  "django__django-10973": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-10973",
    "model_patch": "diff --git a/django/db/backends/postgresql/client.py b/django/db/backends/postgresql/client.py\nindex 7fca6eff30..e8c0fc3ee3 100644\n--- a/django/db/backends/postgresql/client.py\n+++ b/django/db/backends/postgresql/client.py\n@@ -58,7 +58,11 @@ class DatabaseClient(BaseDatabaseClient):\n                     pass\n             # Allow SIGINT to pass to psql to abort queries.\n             signal.signal(signal.SIGINT, signal.SIG_IGN)\n-            subprocess.check_call(args)\n+            # If a password is available, pass it to the subprocess via PGPASSWORD.\n+            env = os.environ.copy() if passwd else None\n+            if passwd:\n+                env['PGPASSWORD'] = passwd\n+            subprocess.run(args, env=env, check=True)\n         finally:\n             # Restore the original SIGINT handler.\n             signal.signal(signal.SIGINT, sigint_handler)"
  },
  "django__django-13810": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-13810",
    "model_patch": "diff --git a/django/core/handlers/base.py b/django/core/handlers/base.py\nindex 8e8c3da06a..4f3c11ad55 100644\n--- a/django/core/handlers/base.py\n+++ b/django/core/handlers/base.py\n@@ -22,7 +22,6 @@ class BaseHandler:\n     _template_response_middleware = None\n     _exception_middleware = None\n     _middleware_chain = None\n-\n     def load_middleware(self, is_async=False):\n         \"\"\"\n         Populate middleware lists from settings.MIDDLEWARE.\n@@ -49,6 +48,7 @@ class BaseHandler:\n                 middleware_is_async = False\n             else:\n                 middleware_is_async = middleware_can_async\n+            handler_before = handler\n             try:\n                 # Adapt handler, if needed.\n                 handler = self.adapt_method_mode(\n@@ -57,6 +57,10 @@ class BaseHandler:\n                 )\n                 mw_instance = middleware(handler)\n             except MiddlewareNotUsed as exc:\n+                # Restore the handler to the previous value so a MiddlewareNotUsed\n+                # raised during instantiation doesn't leave the adapted handler\n+                # in place and \"poison\" the middleware chain.\n+                handler = handler_before\n                 if settings.DEBUG:\n                     if str(exc):\n                         logger.debug('MiddlewareNotUsed(%r): %s', middleware_path, exc)\n@@ -93,7 +97,6 @@ class BaseHandler:\n         # We only assign to this when initialization is complete as it is used\n         # as a flag for initialization being complete.\n         self._middleware_chain = handler\n-\n     def adapt_method_mode(\n         self, is_async, method, method_is_async=None, debug=False, name=None,\n     ):"
  },
  "psf__requests-1921": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "psf__requests-1921",
    "model_patch": "diff --git a/requests/sessions.py b/requests/sessions.py\nindex a023e4e..b3eaa03 100644\n--- a/requests/sessions.py\n+++ b/requests/sessions.py\n@@ -11,10 +11,6 @@ requests (cookies, auth, proxies).\n import os\n from collections import Mapping\n from datetime import datetime\n-\n-from .compat import cookielib, OrderedDict, urljoin, urlparse, builtin_str\n-from .cookies import (\n-    cookiejar_from_dict, extract_cookies_to_jar, RequestsCookieJar, merge_cookies)\n from .models import Request, PreparedRequest, DEFAULT_REDIRECT_LIMIT\n from .hooks import default_hooks, dispatch_hook\n from .utils import to_key_val_list, default_headers, to_native_string\n@@ -30,14 +26,15 @@ from .status_codes import codes\n # formerly defined here, reexposed here for backward compatibility\n from .models import REDIRECT_STATI\n \n-\n+from .compat import cookielib, OrderedDict, urljoin, urlparse, builtin_str\n+from .cookies import (\n+    cookiejar_from_dict, extract_cookies_to_jar, RequestsCookieJar, merge_cookies)\n def merge_setting(request_setting, session_setting, dict_class=OrderedDict):\n     \"\"\"\n     Determines appropriate setting for a given request, taking into account the\n     explicit setting on that request, and the setting in the session. If a\n     setting is a dictionary, they will be merged together using `dict_class`\n     \"\"\"\n-\n     if session_setting is None:\n         return request_setting\n \n@@ -45,13 +42,25 @@ def merge_setting(request_setting, session_setting, dict_class=OrderedDict):\n         return session_setting\n \n     # Bypass if not a dictionary (e.g. verify)\n-    if not (\n-            isinstance(session_setting, Mapping) and\n-            isinstance(request_setting, Mapping)\n-    ):\n+    if not (isinstance(session_setting, Mapping) and\n+            isinstance(request_setting, Mapping)):\n         return request_setting\n \n+    # Start from session settings and remove any keys explicitly set to None\n     merged_setting = dict_class(to_key_val_list(session_setting))\n+    for k, v in list(session_setting.items()):\n+        if v is None:\n+            merged_setting.pop(k, None)\n+\n+    # Update with request settings (request overrides session)\n+    merged_setting.update(to_key_val_list(request_setting))\n+\n+    # Remove keys explicitly set to None on the request to unset them\n+    for k, v in list(request_setting.items()):\n+        if v is None:\n+            merged_setting.pop(k, None)\n+\n+    return merged_setting\n     merged_setting.update(to_key_val_list(request_setting))\n \n     # Remove keys that are set to None."
  },
  "sphinx-doc__sphinx-9658": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-9658",
    "model_patch": "diff --git a/sphinx/util/typing.py b/sphinx/util/typing.py\nindex 87707d48f..dddfefb43 100644\n--- a/sphinx/util/typing.py\n+++ b/sphinx/util/typing.py\n@@ -37,10 +37,10 @@ try:\n     from types import UnionType  # type: ignore  # python 3.10 or above\n except ImportError:\n     UnionType = None\n-\n if False:\n     # For type annotation\n-    from typing import Type  # NOQA # for python3.5.1\n+    pass\n+    \n \n \n # builtin classes that have incorrect __module__\n@@ -192,18 +192,26 @@ def _restify_py37(cls: Optional[Type]) -> str:\n     elif isinstance(cls, typing._SpecialForm):\n         return ':py:obj:`~%s.%s`' % (cls.__module__, cls._name)\n     elif hasattr(cls, '__qualname__'):\n+        # Prefer qualname but fall back to name; handle mocked objects with empty names\n+        name = getattr(cls, '__qualname__', None) or getattr(cls, '__name__', None)\n+        if not name:\n+            # Fallback for weird/mocked objects: use a stable repr instead of an empty name\n+            return repr(cls)\n         if cls.__module__ == 'typing':\n-            return ':py:class:`~%s.%s`' % (cls.__module__, cls.__qualname__)\n+            return ':py:class:`~%s.%s`' % (cls.__module__, name)\n         else:\n-            return ':py:class:`%s.%s`' % (cls.__module__, cls.__qualname__)\n+            return ':py:class:`%s.%s`' % (cls.__module__, name)\n     elif isinstance(cls, ForwardRef):\n         return ':py:class:`%s`' % cls.__forward_arg__\n     else:\n-        # not a class (ex. TypeVar)\n+        # not a class (ex. TypeVar) - ensure we have a usable name or fallback to repr\n+        name = getattr(cls, '__name__', None)\n+        if not name:\n+            return repr(cls)\n         if cls.__module__ == 'typing':\n-            return ':py:obj:`~%s.%s`' % (cls.__module__, cls.__name__)\n+            return ':py:obj:`~%s.%s`' % (cls.__module__, name)\n         else:\n-            return ':py:obj:`%s.%s`' % (cls.__module__, cls.__name__)\n+            return ':py:obj:`%s.%s`' % (cls.__module__, name)\n \n \n def _restify_py36(cls: Optional[Type]) -> str:"
  },
  "sympy__sympy-17655": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "sympy__sympy-17655",
    "model_patch": "diff --git a/sympy/geometry/point.py b/sympy/geometry/point.py\nindex 7c978c47be..19f215ed72 100644\n--- a/sympy/geometry/point.py\n+++ b/sympy/geometry/point.py\n@@ -176,12 +176,6 @@ def __new__(cls, *args, **kwargs):\n \n         # the general Point\n         return GeometryEntity.__new__(cls, *coords)\n-\n-    def __abs__(self):\n-        \"\"\"Returns the distance between this point and the origin.\"\"\"\n-        origin = Point([0]*len(self))\n-        return Point.distance(origin, self)\n-\n     def __add__(self, other):\n         \"\"\"Add other to self by incrementing self's coordinates by\n         those of other.\n@@ -209,18 +203,17 @@ def __add__(self, other):\n \n         See Also\n         ========\n-\n         sympy.geometry.point.Point.translate\n-\n         \"\"\"\n         try:\n             s, o = Point._normalize_dimension(self, Point(other, evaluate=False))\n         except TypeError:\n             raise GeometryError(\"Don't know how to add {} and a Point object\".format(other))\n-\n         coords = [simplify(a + b) for a, b in zip(s, o)]\n         return Point(coords, evaluate=False)\n \n+        return Point(coords, evaluate=False)\n+\n     def __contains__(self, item):\n         return item in self.args\n \n@@ -278,6 +271,9 @@ def __mul__(self, factor):\n         coords = [simplify(x*factor) for x in self.args]\n         return Point(coords, evaluate=False)\n \n+    def __rmul__(self, factor):\n+        \"\"\"Right-side multiplication: delegate to __mul__.\"\"\"\n+        return self.__mul__(factor)\n     def __neg__(self):\n         \"\"\"Negate the point.\"\"\"\n         coords = [-x for x in self.args]"
  },
  "sphinx-doc__sphinx-9230": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-9230",
    "model_patch": "diff --git a/sphinx/ext/napoleon/docstring.py b/sphinx/ext/napoleon/docstring.py\nindex d8cb75a5f..32041af41 100644\n--- a/sphinx/ext/napoleon/docstring.py\n+++ b/sphinx/ext/napoleon/docstring.py\n@@ -23,9 +23,7 @@ from sphinx.locale import _, __\n from sphinx.util import logging\n from sphinx.util.inspect import stringify_annotation\n from sphinx.util.typing import get_type_hints\n-\n logger = logging.getLogger(__name__)\n-\n _directive_regex = re.compile(r'\\.\\. \\S+::')\n _google_section_regex = re.compile(r'^(\\s|\\w)+:\\s*$')\n _google_typed_arg_regex = re.compile(r'(.+?)\\(\\s*(.*[^\\s]+)\\s*\\)')\n@@ -34,16 +32,14 @@ _single_colon_regex = re.compile(r'(?<!:):(?!:)')\n _xref_or_code_regex = re.compile(\n     r'((?::(?:[a-zA-Z0-9]+[\\-_+:.])*[a-zA-Z0-9]+:`.+?`)|'\n     r'(?:``.+?``))')\n-_xref_regex = re.compile(\n-    r'(?:(?::(?:[a-zA-Z0-9]+[\\-_+:.])*[a-zA-Z0-9]+:)?`.+?`)'\n-)\n+_xref_regex = re.compile(r'(?:(?::(?:[a-zA-Z0-9]+[\\-_+:.])*[a-zA-Z0-9]+:)?`.+?`)')\n _bullet_list_regex = re.compile(r'^(\\*|\\+|\\-)(\\s+\\S|\\s*$)')\n _enumerated_list_regex = re.compile(\n     r'^(?P<paren>\\()?'\n     r'(\\d+|#|[ivxlcdm]+|[IVXLCDM]+|[a-zA-Z])'\n     r'(?(paren)\\)|\\.)(\\s+\\S|\\s*$)')\n _token_regex = re.compile(\n-    r\"(,\\sor\\s|\\sor\\s|\\sof\\s|:\\s|\\sto\\s|,\\sand\\s|\\sand\\s|,\\s\"\n+    r\"(,\\sor\\s|\\sor\\s|\\sof\\s|:\\s|\\sto\\s|,\\sand\\s|\\sand\\s\"\n     r\"|[{]|[}]\"\n     r'|\"(?:\\\\\"|[^\"])*\"'\n     r\"|'(?:\\\\'|[^'])*')\""
  },
  "sphinx-doc__sphinx-7590": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-7590",
    "model_patch": "diff --git a/sphinx/domains/cpp.py b/sphinx/domains/cpp.py\nindex fe52d881d..16935b76c 100644\n--- a/sphinx/domains/cpp.py\n+++ b/sphinx/domains/cpp.py\n@@ -4642,7 +4642,6 @@ class DefinitionParser(BaseParser):\n                 escape = False\n             self.pos += 1\n         return self.definition[startPos:self.pos]\n-\n     def _parse_literal(self) -> ASTLiteral:\n         # -> integer-literal\n         #  | character-literal\n@@ -4664,10 +4663,21 @@ class DefinitionParser(BaseParser):\n             if self.match(regex):\n                 while self.current_char in 'uUlLfF':\n                     self.pos += 1\n+                # support user-defined-literal suffixes (e.g., 123_km)\n+                if self.current_char and (self.current_char.isalpha() or self.current_char == '_'):\n+                    while self.current_char and (self.current_char.isalnum() or self.current_char == '_'):\n+                        self.pos += 1\n                 return ASTNumberLiteral(self.definition[pos:self.pos])\n \n         string = self._parse_string()\n         if string is not None:\n+            # allow user-defined-literal suffix immediately after a string literal\n+            string_start = self.pos - len(string)\n+            if self.current_char and (self.current_char.isalpha() or self.current_char == '_'):\n+                while self.current_char and (self.current_char.isalnum() or self.current_char == '_'):\n+                    self.pos += 1\n+                # return the full token (string + suffix) as a string-literal node\n+                return ASTStringLiteral(self.definition[string_start:self.pos])\n             return ASTStringLiteral(string)\n \n         # character-literal\n@@ -4675,6 +4685,13 @@ class DefinitionParser(BaseParser):\n             prefix = self.last_match.group(1)  # may be None when no prefix\n             data = self.last_match.group(2)\n             try:\n+                # detect UDL suffix after char literal; if present, include suffix\n+                char_start = self.pos - len(self.last_match.group(0))\n+                if self.current_char and (self.current_char.isalpha() or self.current_char == '_'):\n+                    while self.current_char and (self.current_char.isalnum() or self.current_char == '_'):\n+                        self.pos += 1\n+                    # represent char+suffix as a string-literal node containing the full token\n+                    return ASTStringLiteral(self.definition[char_start:self.pos])\n                 return ASTCharLiteral(prefix, data)\n             except UnicodeDecodeError as e:\n                 self.fail(\"Can not handle character literal. Internal error was: %s\" % e)\n@@ -4682,6 +4699,8 @@ class DefinitionParser(BaseParser):\n                 self.fail(\"Can not handle character literal\"\n                           \" resulting in multiple decoded characters.\")\n \n+        # no literal found\n+\n         # TODO: user-defined lit\n         return None"
  },
  "astropy__astropy-7166": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "astropy__astropy-7166",
    "model_patch": "diff --git a/astropy/utils/misc.py b/astropy/utils/misc.py\nindex de3fb01d1..016761c20 100644\n--- a/astropy/utils/misc.py\n+++ b/astropy/utils/misc.py\n@@ -528,14 +528,24 @@ class InheritDocstrings(type):\n                 not key.startswith('_'))\n \n         for key, val in dct.items():\n-            if (inspect.isfunction(val) and\n-                is_public_member(key) and\n-                val.__doc__ is None):\n-                for base in cls.__mro__[1:]:\n-                    super_method = getattr(base, key, None)\n-                    if super_method is not None:\n-                        val.__doc__ = super_method.__doc__\n-                        break\n+            if is_public_member(key) and getattr(val, \"__doc__\", None) is None:\n+                # Plain functions: keep original behavior\n+                if inspect.isfunction(val):\n+                    for base in cls.__mro__[1:]:\n+                        super_method = getattr(base, key, None)\n+                        if super_method is not None:\n+                            val.__doc__ = super_method.__doc__\n+                            break\n+                # Properties: create a new property on the class carrying the inherited\n+                # docstring (properties are not functions so inspect.isfunction is False).\n+                elif isinstance(val, property):\n+                    for base in cls.__mro__[1:]:\n+                        super_method = getattr(base, key, None)\n+                        if super_method is not None:\n+                            doc = super_method.__doc__\n+                            new_prop = property(val.fget, val.fset, val.fdel, doc)\n+                            setattr(cls, key, new_prop)\n+                            break\n \n         super().__init__(name, bases, dct)"
  },
  "django__django-14053": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-14053",
    "model_patch": "diff --git a/django/contrib/staticfiles/storage.py b/django/contrib/staticfiles/storage.py\nindex 494890cc23..33cb1bb0d3 100644\n--- a/django/contrib/staticfiles/storage.py\n+++ b/django/contrib/staticfiles/storage.py\n@@ -220,23 +220,28 @@ class HashedFilesMixin:\n \n         # where to store the new paths\n         hashed_files = {}\n+        # Collect final results per original name so we only yield each original\n+        # filename once, using the final hashed_name/processed values after all\n+        # passes are complete.\n+        results = {}\n \n         # build a list of adjustable files\n         adjustable_paths = [\n             path for path in paths\n             if matches_patterns(path, self._patterns)\n         ]\n-        # Do a single pass first. Post-process all files once, then repeat for\n-        # adjustable files.\n+        # Do a single pass first. Record results (will be overwritten by later passes\n+        # for the same name so the final stored value is the last one).\n         for name, hashed_name, processed, _ in self._post_process(paths, adjustable_paths, hashed_files):\n-            yield name, hashed_name, processed\n+            results[name] = (hashed_name, processed)\n \n         paths = {path: paths[path] for path in adjustable_paths}\n \n         for i in range(self.max_post_process_passes):\n             substitutions = False\n             for name, hashed_name, processed, subst in self._post_process(paths, adjustable_paths, hashed_files):\n-                yield name, hashed_name, processed\n+                # Update the stored result for this name with the latest values.\n+                results[name] = (hashed_name, processed)\n                 substitutions = substitutions or subst\n \n             if not substitutions:\n@@ -248,6 +253,12 @@ class HashedFilesMixin:\n         # Store the processed paths\n         self.hashed_files.update(hashed_files)\n \n+        # After all passes, yield each original filename once with its final values.\n+        for name in sorted(results):\n+            hashed_name, processed = results[name]\n+            yield name, hashed_name, processed\n+        self.hashed_files.update(hashed_files)\n+\n     def _post_process(self, paths, adjustable_paths, hashed_files):\n         # Sort the files by directory level\n         def path_level(name):"
  },
  "django__django-16662": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-16662",
    "model_patch": "diff --git a/django/db/migrations/writer.py b/django/db/migrations/writer.py\nindex a59f0c8dcb..722678a895 100644\n--- a/django/db/migrations/writer.py\n+++ b/django/db/migrations/writer.py\n@@ -171,11 +171,12 @@ class MigrationWriter:\n             imports.discard(\"from django.db import models\")\n             imports.add(\"from django.db import migrations, models\")\n         else:\n-            imports.add(\"from django.db import migrations\")\n-\n-        # Sort imports by the package / module to be imported (the part after\n-        # \"from\" in \"from ... import ...\" or after \"import\" in \"import ...\").\n-        sorted_imports = sorted(imports, key=lambda i: i.split()[1])\n+          # Sort imports so that plain \"import <module>\" lines come before\n+          # \"from <module> import <names>\" lines, each group sorted by module.\n+          module_imports = sorted([i for i in imports if i.startswith(\"import \")], key=lambda i: i.split()[1])\n+          from_imports = sorted([i for i in imports if i.startswith(\"from \")], key=lambda i: i.split()[1])\n+          sorted_imports = module_imports + from_imports\n+          items[\"imports\"] = \"\\n\".join(sorted_imports) + \"\\n\" if imports else \"\"\n         items[\"imports\"] = \"\\n\".join(sorted_imports) + \"\\n\" if imports else \"\"\n         if migration_imports:\n             items[\"imports\"] += ("
  }
}