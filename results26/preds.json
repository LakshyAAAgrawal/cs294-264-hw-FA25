{
  "django__django-7530": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-7530",
    "model_patch": "diff --git a/django/core/management/commands/makemigrations.py b/django/core/management/commands/makemigrations.py\nindex 0b39536f5b..e648880ef0 100644\n--- a/django/core/management/commands/makemigrations.py\n+++ b/django/core/management/commands/makemigrations.py\n@@ -105,7 +105,7 @@ class Command(BaseCommand):\n                     # At least one model must be migrated to the database.\n                     router.allow_migrate(connection.alias, app_label, model_name=model._meta.object_name)\n                     for app_label in consistency_check_labels\n-                    for model in apps.get_models(app_label)\n+                    for model in apps.get_app_config(app_label).get_models()\n             )):\n                 loader.check_consistent_history(connection)"
  },
  "sphinx-doc__sphinx-9230": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-9230",
    "model_patch": "diff --git a/sphinx/util/docfields.py b/sphinx/util/docfields.py\nindex 3a3367ebe..6d48e910c 100644\n--- a/sphinx/util/docfields.py\n+++ b/sphinx/util/docfields.py\n@@ -298,7 +298,7 @@ class DocFieldTransformer:\n             # also support syntax like ``:param type name:``\n             if typedesc.is_typed:\n                 try:\n-                    argtype, argname = fieldarg.split(None, 1)\n+                    argtype, argname = fieldarg.rsplit(None, 1)\n                 except ValueError:\n                     pass\n                 else:"
  },
  "django__django-16631": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-16631",
    "model_patch": "diff --git a/docs/ref/settings.txt b/docs/ref/settings.txt\nindex 41387886c0..919060dcba 100644\n--- a/docs/ref/settings.txt\n+++ b/docs/ref/settings.txt\n@@ -2301,9 +2301,19 @@ Default: ``[]``\n A list of fallback secret keys for a particular Django installation. These are\n used to allow rotation of the ``SECRET_KEY``.\n \n-In order to rotate your secret keys, set a new ``SECRET_KEY`` and move the\n-previous value to the beginning of ``SECRET_KEY_FALLBACKS``. Then remove the\n-old values from the end of the ``SECRET_KEY_FALLBACKS`` when you are ready to\n+    In order to rotate your secret keys, set a new ``SECRET_KEY`` and (optionally)\n+    move the previous value to the beginning of ``SECRET_KEY_FALLBACKS``. Note that\n+    only APIs which explicitly support fallback keys (for example, the cookie\n+    signer and Signer/TimestampSigner usages that accept a ``fallback_keys``\n+    argument) will verify signatures created with those fallback keys. Some\n+    functions \u2014 for example ``django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash`` \u2014\n+    call ``django.utils.crypto.salted_hmac`` without supplying an explicit\n+    ``secret``; ``salted_hmac`` defaults to ``settings.SECRET_KEY`` and does not\n+    consult ``SECRET_KEY_FALLBACKS``. Changing ``SECRET_KEY`` will therefore\n+    invalidate session auth hashes and other values produced via ``salted_hmac``\n+    without a provided secret, and users may be logged out. Remove old values\n+    from the end of ``SECRET_KEY_FALLBACKS`` when you are ready to expire the\n+    remaining tokens and signatures that do use fallback keys.\n expire the sessions, password reset tokens, and so on, that make use of them.\n \n .. note::"
  },
  "django__django-10973": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-10973",
    "model_patch": "diff --git a/django/db/backends/postgresql/client.py b/django/db/backends/postgresql/client.py\nindex 7fca6eff30..05cb0e5ca2 100644\n--- a/django/db/backends/postgresql/client.py\n+++ b/django/db/backends/postgresql/client.py\n@@ -34,38 +34,23 @@ class DatabaseClient(BaseDatabaseClient):\n             args += ['-p', str(port)]\n         args += [dbname]\n \n-        temp_pgpass = None\n         sigint_handler = signal.getsignal(signal.SIGINT)\n         try:\n+            env = None\n             if passwd:\n-                # Create temporary .pgpass file.\n-                temp_pgpass = NamedTemporaryFile(mode='w+')\n-                try:\n-                    print(\n-                        _escape_pgpass(host) or '*',\n-                        str(port) or '*',\n-                        _escape_pgpass(dbname) or '*',\n-                        _escape_pgpass(user) or '*',\n-                        _escape_pgpass(passwd),\n-                        file=temp_pgpass,\n-                        sep=':',\n-                        flush=True,\n-                    )\n-                    os.environ['PGPASSFILE'] = temp_pgpass.name\n-                except UnicodeEncodeError:\n-                    # If the current locale can't encode the data, let the\n-                    # user input the password manually.\n-                    pass\n+                # Pass password via PGPASSWORD environment variable to avoid creating a .pgpass file.\n+                env = os.environ.copy()\n+                env['PGPASSWORD'] = passwd\n             # Allow SIGINT to pass to psql to abort queries.\n             signal.signal(signal.SIGINT, signal.SIG_IGN)\n-            subprocess.check_call(args)\n+            # Use subprocess.run to pass a custom environment (requires Python >= 3.5).\n+            if env is not None:\n+                subprocess.run(args, env=env, check=True)\n+            else:\n+                subprocess.check_call(args)\n         finally:\n             # Restore the original SIGINT handler.\n             signal.signal(signal.SIGINT, sigint_handler)\n-            if temp_pgpass:\n-                temp_pgpass.close()\n-                if 'PGPASSFILE' in os.environ:  # unit tests need cleanup\n-                    del os.environ['PGPASSFILE']\n \n     def runshell(self):\n         DatabaseClient.runshell_db(self.connection.get_connection_params())"
  },
  "django__django-13297": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-13297",
    "model_patch": "diff --git a/django/views/generic/base.py b/django/views/generic/base.py\nindex ea5baca08d..9631537207 100644\n--- a/django/views/generic/base.py\n+++ b/django/views/generic/base.py\n@@ -13,23 +13,33 @@ from django.utils.decorators import classonlymethod\n from django.utils.deprecation import RemovedInDjango40Warning\n from django.utils.functional import SimpleLazyObject\n \n-logger = logging.getLogger('django.request')\n-\n-\n class ContextMixin:\n     \"\"\"\n     A default context mixin that passes the keyword arguments received by\n     get_context_data() as the template context.\n     \"\"\"\n     extra_context = None\n-\n     def get_context_data(self, **kwargs):\n         kwargs.setdefault('view', self)\n         if self.extra_context is not None:\n             kwargs.update(self.extra_context)\n+        # Resolve any SimpleLazyObject values so callers that expect concrete\n+        # types (e.g., slugs) don't receive lazy proxy objects which can cause\n+        # errors when used in database operations.\n+        for key, value in list(kwargs.items()):\n+            if isinstance(value, SimpleLazyObject):\n+                try:\n+                    # Force evaluation of the lazy object and replace with the\n+                    # underlying wrapped object.\n+                    value._setup()\n+                    kwargs[key] = value._wrapped\n+                except Exception:\n+                    # If forcing evaluation fails, fall back to string conversion.\n+                    kwargs[key] = str(value)\n         return kwargs\n \n \n+\n class View:\n     \"\"\"\n     Intentionally simple parent class for all views. Only implements"
  },
  "scikit-learn__scikit-learn-26323": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "scikit-learn__scikit-learn-26323",
    "model_patch": "diff --git a/sklearn/compose/_column_transformer.py b/sklearn/compose/_column_transformer.py\nindex 4eddd12b1..2762ea7de 100644\n--- a/sklearn/compose/_column_transformer.py\n+++ b/sklearn/compose/_column_transformer.py\n@@ -271,22 +271,21 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n             ]\n         except (TypeError, ValueError):\n             self.transformers = value\n-\n     def set_output(self, *, transform=None):\n         \"\"\"Set the output container when `\"transform\"` and `\"fit_transform\"` are called.\n-\n+    \n         Calling `set_output` will set the output of all estimators in `transformers`\n         and `transformers_`.\n-\n+    \n         Parameters\n         ----------\n         transform : {\"default\", \"pandas\"}, default=None\n             Configure output of `transform` and `fit_transform`.\n-\n+    \n             - `\"default\"`: Default output format of a transformer\n             - `\"pandas\"`: DataFrame output\n             - `None`: Transform configuration is unchanged\n-\n+    \n         Returns\n         -------\n         self : estimator instance\n@@ -302,7 +301,12 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n         )\n         for trans in transformers:\n             _safe_set_output(trans, transform=transform)\n-\n+    \n+        # If remainder is an estimator (not 'drop'/'passthrough'/None), set its output.\n+        remainder = getattr(self, \"remainder\", None)\n+        if remainder is not None and remainder not in {\"passthrough\", \"drop\"}:\n+            _safe_set_output(remainder, transform=transform)\n+    \n         return self\n \n     def get_params(self, deep=True):"
  },
  "pytest-dev__pytest-7490": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "pytest-dev__pytest-7490",
    "model_patch": "diff --git a/src/_pytest/nodes.py b/src/_pytest/nodes.py\nindex 560548aea..8b2691db4 100644\n--- a/src/_pytest/nodes.py\n+++ b/src/_pytest/nodes.py\n@@ -257,30 +257,39 @@ class Node(metaclass=NodeMeta):\n             item = item.parent\n         chain.reverse()\n         return chain\n-\n-    def add_marker(\n-        self, marker: Union[str, MarkDecorator], append: bool = True\n-    ) -> None:\n-        \"\"\"dynamically add a marker object to the node.\n-\n-        :type marker: ``str`` or ``pytest.mark.*``  object\n-        :param marker:\n-            ``append=True`` whether to append the marker,\n-            if ``False`` insert at position ``0``.\n-        \"\"\"\n-        from _pytest.mark import MARK_GEN\n-\n-        if isinstance(marker, MarkDecorator):\n-            marker_ = marker\n-        elif isinstance(marker, str):\n-            marker_ = getattr(MARK_GEN, marker)\n-        else:\n-            raise ValueError(\"is not a string or pytest.mark.* Marker\")\n-        self.keywords[marker_.name] = marker_\n-        if append:\n-            self.own_markers.append(marker_.mark)\n-        else:\n-            self.own_markers.insert(0, marker_.mark)\n+def add_marker(\n+    self, marker: Union[str, MarkDecorator], append: bool = True\n+) -> None:\n+    \"\"\"dynamically add a marker object to the node.\n+\n+    :type marker: ``str`` or ``pytest.mark.*``  object\n+    :param marker:\n+        ``append=True`` whether to append the marker,\n+        if ``False`` insert at position ``0``.\n+    \"\"\"\n+    from _pytest.mark import MARK_GEN\n+\n+    if isinstance(marker, MarkDecorator):\n+        marker_ = marker\n+    elif isinstance(marker, str):\n+        marker_ = getattr(MARK_GEN, marker)\n+    else:\n+        raise ValueError(\"is not a string or pytest.mark.* Marker\")\n+    self.keywords[marker_.name] = marker_\n+    if append:\n+        self.own_markers.append(marker_.mark)\n+    else:\n+        self.own_markers.insert(0, marker_.mark)\n+\n+    # Invalidate cached xfail evaluation so dynamically added xfail marks\n+    # are considered during the test run (see pytest issue #7486).\n+    try:\n+        from _pytest.skipping import xfailed_key\n+    except Exception:\n+        xfailed_key = None\n+    if xfailed_key is not None:\n+        # remove cached evaluation if present\n+        self._store.pop(xfailed_key, None)\n \n     def iter_markers(self, name: Optional[str] = None) -> Iterator[Mark]:\n         \"\"\""
  },
  "django__django-14011": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-14011",
    "model_patch": "diff --git a/django/test/testcases.py b/django/test/testcases.py\nindex 92f566b7b0..96e07d3988 100644\n--- a/django/test/testcases.py\n+++ b/django/test/testcases.py\n@@ -1485,8 +1485,6 @@ class LiveServerThread(threading.Thread):\n         self.error = None\n         self.static_handler = static_handler\n         self.connections_override = connections_override\n-        super().__init__()\n-\n     def run(self):\n         \"\"\"\n         Set up the live server and databases, and then loop over handling\n@@ -1501,6 +1499,11 @@ class LiveServerThread(threading.Thread):\n             # Create the handler for serving static and media files\n             handler = self.static_handler(_MediaFilesHandler(WSGIHandler()))\n             self.httpd = self._create_server()\n+            # Ensure worker threads are not daemonic so shutdown waits for them,\n+            # allowing database connections to be closed before test DB destruction.\n+            # This prevents race conditions where destroy_test_db() fails because\n+            # other threads still hold connections (see ticket #22414 regression).\n+            self.httpd.daemon_threads = False\n             # If binding to port zero, assign the port allocated by the OS.\n             if self.port == 0:\n                 self.port = self.httpd.server_address[1]\n@@ -1510,6 +1513,7 @@ class LiveServerThread(threading.Thread):\n         except Exception as e:\n             self.error = e\n             self.is_ready.set()\n+\n         finally:\n             connections.close_all()"
  },
  "django__django-13810": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-13810",
    "model_patch": "diff --git a/django/core/handlers/base.py b/django/core/handlers/base.py\nindex 8e8c3da06a..be8a114eb1 100644\n--- a/django/core/handlers/base.py\n+++ b/django/core/handlers/base.py\n@@ -51,11 +51,11 @@ class BaseHandler:\n                 middleware_is_async = middleware_can_async\n             try:\n                 # Adapt handler, if needed.\n-                handler = self.adapt_method_mode(\n+                adapted_handler = self.adapt_method_mode(\n                     middleware_is_async, handler, handler_is_async,\n                     debug=settings.DEBUG, name='middleware %s' % middleware_path,\n                 )\n-                mw_instance = middleware(handler)\n+                mw_instance = middleware(adapted_handler)\n             except MiddlewareNotUsed as exc:\n                 if settings.DEBUG:\n                     if str(exc):"
  },
  "django__django-11179": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-11179",
    "model_patch": "diff --git a/django/db/models/deletion.py b/django/db/models/deletion.py\nindex 92fe4affb9..170f45735a 100644\n--- a/django/db/models/deletion.py\n+++ b/django/db/models/deletion.py\n@@ -265,17 +265,16 @@ class Collector:\n             self.data[model] = sorted(instances, key=attrgetter(\"pk\"))\n \n         # if possible, bring the models in an order suitable for databases that\n-        # don't support transactions or cannot defer constraint checks until the\n-        # end of a transaction.\n-        self.sort()\n-        # number of objects deleted for each model label\n-        deleted_counter = Counter()\n-\n         # Optimize for the case with a single obj and no dependencies\n-        if len(self.data) == 1 and len(instances) == 1:\n-            instance = list(instances)[0]\n-            if self.can_fast_delete(instance):\n-                with transaction.mark_for_rollback_on_error():\n+        if len(self.data) == 1:\n+            model, instances = next(iter(self.data.items()))\n+            if len(instances) == 1:\n+                instance = list(instances)[0]\n+                if self.can_fast_delete(instance):\n+                    with transaction.mark_for_rollback_on_error():\n+                        count = sql.DeleteQuery(model).delete_batch([instance.pk], self.using)\n+                    # Clear the instance's PK to reflect that it no longer exists in DB.\n+\n                     count = sql.DeleteQuery(model).delete_batch([instance.pk], self.using)\n                 return count, {model._meta.label: count}"
  },
  "psf__requests-1921": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "psf__requests-1921",
    "model_patch": "diff --git a/requests/sessions.py b/requests/sessions.py\nindex a023e4e..e2be978 100644\n--- a/requests/sessions.py\n+++ b/requests/sessions.py\n@@ -19,40 +19,21 @@ from .models import Request, PreparedRequest, DEFAULT_REDIRECT_LIMIT\n from .hooks import default_hooks, dispatch_hook\n from .utils import to_key_val_list, default_headers, to_native_string\n from .exceptions import TooManyRedirects, InvalidSchema\n-from .structures import CaseInsensitiveDict\n-\n-from .adapters import HTTPAdapter\n-\n-from .utils import requote_uri, get_environ_proxies, get_netrc_auth\n-\n-from .status_codes import codes\n-\n-# formerly defined here, reexposed here for backward compatibility\n-from .models import REDIRECT_STATI\n-\n-\n def merge_setting(request_setting, session_setting, dict_class=OrderedDict):\n-    \"\"\"\n-    Determines appropriate setting for a given request, taking into account the\n-    explicit setting on that request, and the setting in the session. If a\n-    setting is a dictionary, they will be merged together using `dict_class`\n-    \"\"\"\n-\n-    if session_setting is None:\n-        return request_setting\n-\n+    \"\"\"Determine setting for a request, merging session and request values.\"\"\"\n+    if session_setting is None: return request_setting\n     if request_setting is None:\n+        # No per-request override; filter out keys set to None in session.\n+        if isinstance(session_setting, Mapping):\n+            filtered = dict_class(to_key_val_list(session_setting))\n+            for k, v in list(filtered.items()):\n+                if v is None: del filtered[k]\n+            return filtered\n         return session_setting\n-\n-    # Bypass if not a dictionary (e.g. verify)\n-    if not (\n-            isinstance(session_setting, Mapping) and\n-            isinstance(request_setting, Mapping)\n-    ):\n+    if not (isinstance(session_setting, Mapping) and isinstance(request_setting, Mapping)):\n         return request_setting\n-\n     merged_setting = dict_class(to_key_val_list(session_setting))\n-    merged_setting.update(to_key_val_list(request_setting))\n+\n \n     # Remove keys that are set to None.\n     for (k, v) in request_setting.items():"
  },
  "sympy__sympy-24213": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "sympy__sympy-24213",
    "model_patch": "diff --git a/sympy/physics/units/unitsystem.py b/sympy/physics/units/unitsystem.py\nindex a436880c4b..a5ba41be45 100644\n--- a/sympy/physics/units/unitsystem.py\n+++ b/sympy/physics/units/unitsystem.py\n@@ -172,10 +172,12 @@ def _collect_factor_and_dimension(self, expr):\n             return factor ** exp_factor, dim ** (exp_factor * exp_dim)\n         elif isinstance(expr, Add):\n             factor, dim = self._collect_factor_and_dimension(expr.args[0])\n+            ds = self.get_dimension_system()\n             for addend in expr.args[1:]:\n                 addend_factor, addend_dim = \\\n                     self._collect_factor_and_dimension(addend)\n-                if dim != addend_dim:\n+                # Use the dimension system's equivalence check rather than direct equality\n+                if not ds.equivalent_dims(dim, addend_dim):\n                     raise ValueError(\n                         'Dimension of \"{}\" is {}, '\n                         'but it should be {}'.format("
  },
  "django__django-12406": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-12406",
    "model_patch": "diff --git a/django/forms/models.py b/django/forms/models.py\nindex dafc11f995..10996e81ef 100644\n--- a/django/forms/models.py\n+++ b/django/forms/models.py\n@@ -1129,11 +1129,6 @@ class InlineForeignKeyField(Field):\n class ModelChoiceIteratorValue:\n     def __init__(self, value, instance):\n         self.value = value\n-        self.instance = instance\n-\n-    def __str__(self):\n-        return str(self.value)\n-\n     def __eq__(self, other):\n         if isinstance(other, ModelChoiceIteratorValue):\n             other = other.value\n@@ -1146,8 +1141,12 @@ class ModelChoiceIterator:\n         self.queryset = field.queryset\n \n     def __iter__(self):\n+        # If there's an empty_label, include it unless the widget is a RadioSelect\n+        # for a required field (RadioSelect has an inherent unselected state).\n         if self.field.empty_label is not None:\n-            yield (\"\", self.field.empty_label)\n+            from django.forms.widgets import RadioSelect\n+            if not (isinstance(self.field.widget, RadioSelect) and self.field.required):\n+                yield (\"\", self.field.empty_label)\n         queryset = self.queryset\n         # Can't use iterator() when queryset uses prefetch_related()\n         if not queryset._prefetch_related_lookups:"
  },
  "astropy__astropy-7166": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "astropy__astropy-7166",
    "model_patch": "diff --git a/astropy/utils/misc.py b/astropy/utils/misc.py\nindex de3fb01d1..35f51ad3a 100644\n--- a/astropy/utils/misc.py\n+++ b/astropy/utils/misc.py\n@@ -523,21 +523,48 @@ class InheritDocstrings(type):\n     def __init__(cls, name, bases, dct):\n         def is_public_member(key):\n             return (\n-                (key.startswith('__') and key.endswith('__')\n-                 and len(key) > 4) or\n-                not key.startswith('_'))\n+                (key.startswith('__') and key.endswith('__') and len(key) > 4)\n+                or not key.startswith('_')\n+            )\n \n         for key, val in dct.items():\n-            if (inspect.isfunction(val) and\n-                is_public_member(key) and\n-                val.__doc__ is None):\n+            if ((inspect.isfunction(val) or\n+                 isinstance(val, (property, classmethod, staticmethod)))\n+                and is_public_member(key) and\n+                getattr(val, '__doc__', None) is None):\n                 for base in cls.__mro__[1:]:\n                     super_method = getattr(base, key, None)\n                     if super_method is not None:\n-                        val.__doc__ = super_method.__doc__\n+                        # Handle properties: copy docstring to the fget if possible\n+                        if isinstance(val, property):\n+                            super_doc = getattr(super_method, '__doc__', None)\n+                            if super_doc is None and hasattr(super_method, 'fget'):\n+                                super_doc = getattr(super_method.fget, '__doc__', None)\n+                            if super_doc is not None:\n+                                try:\n+                                    if getattr(val, 'fget', None) is not None and getattr(val.fget, '__doc__', None) is None:\n+                                        val.fget.__doc__ = super_doc\n+                                    else:\n+                                        # Fallback: set property's __doc__ if available\n+                                        val.__doc__ = super_doc\n+                                except Exception:\n+                                    pass\n+                        # Handle classmethod/staticmethod by updating the underlying function\n+                        elif isinstance(val, (classmethod, staticmethod)):\n+                            func = getattr(val, '__func__', None)\n+                            super_doc = getattr(super_method, '__doc__', None)\n+                            if super_doc is None and hasattr(super_method, '__func__'):\n+                                super_doc = getattr(super_method.__func__, '__doc__', None)\n+                            if func is not None and super_doc is not None and getattr(func, '__doc__', None) is None:\n+                                try:\n+                                    func.__doc__ = super_doc\n+                                except Exception:\n+                                    pass\n+                        else:\n+                            # Plain functions: copy docstring directly\n+                            val.__doc__ = getattr(super_method, '__doc__', None)\n                         break\n-\n-        super().__init__(name, bases, dct)\n+    super().__init__(name, bases, dct)\n \n \n class OrderedDescriptor(metaclass=abc.ABCMeta):"
  },
  "django__django-14053": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-14053",
    "model_patch": "diff --git a/django/contrib/staticfiles/storage.py b/django/contrib/staticfiles/storage.py\nindex 494890cc23..b1b6e9c6a3 100644\n--- a/django/contrib/staticfiles/storage.py\n+++ b/django/contrib/staticfiles/storage.py\n@@ -198,8 +198,6 @@ class HashedFilesMixin:\n             # Return the hashed version to the file\n             return template % unquote(transformed_url)\n \n-        return converter\n-\n     def post_process(self, paths, dry_run=False, **options):\n         \"\"\"\n         Post process the given dictionary of files (called from collectstatic).\n@@ -226,22 +224,44 @@ class HashedFilesMixin:\n             path for path in paths\n             if matches_patterns(path, self._patterns)\n         ]\n+\n+        # Track original names we've already yielded to avoid duplicates.\n+        yielded = set()\n+\n         # Do a single pass first. Post-process all files once, then repeat for\n         # adjustable files.\n         for name, hashed_name, processed, _ in self._post_process(paths, adjustable_paths, hashed_files):\n-            yield name, hashed_name, processed\n+            # Propagate the special 'All' sentinel (max passes exceeded) immediately.\n+            if name == 'All':\n+                yield name, hashed_name, processed\n+                continue\n+            # Only yield each original name once to avoid duplicate work.\n+            if name not in yielded:\n+                yielded.add(name)\n+                yield name, hashed_name, processed\n \n         paths = {path: paths[path] for path in adjustable_paths}\n \n         for i in range(self.max_post_process_passes):\n             substitutions = False\n             for name, hashed_name, processed, subst in self._post_process(paths, adjustable_paths, hashed_files):\n-                yield name, hashed_name, processed\n-                substitutions = substitutions or subst\n+                # Propagate the special 'All' sentinel (max passes exceeded) immediately.\n+                if name == 'All':\n+                    yield name, hashed_name, processed\n+                    continue\n+\n+                # Yield each original name at most once.\n+                if name not in yielded:\n+                    yielded.add(name)\n+                    yield name, hashed_name, processed\n \n             if not substitutions:\n                 break\n \n+        if substitutions:\n+            yield 'All', None, RuntimeError('Max post-process passes exceeded.')\n+\n+\n         if substitutions:\n             yield 'All', None, RuntimeError('Max post-process passes exceeded.')"
  },
  "sympy__sympy-17655": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "sympy__sympy-17655",
    "model_patch": "diff --git a/sympy/geometry/point.py b/sympy/geometry/point.py\nindex 7c978c47be..751d59d0a3 100644\n--- a/sympy/geometry/point.py\n+++ b/sympy/geometry/point.py\n@@ -32,6 +32,7 @@\n from sympy.core.numbers import Float\n from sympy.core.evaluate import global_evaluate\n from sympy.core.add import Add\n+from sympy.core.mul import Mul\n from sympy.utilities.iterables import uniq\n from sympy.utilities.misc import filldedent, func_name, Undecidable\n \n@@ -202,6 +203,21 @@ def __add__(self, other):\n         If this is not desired, the `translate` method can be used or\n         another Point can be added:\n \n+        # Support left-side scalar*Point, e.g. 2*Point2D(1, 1)\n+        if isinstance(other, Mul):\n+            # find a Point operand inside the Mul\n+            point_operand = None\n+            for a in other.args:\n+                if isinstance(a, Point):\n+                    point_operand = a\n+                    break\n+            if point_operand is not None:\n+                # build scalar from the remaining Mul args (or 1 if none)\n+                scalar_args = [a for a in other.args if a is not point_operand]\n+                scalar = Mul(*scalar_args) if scalar_args else S.One\n+                s, o = Point._normalize_dimension(self, point_operand)\n+                coords = [simplify(a + b*scalar) for a, b in zip(s, o)]\n+                return Point(coords, evaluate=False)\n         >>> Point(1, 2).translate(.1, .2)\n         Point2D(11/10, 11/5)\n         >>> Point(1, 2) + Point(.1, .2)"
  },
  "sphinx-doc__sphinx-9658": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-9658",
    "model_patch": "diff --git a/sphinx/util/typing.py b/sphinx/util/typing.py\nindex 87707d48f..88d5320c1 100644\n--- a/sphinx/util/typing.py\n+++ b/sphinx/util/typing.py\n@@ -145,8 +145,6 @@ def restify(cls: Optional[Type]) -> str:\n                 return _restify_py36(cls)\n     except (AttributeError, TypeError):\n         return repr(cls)\n-\n-\n def _restify_py37(cls: Optional[Type]) -> str:\n     \"\"\"Convert python class to a reST reference.\"\"\"\n     from sphinx.util import inspect  # lazy loading\n@@ -192,10 +190,15 @@ def _restify_py37(cls: Optional[Type]) -> str:\n     elif isinstance(cls, typing._SpecialForm):\n         return ':py:obj:`~%s.%s`' % (cls.__module__, cls._name)\n     elif hasattr(cls, '__qualname__'):\n+        # Use a safe qualifier: prefer __qualname__ but fall back to __name__\n+        qual = getattr(cls, '__qualname__', None) or getattr(cls, '__name__', None)\n+        if not qual:\n+            # As a last resort, use repr to avoid empty trailing dots like \"torch.nn.\"\n+            qual = getattr(cls, '__name__', None) or repr(cls)\n         if cls.__module__ == 'typing':\n-            return ':py:class:`~%s.%s`' % (cls.__module__, cls.__qualname__)\n+            return ':py:class:`~%s.%s`' % (cls.__module__, qual)\n         else:\n-            return ':py:class:`%s.%s`' % (cls.__module__, cls.__qualname__)\n+            return ':py:class:`%s.%s`' % (cls.__module__, qual)\n     elif isinstance(cls, ForwardRef):\n         return ':py:class:`%s`' % cls.__forward_arg__\n     else:\n@@ -204,6 +207,11 @@ def _restify_py37(cls: Optional[Type]) -> str:\n             return ':py:obj:`~%s.%s`' % (cls.__module__, cls.__name__)\n         else:\n             return ':py:obj:`%s.%s`' % (cls.__module__, cls.__name__)\n+        # not a class (ex. TypeVar)\n+        if cls.__module__ == 'typing':\n+            return ':py:obj:`~%s.%s`' % (cls.__module__, cls.__name__)\n+        else:\n+            return ':py:obj:`%s.%s`' % (cls.__module__, cls.__name__)\n \n \n def _restify_py36(cls: Optional[Type]) -> str:"
  },
  "sphinx-doc__sphinx-7590": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-7590",
    "model_patch": "diff --git a/sphinx/domains/cpp.py b/sphinx/domains/cpp.py\nindex fe52d881d..0f9a8230e 100644\n--- a/sphinx/domains/cpp.py\n+++ b/sphinx/domains/cpp.py\n@@ -783,12 +783,6 @@ class ASTExpression(ASTBase):\n \n \n # Primary expressions\n-################################################################################\n-\n-class ASTLiteral(ASTExpression):\n-    pass\n-\n-\n class ASTPointerLiteral(ASTLiteral):\n     def _stringify(self, transform: StringifyTransform) -> str:\n         return 'nullptr'\n@@ -855,6 +849,54 @@ class ASTStringLiteral(ASTLiteral):\n         signode.append(nodes.Text(txt, txt))\n \n \n+class ASTUserDefinedLiteral(ASTLiteral):\n+    \"\"\"\n+    Represents a literal with a user-defined-literal suffix (e.g., 1q_s,\n+    6.626e-34q_J, \"foo\"_s, 'a'_chr). Stored as the full literal text.\n+    \"\"\"\n+    def __init__(self, text: str) -> None:\n+        self.text = text\n+\n+    def _stringify(self, transform: StringifyTransform) -> str:\n+        return self.text\n+\n+    def get_id(self, version: int) -> str:\n+        # encode UDLs in the id so they are distinct\n+        return \"LUD%sE\" % self.text\n+\n+    def describe_signature(self, signode: TextElement, mode: str,\n+                           env: \"BuildEnvironment\", symbol: \"Symbol\") -> None:\n+        txt = str(self)\n+        signode.append(nodes.Text(txt, txt))\n+\n+\n+class ASTCharLiteral(ASTLiteral):\n+    def __init__(self, prefix: str, data: str) -> None:\n+        self.prefix = prefix  # may be None when no prefix\n+        self.data = data\n+        assert prefix in _id_char_from_prefix\n+        self.type = _id_char_from_prefix[prefix]\n+        decoded = data.encode().decode('unicode-escape')\n+        if len(decoded) == 1:\n+            self.value = ord(decoded)\n+        else:\n+            raise UnsupportedMultiCharacterCharLiteral(decoded)\n+\n+    def _stringify(self, transform: StringifyTransform) -> str:\n+        if self.prefix is None:\n+            return \"'\" + self.data + \"'\"\n+        else:\n+            return self.prefix + \"'\" + self.data + \"'\"\n+\n+    def get_id(self, version: int) -> str:\n+        return self.type + str(self.value)\n+\n+    def describe_signature(self, signode: TextElement, mode: str,\n+                           env: \"BuildEnvironment\", symbol: \"Symbol\") -> None:\n+        txt = str(self)\n+        signode.append(nodes.Text(txt, txt))\n+\n+\n class ASTCharLiteral(ASTLiteral):\n     def __init__(self, prefix: str, data: str) -> None:\n         self.prefix = prefix  # may be None when no prefix\n@@ -4650,7 +4692,6 @@ class DefinitionParser(BaseParser):\n         #  | string-literal\n         #  | boolean-literal -> \"false\" | \"true\"\n         #  | pointer-literal -> \"nullptr\"\n-        #  | user-defined-literal\n         self.skip_ws()\n         if self.skip_word('nullptr'):\n             return ASTPointerLiteral()\n@@ -4662,8 +4703,14 @@ class DefinitionParser(BaseParser):\n                       integer_literal_re, octal_literal_re]:\n             pos = self.pos\n             if self.match(regex):\n+                # consume built-in suffix letters (e.g., u, U, l, L, f, F)\n                 while self.current_char in 'uUlLfF':\n                     self.pos += 1\n+                # support user-defined-literal suffixes that are identifiers\n+                # (e.g., 6.62607015e-34q_J or 1q_s)\n+                if self.match(identifier_re):\n+                    # identifier matched and self.pos advanced by match()\n+                    pass\n                 return ASTNumberLiteral(self.definition[pos:self.pos])\n \n         string = self._parse_string()"
  },
  "psf__requests-2931": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "psf__requests-2931",
    "model_patch": "diff --git a/requests/utils.py b/requests/utils.py\nindex 132cd2b..55b7f2d 100644\n--- a/requests/utils.py\n+++ b/requests/utils.py\n@@ -625,8 +625,6 @@ def parse_header_links(value):\n _null = '\\x00'.encode('ascii')  # encoding to ASCII for Python 3\n _null2 = _null * 2\n _null3 = _null * 3\n-\n-\n def guess_json_utf(data):\n     # JSON always starts with two ASCII characters, so detection is as\n     # easy as counting the nulls and from their location and count\n@@ -655,7 +653,6 @@ def guess_json_utf(data):\n         # Did not detect a valid UTF-32 ascii-range character\n     return None\n \n-\n def prepend_scheme_if_needed(url, new_scheme):\n     '''Given a URL that may or may not have a scheme, prepend the given scheme.\n     Does not replace a present scheme with the one provided as an argument.'''\n@@ -683,7 +680,7 @@ def get_auth_from_url(url):\n     return auth\n \n \n-def to_native_string(string, encoding='ascii'):\n+def to_native_string(string, encoding='utf-8'):\n     \"\"\"\n     Given a string object, regardless of type, returns a representation of that\n     string in the native string type, encoding and decoding where necessary.\n@@ -699,9 +696,6 @@ def to_native_string(string, encoding='ascii'):\n         else:\n             out = string.decode(encoding)\n \n-    return out\n-\n-\n def urldefragauth(url):\n     \"\"\"\n     Given a url remove the fragment and the authentication part\n@@ -715,3 +709,11 @@ def urldefragauth(url):\n     netloc = netloc.rsplit('@', 1)[-1]\n \n     return urlunparse((scheme, netloc, path, params, query, ''))\n+\n+    # see func:`prepend_scheme_if_needed`\n+    if not netloc:\n+        netloc, path = path, netloc\n+\n+    netloc = netloc.rsplit('@', 1)[-1]\n+\n+    return urlunparse((scheme, netloc, path, params, query, ''))"
  },
  "django__django-16662": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-16662",
    "model_patch": "diff --git a/django/db/migrations/writer.py b/django/db/migrations/writer.py\nindex a59f0c8dcb..b3b3c91405 100644\n--- a/django/db/migrations/writer.py\n+++ b/django/db/migrations/writer.py\n@@ -173,8 +173,7 @@ class MigrationWriter:\n         else:\n             imports.add(\"from django.db import migrations\")\n \n-        # Sort imports by the package / module to be imported (the part after\n-        # \"from\" in \"from ... import ...\" or after \"import\" in \"import ...\").\n+          sorted_imports = sorted(imports, key=lambda i: (0 if i.startswith(\"import \") else 1, i.split()[1]))\n         sorted_imports = sorted(imports, key=lambda i: i.split()[1])\n         items[\"imports\"] = \"\\n\".join(sorted_imports) + \"\\n\" if imports else \"\"\n         if migration_imports:"
  }
}