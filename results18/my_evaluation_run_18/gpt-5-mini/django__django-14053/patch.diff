diff --git a/django/contrib/staticfiles/storage.py b/django/contrib/staticfiles/storage.py
index 494890cc23..cd479efca9 100644
--- a/django/contrib/staticfiles/storage.py
+++ b/django/contrib/staticfiles/storage.py
@@ -164,59 +164,68 @@ class HashedFilesMixin:
 
             # Ignore absolute/protocol-relative and data-uri URLs.
             if re.match(r'^[a-z]+:', url):
-                return matched
-
-            # Ignore absolute URLs that don't point to a static file (dynamic
-            # CSS / JS?). Note that STATIC_URL cannot be empty.
-            if url.startswith('/') and not url.startswith(settings.STATIC_URL):
-                return matched
-
-            # Strip off the fragment so a path-like fragment won't interfere.
-            url_path, fragment = urldefrag(url)
-
-            if url_path.startswith('/'):
-                # Otherwise the condition above would have returned prematurely.
-                assert url_path.startswith(settings.STATIC_URL)
-                target_name = url_path[len(settings.STATIC_URL):]
-            else:
-                # We're using the posixpath module to mix paths and URLs conveniently.
-                source_name = name if os.sep == '/' else name.replace(os.sep, '/')
-                target_name = posixpath.join(posixpath.dirname(source_name), url_path)
-
-            # Determine the hashed name of the target file with the storage backend.
-            hashed_url = self._url(
-                self._stored_name, unquote(target_name),
-                force=True, hashed_files=hashed_files,
-            )
-
-            transformed_url = '/'.join(url_path.split('/')[:-1] + hashed_url.split('/')[-1:])
-
+transformed_url = '/'.join(url_path.split('/')[:-1] + hashed_url.split('/')[-1:])
             # Restore the fragment that was stripped off earlier.
             if fragment:
                 transformed_url += ('?#' if '?#' in url else '#') + fragment
-
             # Return the hashed version to the file
             return template % unquote(transformed_url)
-
+        
         return converter
-
+        
     def post_process(self, paths, dry_run=False, **options):
         """
         Post process the given dictionary of files (called from collectstatic).
-
+        
         Processing is actually two separate operations:
-
+        
         1. renaming files to include a hash of their content for cache-busting,
            and copying those files to the target storage.
         2. adjusting files which contain references to other files so they
            refer to the cache-busting filenames.
-
+        
         If either of these are performed on a file, then that file is considered
         post-processed.
         """
         # don't even dare to process the files if we're in dry run mode
         if dry_run:
             return
+        
+        # where to store the new paths
+        hashed_files = {}
+        yielded_names = set()
+        
+        # build a list of adjustable files
+        adjustable_paths = [
+            path for path in paths
+            if matches_patterns(path, self._patterns)
+        ]
+        # Do a single pass first. Post-process all files once, then repeat for
+        # adjustable files.
+        for name, hashed_name, processed, _ in self._post_process(paths, adjustable_paths, hashed_files):
+            if name not in yielded_names:
+                yield name, hashed_name, processed
+                yielded_names.add(name)
+        
+        paths = {path: paths[path] for path in adjustable_paths}
+        
+        for i in range(self.max_post_process_passes):
+            substitutions = False
+            for name, hashed_name, processed, subst in self._post_process(paths, adjustable_paths, hashed_files):
+                if name not in yielded_names:
+                    yield name, hashed_name, processed
+                    yielded_names.add(name)
+                substitutions = substitutions or subst
+        
+            if not substitutions:
+                break
+        
+        if substitutions:
+            yield 'All', None, RuntimeError('Max post-process passes exceeded.')
+        
+        # Store the processed paths
+        self.hashed_files.update(hashed_files)
+            return
 
         # where to store the new paths
         hashed_files = {}