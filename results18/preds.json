{
  "django__django-16662": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-16662",
    "model_patch": "diff --git a/django/db/migrations/writer.py b/django/db/migrations/writer.py\nindex a59f0c8dcb..a95aa75a9a 100644\n--- a/django/db/migrations/writer.py\n+++ b/django/db/migrations/writer.py\n@@ -148,10 +148,17 @@ class MigrationWriter:\n         for dependency in self.migration.dependencies:\n             if dependency[0] == \"__setting__\":\n                 dependencies.append(\n-                    \"        migrations.swappable_dependency(settings.%s),\"\n-                    % dependency[1]\n-                )\n-                imports.add(\"from django.conf import settings\")\n+# Sort imports by placing bare module imports before \"from\" imports,\n+          # then by the package / module to be imported (the part after\n+          # \"from\" in \"from ... import ...\" or after \"import\" in \"import ...\").\n+          def _import_sort_key(i):\n+              parts = i.split()\n+              # Treat \"from ...\" imports as greater so plain \"import ...\" come first.\n+              is_from = 1 if parts[0] == \"from\" else 0\n+              module = parts[1]\n+              return (is_from, module)\n+          sorted_imports = sorted(imports, key=_import_sort_key)\n+          items[\"imports\"] = \"\\n\".join(sorted_imports) + \"\\n\" if imports else \"\"\n             else:\n                 dependencies.append(\"        %s,\" % self.serialize(dependency)[0])\n         items[\"dependencies\"] = \"\\n\".join(dependencies) + \"\\n\" if dependencies else \"\""
  },
  "sympy__sympy-24213": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "sympy__sympy-24213",
    "model_patch": "diff --git a/sympy/physics/units/unitsystem.py b/sympy/physics/units/unitsystem.py\nindex a436880c4b..15f0bfef24 100644\n--- a/sympy/physics/units/unitsystem.py\n+++ b/sympy/physics/units/unitsystem.py\n@@ -164,25 +164,25 @@ def _collect_factor_and_dimension(self, expr):\n                 factor *= arg_factor\n                 dimension *= arg_dim\n             return factor, dimension\n-        elif isinstance(expr, Pow):\n-            factor, dim = self._collect_factor_and_dimension(expr.base)\n-            exp_factor, exp_dim = self._collect_factor_and_dimension(expr.exp)\n-            if self.get_dimension_system().is_dimensionless(exp_dim):\n-                exp_dim = 1\n-            return factor ** exp_factor, dim ** (exp_factor * exp_dim)\n-        elif isinstance(expr, Add):\n-            factor, dim = self._collect_factor_and_dimension(expr.args[0])\n-            for addend in expr.args[1:]:\n-                addend_factor, addend_dim = \\\n-                    self._collect_factor_and_dimension(addend)\n-                if dim != addend_dim:\n-                    raise ValueError(\n-                        'Dimension of \"{}\" is {}, '\n-                        'but it should be {}'.format(\n-                            addend, addend_dim, dim))\n-                factor += addend_factor\n-            return factor, dim\n-        elif isinstance(expr, Derivative):\n+elif isinstance(expr, Pow):\n+                factor, dim = self._collect_factor_and_dimension(expr.base)\n+                exp_factor, exp_dim = self._collect_factor_and_dimension(expr.exp)\n+                if self.get_dimension_system().is_dimensionless(exp_dim):\n+                    exp_dim = 1\n+                return factor ** exp_factor, dim ** (exp_factor * exp_dim)\n+            elif isinstance(expr, Add):\n+                factor, dim = self._collect_factor_and_dimension(expr.args[0])\n+                for addend in expr.args[1:]:\n+                    addend_factor, addend_dim = \\\n+                        self._collect_factor_and_dimension(addend)\n+                    if not self.get_dimension_system().equivalent_dims(dim,\n+                                                                      addend_dim):\n+                        raise ValueError(\n+                            'Dimension of \"{}\" is {}, '\n+                            'but it should be {}'.format(\n+                                addend, addend_dim, dim))\n+                    factor += addend_factor\n+                return factor, dim\n             factor, dim = self._collect_factor_and_dimension(expr.args[0])\n             for independent, count in expr.variable_count:\n                 ifactor, idim = self._collect_factor_and_dimension(independent)"
  },
  "django__django-10973": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-10973",
    "model_patch": "diff --git a/django/db/backends/postgresql/client.py b/django/db/backends/postgresql/client.py\nindex 7fca6eff30..eaf6372213 100644\n--- a/django/db/backends/postgresql/client.py\n+++ b/django/db/backends/postgresql/client.py\n@@ -18,47 +18,19 @@ class DatabaseClient(BaseDatabaseClient):\n \n     @classmethod\n     def runshell_db(cls, conn_params):\n-        args = [cls.executable_name]\n-\n-        host = conn_params.get('host', '')\n-        port = conn_params.get('port', '')\n-        dbname = conn_params.get('database', '')\n-        user = conn_params.get('user', '')\n-        passwd = conn_params.get('password', '')\n-\n-        if user:\n-            args += ['-U', user]\n-        if host:\n-            args += ['-h', host]\n-        if port:\n-            args += ['-p', str(port)]\n-        args += [dbname]\n-\n-        temp_pgpass = None\n-        sigint_handler = signal.getsignal(signal.SIGINT)\n+sigint_handler = signal.getsignal(signal.SIGINT)\n+        env = os.environ.copy()\n         try:\n             if passwd:\n-                # Create temporary .pgpass file.\n-                temp_pgpass = NamedTemporaryFile(mode='w+')\n-                try:\n-                    print(\n-                        _escape_pgpass(host) or '*',\n-                        str(port) or '*',\n-                        _escape_pgpass(dbname) or '*',\n-                        _escape_pgpass(user) or '*',\n-                        _escape_pgpass(passwd),\n-                        file=temp_pgpass,\n-                        sep=':',\n-                        flush=True,\n-                    )\n-                    os.environ['PGPASSFILE'] = temp_pgpass.name\n-                except UnicodeEncodeError:\n-                    # If the current locale can't encode the data, let the\n-                    # user input the password manually.\n-                    pass\n+                # Provide the password via the PGPASSWORD environment variable for the\n+                # child process instead of creating a temporary .pgpass file.\n+                env['PGPASSWORD'] = passwd\n             # Allow SIGINT to pass to psql to abort queries.\n             signal.signal(signal.SIGINT, signal.SIG_IGN)\n-            subprocess.check_call(args)\n+            subprocess.run(args, check=True, env=env)\n+        finally:\n+            # Restore the original SIGINT handler.\n+            signal.signal(signal.SIGINT, sigint_handler)\n         finally:\n             # Restore the original SIGINT handler.\n             signal.signal(signal.SIGINT, sigint_handler)"
  },
  "django__django-13810": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-13810",
    "model_patch": "diff --git a/django/core/handlers/base.py b/django/core/handlers/base.py\nindex 8e8c3da06a..3b0ebccc47 100644\n--- a/django/core/handlers/base.py\n+++ b/django/core/handlers/base.py\n@@ -49,13 +49,13 @@ class BaseHandler:\n                 middleware_is_async = False\n             else:\n                 middleware_is_async = middleware_can_async\n-            try:\n+try:\n                 # Adapt handler, if needed.\n-                handler = self.adapt_method_mode(\n+                adapted_handler = self.adapt_method_mode(\n                     middleware_is_async, handler, handler_is_async,\n                     debug=settings.DEBUG, name='middleware %s' % middleware_path,\n                 )\n-                mw_instance = middleware(handler)\n+                mw_instance = middleware(adapted_handler)\n             except MiddlewareNotUsed as exc:\n                 if settings.DEBUG:\n                     if str(exc):"
  },
  "django__django-11179": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-11179",
    "model_patch": "diff --git a/django/db/models/deletion.py b/django/db/models/deletion.py\nindex 92fe4affb9..74ff11cddb 100644\n--- a/django/db/models/deletion.py\n+++ b/django/db/models/deletion.py\n@@ -261,20 +261,21 @@ class Collector:\n \n     def delete(self):\n         # sort instance collections\n-        for model, instances in self.data.items():\n-            self.data[model] = sorted(instances, key=attrgetter(\"pk\"))\n-\n-        # if possible, bring the models in an order suitable for databases that\n-        # don't support transactions or cannot defer constraint checks until the\n-        # end of a transaction.\n-        self.sort()\n-        # number of objects deleted for each model label\n-        deleted_counter = Counter()\n-\n-        # Optimize for the case with a single obj and no dependencies\n-        if len(self.data) == 1 and len(instances) == 1:\n-            instance = list(instances)[0]\n-            if self.can_fast_delete(instance):\n+# if possible, bring the models in an order suitable for databases that\n+          # don't support transactions or cannot defer constraint checks until the\n+          # end of a transaction.\n+          self.sort()\n+          # number of objects deleted for each model label\n+          deleted_counter = Counter()\n+        \n+          # Optimize for the case with a single obj and no dependencies\n+          if len(self.data) == 1 and len(instances) == 1:\n+              instance = list(instances)[0]\n+              if self.can_fast_delete(instance):\n+                  with transaction.mark_for_rollback_on_error():\n+                      count = sql.DeleteQuery(model).delete_batch([instance.pk], self.using)\n+                  setattr(instance, model._meta.pk.attname, None)\n+                  return count, {model._meta.label: count}\n                 with transaction.mark_for_rollback_on_error():\n                     count = sql.DeleteQuery(model).delete_batch([instance.pk], self.using)\n                 return count, {model._meta.label: count}"
  },
  "psf__requests-1921": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "psf__requests-1921",
    "model_patch": "diff --git a/requests/sessions.py b/requests/sessions.py\nindex a023e4e..1c6c59c 100644\n--- a/requests/sessions.py\n+++ b/requests/sessions.py\n@@ -21,16 +21,6 @@ from .utils import to_key_val_list, default_headers, to_native_string\n from .exceptions import TooManyRedirects, InvalidSchema\n from .structures import CaseInsensitiveDict\n \n-from .adapters import HTTPAdapter\n-\n-from .utils import requote_uri, get_environ_proxies, get_netrc_auth\n-\n-from .status_codes import codes\n-\n-# formerly defined here, reexposed here for backward compatibility\n-from .models import REDIRECT_STATI\n-\n-\n def merge_setting(request_setting, session_setting, dict_class=OrderedDict):\n     \"\"\"\n     Determines appropriate setting for a given request, taking into account the\n@@ -42,12 +32,24 @@ def merge_setting(request_setting, session_setting, dict_class=OrderedDict):\n         return request_setting\n \n     if request_setting is None:\n+        # If the request did not provide a setting, return the session setting\n+        # but remove any keys explicitly set to None on the session (treat None\n+        # as \"delete this default\").\n+        if isinstance(session_setting, Mapping):\n+            cleaned = dict_class(to_key_val_list(session_setting))\n+            for (k, v) in list(session_setting.items()):\n+                if v is None and k in cleaned:\n+                    del cleaned[k]\n+            return cleaned\n         return session_setting\n \n     # Bypass if not a dictionary (e.g. verify)\n     if not (\n             isinstance(session_setting, Mapping) and\n             isinstance(request_setting, Mapping)\n+    ):\n+            isinstance(session_setting, Mapping) and\n+            isinstance(request_setting, Mapping)\n     ):\n         return request_setting"
  },
  "pytest-dev__pytest-7490": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "pytest-dev__pytest-7490",
    "model_patch": "diff --git a/src/_pytest/skipping.py b/src/_pytest/skipping.py\nindex 335e10996..814f92cd7 100644\n--- a/src/_pytest/skipping.py\n+++ b/src/_pytest/skipping.py\n@@ -209,40 +209,45 @@ def evaluate_xfail_marks(item: Item) -> Optional[Xfail]:\n             conditions = (mark.kwargs[\"condition\"],)\n \n         # Unconditional.\n-        if not conditions:\n-            reason = mark.kwargs.get(\"reason\", \"\")\n-            return Xfail(reason, run, strict, raises)\n-\n-        # If any of the conditions are true.\n-        for condition in conditions:\n-            result, reason = evaluate_condition(item, mark, condition)\n-            if result:\n-                return Xfail(reason, run, strict, raises)\n-\n-    return None\n-\n-\n-# Whether skipped due to skip or skipif marks.\n-skipped_by_mark_key = StoreKey[bool]()\n-# Saves the xfail mark evaluation. Can be refreshed during call if None.\n-xfailed_key = StoreKey[Optional[Xfail]]()\n-unexpectedsuccess_key = StoreKey[str]()\n-\n-\n-@hookimpl(tryfirst=True)\n-def pytest_runtest_setup(item: Item) -> None:\n-    item._store[skipped_by_mark_key] = False\n-\n-    skipped = evaluate_skip_marks(item)\n-    if skipped:\n-        item._store[skipped_by_mark_key] = True\n-        skip(skipped.reason)\n-\n-    if not item.config.option.runxfail:\n+@hookimpl(hookwrapper=True)\n+def pytest_runtest_makereport(item: Item, call: CallInfo[None]):\n+    outcome = yield\n+    rep = outcome.get_result()\n+    # Refresh xfail evaluation if it wasn't cached so that marks added\n+    # during the call (e.g. via request.node.add_marker) are honored.\n+    xfailed = item._store.get(xfailed_key, None)\n+    if xfailed is None:\n         item._store[xfailed_key] = xfailed = evaluate_xfail_marks(item)\n-        if xfailed and not xfailed.run:\n-            xfail(\"[NOTRUN] \" + xfailed.reason)\n \n+    # unittest special case, see setting of unexpectedsuccess_key\n+    if unexpectedsuccess_key in item._store and rep.when == \"call\":\n+        reason = item._store[unexpectedsuccess_key]\n+        if reason:\n+            rep.longrepr = \"Unexpected success: {}\".format(reason)\n+        else:\n+            rep.longrepr = \"Unexpected success\"\n+        rep.outcome = \"failed\"\n+    elif item.config.option.runxfail:\n+        pass  # don't interfere\n+    elif call.excinfo and isinstance(call.excinfo.value, xfail.Exception):\n+        assert call.excinfo.value.msg is not None\n+        rep.wasxfail = \"reason: \" + call.excinfo.value.msg\n+        rep.outcome = \"skipped\"\n+    elif not rep.skipped and xfailed:\n+        if call.excinfo:\n+            raises = xfailed.raises\n+            if raises is not None and not isinstance(call.excinfo.value, raises):\n+                rep.outcome = \"failed\"\n+            else:\n+                rep.outcome = \"skipped\"\n+                rep.wasxfail = xfailed.reason\n+        elif call.when == \"call\":\n+            if xfailed.strict:\n+                rep.outcome = \"failed\"\n+                rep.longrepr = \"[XPASS(strict)] \" + xfailed.reason\n+            else:\n+                rep.outcome = \"passed\"\n+                rep.wasxfail = xfailed.reason\n \n @hookimpl(hookwrapper=True)\n def pytest_runtest_call(item: Item) -> Generator[None, None, None]:"
  },
  "scikit-learn__scikit-learn-26323": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "scikit-learn__scikit-learn-26323",
    "model_patch": "diff --git a/sklearn/compose/_column_transformer.py b/sklearn/compose/_column_transformer.py\nindex 4eddd12b1..1008163d2 100644\n--- a/sklearn/compose/_column_transformer.py\n+++ b/sklearn/compose/_column_transformer.py\n@@ -232,49 +232,45 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n \n     def __init__(\n         self,\n-        transformers,\n-        *,\n-        remainder=\"drop\",\n-        sparse_threshold=0.3,\n-        n_jobs=None,\n-        transformer_weights=None,\n-        verbose=False,\n-        verbose_feature_names_out=True,\n-    ):\n-        self.transformers = transformers\n-        self.remainder = remainder\n-        self.sparse_threshold = sparse_threshold\n-        self.n_jobs = n_jobs\n-        self.transformer_weights = transformer_weights\n-        self.verbose = verbose\n-        self.verbose_feature_names_out = verbose_feature_names_out\n+def set_output(self, *, transform=None):\n+        \"\"\"Set the output container when `\"transform\"` and `\"fit_transform\"` are called.\n \n-    @property\n-    def _transformers(self):\n-        \"\"\"\n-        Internal list of transformer only containing the name and\n-        transformers, dropping the columns. This is for the implementation\n-        of get_params via BaseComposition._get_params which expects lists\n-        of tuples of len 2.\n-        \"\"\"\n-        try:\n-            return [(name, trans) for name, trans, _ in self.transformers]\n-        except (TypeError, ValueError):\n-            return self.transformers\n+        Calling `set_output` will set the output of all estimators in `transformers`\n+        and `transformers_`.\n \n-    @_transformers.setter\n-    def _transformers(self, value):\n-        try:\n-            self.transformers = [\n-                (name, trans, col)\n-                for ((name, trans), (_, _, col)) in zip(value, self.transformers)\n-            ]\n-        except (TypeError, ValueError):\n-            self.transformers = value\n+        Parameters\n+        ----------\n+        transform : {\"default\", \"pandas\"}, default=None\n+            Configure output of `transform` and `fit_transform`.\n \n-    def set_output(self, *, transform=None):\n-        \"\"\"Set the output container when `\"transform\"` and `\"fit_transform\"` are called.\n+            - `\"default\"`: Default output format of a transformer\n+            - `\"pandas\"`: DataFrame output\n+            - `None`: Transform configuration is unchanged\n \n+        Returns\n+        -------\n+        self : estimator instance\n+            Estimator instance.\n+        \"\"\"\n+        super().set_output(transform=transform)\n+        transformers = (\n+            trans\n+            for _, trans, _ in chain(\n+                self.transformers, getattr(self, \"transformers_\", [])\n+            )\n+            if trans not in {\"passthrough\", \"drop\"}\n+        )\n+        for trans in transformers:\n+            _safe_set_output(trans, transform=transform)\n+\n+        # Ensure the remainder estimator (if present and not \"drop\"/\"passthrough\")\n+        # also has its output configured. The remainder may be provided as the\n+        # `remainder` attribute and thus not present in `self.transformers`.\n+        remainder = getattr(self, \"remainder\", None)\n+        if remainder is not None and remainder not in {\"passthrough\", \"drop\"}:\n+            _safe_set_output(remainder, transform=transform)\n+\n+        return self\n         Calling `set_output` will set the output of all estimators in `transformers`\n         and `transformers_`.\n \n@@ -303,6 +299,21 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n         for trans in transformers:\n             _safe_set_output(trans, transform=transform)\n \n+        # Ensure the remainder estimator (if present and not \"drop\"/\"passthrough\")\n+        # also has its output configured. The remainder may be provided as the\n+        # `remainder` attribute and thus not present in `self.transformers`.\n+        remainder = getattr(self, \"remainder\", None)\n+        if remainder is not None and remainder not in {\"passthrough\", \"drop\"}:\n+            _safe_set_output(remainder, transform=transform)\n+\n+        return self\n+                self.transformers, getattr(self, \"transformers_\", [])\n+            )\n+            if trans not in {\"passthrough\", \"drop\"}\n+        )\n+        for trans in transformers:\n+            _safe_set_output(trans, transform=transform)\n+\n         return self\n \n     def get_params(self, deep=True):"
  },
  "sympy__sympy-17655": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "sympy__sympy-17655",
    "model_patch": "diff --git a/sympy/geometry/point.py b/sympy/geometry/point.py\nindex 7c978c47be..e44dab6c95 100644\n--- a/sympy/geometry/point.py\n+++ b/sympy/geometry/point.py\n@@ -145,34 +145,65 @@ def __new__(cls, *args, **kwargs):\n                 raise ValueError(message)\n             elif on_morph == 'warn':\n                 warnings.warn(message)\n-            else:\n-                raise ValueError(filldedent('''\n-                        on_morph value should be 'error',\n-                        'warn' or 'ignore'.'''))\n-        if any(coords[dim:]):\n-            raise ValueError('Nonzero coordinates cannot be removed.')\n-        if any(a.is_number and im(a) for a in coords):\n-            raise ValueError('Imaginary coordinates are not permitted.')\n-        if not all(isinstance(a, Expr) for a in coords):\n-            raise TypeError('Coordinates must be valid SymPy expressions.')\n-\n-        # pad with zeros appropriately\n-        coords = coords[:dim] + (S.Zero,)*(dim - len(coords))\n-\n-        # Turn any Floats into rationals and simplify\n-        # any expressions before we instantiate\n-        if evaluate:\n-            coords = coords.xreplace(dict(\n-                [(f, simplify(nsimplify(f, rational=True)))\n-                 for f in coords.atoms(Float)]))\n-\n-        # return 2D or 3D instances\n-        if len(coords) == 2:\n-            kwargs['_nocheck'] = True\n-            return Point2D(*coords, **kwargs)\n-        elif len(coords) == 3:\n-            kwargs['_nocheck'] = True\n-            return Point3D(*coords, **kwargs)\n+def __add__(self, other):\n+        \"\"\"Add other to self by incrementing self's coordinates by\n+        those of other.\n+\n+        Notes\n+        =====\n+\n+        >>> from sympy.geometry.point import Point\n+\n+        When sequences of coordinates are passed to Point methods, they\n+        are converted to a Point internally. This __add__ method does\n+        not do that so if floating point values are used, a floating\n+        point result (in terms of SymPy Floats) will be returned.\n+\n+        >>> Point(1, 2) + (.1, .2)\n+        Point2D(1.1, 2.2)\n+\n+        If this is not desired, the `translate` method can be used or\n+        another Point can be added:\n+\n+        >>> Point(1, 2).translate(.1, .2)\n+        Point2D(11/10, 11/5)\n+        >>> Point(1, 2) + Point(.1, .2)\n+        Point2D(11/10, 11/5)\n+\n+        See Also\n+        ========\n+\n+        sympy.geometry.point.Point.translate\n+\n+        \"\"\"\n+        # Handle cases like scalar * Point (e.g., 2*Point(1,1)) by extracting\n+        # the Point factor and scaling it so Point(...) below receives a Point\n+        # or a sequence of coordinates rather than a Mul.\n+        if isinstance(other, Expr) and getattr(other, 'is_Mul', False):\n+            point_arg = None\n+            # find the first Point in the Mul args\n+            for a in other.args:\n+                if isinstance(a, Point):\n+                    point_arg = a\n+                    break\n+            if point_arg is not None:\n+                scalar = sympify(1)\n+                found = False\n+                for a in other.args:\n+                    if isinstance(a, Point) and not found:\n+                        # skip the first Point factor\n+                        found = True\n+                        continue\n+                    scalar = scalar * a\n+                other = point_arg * scalar\n+\n+        try:\n+            s, o = Point._normalize_dimension(self, Point(other, evaluate=False))\n+        except TypeError:\n+            raise GeometryError(\"Don't know how to add {} and a Point object\".format(other))\n+\n+        coords = [simplify(a + b) for a, b in zip(s, o)]\n+        return Point(coords, evaluate=False)\n \n         # the general Point\n         return GeometryEntity.__new__(cls, *coords)"
  },
  "psf__requests-2931": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "psf__requests-2931",
    "model_patch": "diff --git a/requests/utils.py b/requests/utils.py\nindex 132cd2b..07c9136 100644\n--- a/requests/utils.py\n+++ b/requests/utils.py\n@@ -664,12 +664,6 @@ def prepend_scheme_if_needed(url, new_scheme):\n     # urlparse is a finicky beast, and sometimes decides that there isn't a\n     # netloc present. Assume that it's being over-cautious, and switch netloc\n     # and path if urlparse decided there was no netloc.\n-    if not netloc:\n-        netloc, path = path, netloc\n-\n-    return urlunparse((scheme, netloc, path, params, query, fragment))\n-\n-\n def get_auth_from_url(url):\n     \"\"\"Given a url with authentication components, extract them into a tuple of\n     username,password.\"\"\"\n@@ -691,6 +685,25 @@ def to_native_string(string, encoding='ascii'):\n     \"\"\"\n     out = None\n \n+    if isinstance(string, builtin_str):\n+        out = string\n+    else:\n+        if is_py2:\n+            out = string.encode(encoding)\n+        else:\n+            # On Python 3, if we receive bytes try decoding using the requested\n+            # encoding first; if that fails (e.g., non-ASCII bytes), fall back\n+            # to UTF-8 with replacement to avoid raising UnicodeDecodeError.\n+            if isinstance(string, bytes):\n+                try:\n+                    out = string.decode(encoding)\n+                except UnicodeDecodeError:\n+                    out = string.decode('utf-8', 'replace')\n+            else:\n+                out = string.decode(encoding)\n+\n+    return out\n+\n     if isinstance(string, builtin_str):\n         out = string\n     else:"
  },
  "django__django-14011": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-14011",
    "model_patch": "diff --git a/django/core/servers/basehttp.py b/django/core/servers/basehttp.py\nindex 14dab517c9..1e5d1fb748 100644\n--- a/django/core/servers/basehttp.py\n+++ b/django/core/servers/basehttp.py\n@@ -1,4 +1,4 @@\n-\"\"\"\n+\"\"\" \n HTTP server that implements the Python WSGI protocol (PEP 333, rev 1.21).\n \n Based on wsgiref.simple_server which is part of the standard library since 2.5.\n@@ -17,6 +17,7 @@ from django.core.exceptions import ImproperlyConfigured\n from django.core.handlers.wsgi import LimitedStream\n from django.core.wsgi import get_wsgi_application\n from django.utils.module_loading import import_string\n+from django.db import close_old_connections\n \n __all__ = ('WSGIServer', 'WSGIRequestHandler')\n \n@@ -116,7 +117,10 @@ class ServerHandler(simple_server.ServerHandler):\n     def close(self):\n         self.get_stdin()._read_limited()\n         super().close()\n-\n+        # Ensure DB connections are cleaned up at the end of handling the request.\n+        # This mirrors the request_finished handling that isn't necessarily\n+        # triggered for requests handled by this low-level server in threaded mode.\n+        close_old_connections()\n \n class WSGIRequestHandler(simple_server.WSGIRequestHandler):\n     protocol_version = 'HTTP/1.1'\n@@ -196,6 +200,46 @@ class WSGIRequestHandler(simple_server.WSGIRequestHandler):\n         handler.run(self.server.get_app())\n \n \n+def run(addr, port, wsgi_handler, ipv6=False, threading=False, server_cls=WSGIServer):\n+    server_address = (addr, port)\n+    if threading:\n+        httpd_cls = type('WSGIServer', (socketserver.ThreadingMixIn, server_cls), {})\n+    else:\n+        httpd_cls = server_cls\n+    httpd = httpd_cls(server_address, WSGIRequestHandler, ipv6=ipv6)\n+    if threading:\n+        # ThreadingMixIn.daemon_threads indicates how threads will behave on an\n+        # abrupt shutdown; like quitting the server by the user or restarting\n+        # by the auto-reloader. True means the server will not wait for thread\n+        # termination before it quits. This will make auto-reloader faster\n+        # and will prevent the need to kill the server manually if a thread\n+        # isn't terminating correctly.\n+        httpd.daemon_threads = True\n+    httpd.set_app(wsgi_handler)\n+    httpd.serve_forever()\n+        except (AttributeError, OSError):\n+            pass\n+\n+    def handle_one_request(self):\n+        \"\"\"Copy of WSGIRequestHandler.handle() but with different ServerHandler\"\"\"\n+        self.raw_requestline = self.rfile.readline(65537)\n+        if len(self.raw_requestline) > 65536:\n+            self.requestline = ''\n+            self.request_version = ''\n+            self.command = ''\n+            self.send_error(414)\n+            return\n+\n+        if not self.parse_request():  # An error code has been sent, just exit\n+            return\n+\n+        handler = ServerHandler(\n+            self.rfile, self.wfile, self.get_stderr(), self.get_environ()\n+        )\n+        handler.request_handler = self      # backpointer for logging & connection closing\n+        handler.run(self.server.get_app())\n+\n+\n def run(addr, port, wsgi_handler, ipv6=False, threading=False, server_cls=WSGIServer):\n     server_address = (addr, port)\n     if threading:"
  },
  "sphinx-doc__sphinx-9658": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-9658",
    "model_patch": "diff --git a/sphinx/util/typing.py b/sphinx/util/typing.py\nindex 87707d48f..bd8c3e7aa 100644\n--- a/sphinx/util/typing.py\n+++ b/sphinx/util/typing.py\n@@ -155,21 +155,27 @@ def _restify_py37(cls: Optional[Type]) -> str:\n             cls.__module__ == 'typing' and cls.__origin__ is Union):\n         # Union\n         if len(cls.__args__) > 1 and cls.__args__[-1] is NoneType:\n-            if len(cls.__args__) > 2:\n-                args = ', '.join(restify(a) for a in cls.__args__[:-1])\n-                return ':py:obj:`~typing.Optional`\\\\ [:obj:`~typing.Union`\\\\ [%s]]' % args\n-            else:\n-                return ':py:obj:`~typing.Optional`\\\\ [%s]' % restify(cls.__args__[0])\n+elif isinstance(cls, typing._SpecialForm):\n+        return ':py:obj:`~%s.%s`' % (cls.__module__, cls._name)\n+    elif hasattr(cls, '__qualname__'):\n+        qual = getattr(cls, '__qualname__', None) or getattr(cls, '__name__', None)\n+        if not qual:\n+            return repr(cls)\n+        if cls.__module__ == 'typing':\n+            return ':py:class:`~%s.%s`' % (cls.__module__, qual)\n         else:\n-            args = ', '.join(restify(a) for a in cls.__args__)\n-            return ':py:obj:`~typing.Union`\\\\ [%s]' % args\n-    elif inspect.isgenericalias(cls):\n-        if isinstance(cls.__origin__, typing._SpecialForm):\n-            text = restify(cls.__origin__)  # type: ignore\n-        elif getattr(cls, '_name', None):\n-            if cls.__module__ == 'typing':\n-                text = ':py:class:`~%s.%s`' % (cls.__module__, cls._name)\n-            else:\n+            return ':py:class:`%s.%s`' % (cls.__module__, qual)\n+    elif isinstance(cls, ForwardRef):\n+        return ':py:class:`%s`' % cls.__forward_arg__\n+    else:\n+        # not a class (ex. TypeVar)\n+        name = getattr(cls, '__name__', None)\n+        if not name:\n+            return repr(cls)\n+        if cls.__module__ == 'typing':\n+            return ':py:obj:`~%s.%s`' % (cls.__module__, name)\n+        else:\n+            return ':py:obj:`%s.%s`' % (cls.__module__, name)\n                 text = ':py:class:`%s.%s`' % (cls.__module__, cls._name)\n         else:\n             text = restify(cls.__origin__)"
  },
  "astropy__astropy-7166": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "astropy__astropy-7166",
    "model_patch": "diff --git a/astropy/utils/misc.py b/astropy/utils/misc.py\nindex de3fb01d1..8a1d26907 100644\n--- a/astropy/utils/misc.py\n+++ b/astropy/utils/misc.py\n@@ -491,9 +491,6 @@ def did_you_mean(s, candidates, n=3, cutoff=0.8, fix=None):\n                        matches[-1])\n         return 'Did you mean {0}?'.format(matches)\n \n-    return ''\n-\n-\n class InheritDocstrings(type):\n     \"\"\"\n     This metaclass makes methods of a class automatically have their\n@@ -527,6 +524,38 @@ class InheritDocstrings(type):\n                  and len(key) > 4) or\n                 not key.startswith('_'))\n \n+        for key, val in dct.items():\n+            if (is_public_member(key) and getattr(val, '__doc__', None) is None):\n+                # Determine the target function object that should receive the\n+                # inherited docstring. For plain functions this is the function\n+                # itself; for properties use the fget; for classmethod/staticmethod\n+                # use the underlying __func__.\n+                target = None\n+                if inspect.isfunction(val):\n+                    target = val\n+                elif isinstance(val, property):\n+                    target = val.fget\n+                elif isinstance(val, (classmethod, staticmethod)):\n+                    target = val.__func__\n+                if target is None:\n+                    continue\n+\n+                for base in cls.__mro__[1:]:\n+                    super_method = getattr(base, key, None)\n+                    if super_method is not None:\n+                        # Prefer the descriptor's __doc__, but fall back to\n+                        # underlying function docstrings for descriptors.\n+                        doc = getattr(super_method, '__doc__', None)\n+                        if doc is None:\n+                            if isinstance(super_method, property) and super_method.fget is not None:\n+                                doc = super_method.fget.__doc__\n+                            elif isinstance(super_method, (classmethod, staticmethod)) and getattr(super_method, '__func__', None) is not None:\n+                                doc = super_method.__func__.__doc__\n+                        if doc:\n+                            target.__doc__ = doc\n+                            break\n+\n+        super().__init__(name, bases, dct)\n         for key, val in dct.items():\n             if (inspect.isfunction(val) and\n                 is_public_member(key) and"
  },
  "django__django-14053": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-14053",
    "model_patch": "diff --git a/django/contrib/staticfiles/storage.py b/django/contrib/staticfiles/storage.py\nindex 494890cc23..cd479efca9 100644\n--- a/django/contrib/staticfiles/storage.py\n+++ b/django/contrib/staticfiles/storage.py\n@@ -164,59 +164,68 @@ class HashedFilesMixin:\n \n             # Ignore absolute/protocol-relative and data-uri URLs.\n             if re.match(r'^[a-z]+:', url):\n-                return matched\n-\n-            # Ignore absolute URLs that don't point to a static file (dynamic\n-            # CSS / JS?). Note that STATIC_URL cannot be empty.\n-            if url.startswith('/') and not url.startswith(settings.STATIC_URL):\n-                return matched\n-\n-            # Strip off the fragment so a path-like fragment won't interfere.\n-            url_path, fragment = urldefrag(url)\n-\n-            if url_path.startswith('/'):\n-                # Otherwise the condition above would have returned prematurely.\n-                assert url_path.startswith(settings.STATIC_URL)\n-                target_name = url_path[len(settings.STATIC_URL):]\n-            else:\n-                # We're using the posixpath module to mix paths and URLs conveniently.\n-                source_name = name if os.sep == '/' else name.replace(os.sep, '/')\n-                target_name = posixpath.join(posixpath.dirname(source_name), url_path)\n-\n-            # Determine the hashed name of the target file with the storage backend.\n-            hashed_url = self._url(\n-                self._stored_name, unquote(target_name),\n-                force=True, hashed_files=hashed_files,\n-            )\n-\n-            transformed_url = '/'.join(url_path.split('/')[:-1] + hashed_url.split('/')[-1:])\n-\n+transformed_url = '/'.join(url_path.split('/')[:-1] + hashed_url.split('/')[-1:])\n             # Restore the fragment that was stripped off earlier.\n             if fragment:\n                 transformed_url += ('?#' if '?#' in url else '#') + fragment\n-\n             # Return the hashed version to the file\n             return template % unquote(transformed_url)\n-\n+        \n         return converter\n-\n+        \n     def post_process(self, paths, dry_run=False, **options):\n         \"\"\"\n         Post process the given dictionary of files (called from collectstatic).\n-\n+        \n         Processing is actually two separate operations:\n-\n+        \n         1. renaming files to include a hash of their content for cache-busting,\n            and copying those files to the target storage.\n         2. adjusting files which contain references to other files so they\n            refer to the cache-busting filenames.\n-\n+        \n         If either of these are performed on a file, then that file is considered\n         post-processed.\n         \"\"\"\n         # don't even dare to process the files if we're in dry run mode\n         if dry_run:\n             return\n+        \n+        # where to store the new paths\n+        hashed_files = {}\n+        yielded_names = set()\n+        \n+        # build a list of adjustable files\n+        adjustable_paths = [\n+            path for path in paths\n+            if matches_patterns(path, self._patterns)\n+        ]\n+        # Do a single pass first. Post-process all files once, then repeat for\n+        # adjustable files.\n+        for name, hashed_name, processed, _ in self._post_process(paths, adjustable_paths, hashed_files):\n+            if name not in yielded_names:\n+                yield name, hashed_name, processed\n+                yielded_names.add(name)\n+        \n+        paths = {path: paths[path] for path in adjustable_paths}\n+        \n+        for i in range(self.max_post_process_passes):\n+            substitutions = False\n+            for name, hashed_name, processed, subst in self._post_process(paths, adjustable_paths, hashed_files):\n+                if name not in yielded_names:\n+                    yield name, hashed_name, processed\n+                    yielded_names.add(name)\n+                substitutions = substitutions or subst\n+        \n+            if not substitutions:\n+                break\n+        \n+        if substitutions:\n+            yield 'All', None, RuntimeError('Max post-process passes exceeded.')\n+        \n+        # Store the processed paths\n+        self.hashed_files.update(hashed_files)\n+            return\n \n         # where to store the new paths\n         hashed_files = {}"
  },
  "django__django-7530": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-7530",
    "model_patch": "diff --git a/django/core/management/commands/makemigrations.py b/django/core/management/commands/makemigrations.py\nindex 0b39536f5b..ec7d449279 100644\n--- a/django/core/management/commands/makemigrations.py\n+++ b/django/core/management/commands/makemigrations.py\n@@ -92,9 +92,8 @@ class Command(BaseCommand):\n             sys.exit(2)\n \n         # Load the current graph state. Pass in None for the connection so\n-        # the loader doesn't try to resolve replaced migrations from DB.\n-        loader = MigrationLoader(None, ignore_no_migrations=True)\n-\n+loader = MigrationLoader(None, ignore_no_migrations=True)\n+        \n         # Raise an error if any migrations are applied before their dependencies.\n         consistency_check_labels = set(config.label for config in apps.get_app_configs())\n         # Non-default databases are only checked if database routers used.\n@@ -105,7 +104,7 @@ class Command(BaseCommand):\n                     # At least one model must be migrated to the database.\n                     router.allow_migrate(connection.alias, app_label, model_name=model._meta.object_name)\n                     for app_label in consistency_check_labels\n-                    for model in apps.get_models(app_label)\n+                    for model in apps.get_app_config(app_label).get_models()\n             )):\n                 loader.check_consistent_history(connection)"
  },
  "django__django-13297": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-13297",
    "model_patch": "diff --git a/django/views/generic/base.py b/django/views/generic/base.py\nindex ea5baca08d..1e6d201fef 100644\n--- a/django/views/generic/base.py\n+++ b/django/views/generic/base.py\n@@ -11,11 +11,8 @@ from django.template.response import TemplateResponse\n from django.urls import reverse\n from django.utils.decorators import classonlymethod\n from django.utils.deprecation import RemovedInDjango40Warning\n-from django.utils.functional import SimpleLazyObject\n-\n logger = logging.getLogger('django.request')\n \n-\n class ContextMixin:\n     \"\"\"\n     A default context mixin that passes the keyword arguments received by\n@@ -27,6 +24,23 @@ class ContextMixin:\n         kwargs.setdefault('view', self)\n         if self.extra_context is not None:\n             kwargs.update(self.extra_context)\n+        # Resolve SimpleLazyObject values in kwargs so downstream users (e.g. ORM filters)\n+        # receive the underlying objects instead of lazy proxies which may cause errors.\n+        for key, value in list(kwargs.items()):\n+            if isinstance(value, SimpleLazyObject):\n+                try:\n+                    # Force evaluation of the lazy object.\n+                    value._setup()\n+                except Exception:\n+                    # If _setup() fails or is already evaluated, ignore and fall back.\n+                    pass\n+                try:\n+                    kwargs[key] = value._wrapped\n+                except Exception:\n+                    # As a last resort, leave the original lazy object in place.\n+                    kwargs[key] = value\n+        return kwargs\n+            kwargs.update(self.extra_context)\n         return kwargs"
  },
  "django__django-16631": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-16631",
    "model_patch": "diff --git a/docs/ref/settings.txt b/docs/ref/settings.txt\nindex 41387886c0..1e10efcc40 100644\n--- a/docs/ref/settings.txt\n+++ b/docs/ref/settings.txt\n@@ -2265,23 +2265,75 @@ Django will refuse to start if :setting:`SECRET_KEY` is not set.\n     Running Django with a known :setting:`SECRET_KEY` defeats many of Django's\n     security protections, and can lead to privilege escalation and remote code\n     execution vulnerabilities.\n-\n-The secret key is used for:\n-\n-* All :doc:`sessions </topics/http/sessions>` if you are using\n-  any other session backend than ``django.contrib.sessions.backends.cache``,\n-  or are using the default\n-  :meth:`~django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash()`.\n-* All :doc:`messages </ref/contrib/messages>` if you are using\n-  :class:`~django.contrib.messages.storage.cookie.CookieStorage` or\n-  :class:`~django.contrib.messages.storage.fallback.FallbackStorage`.\n-* All :class:`~django.contrib.auth.views.PasswordResetView` tokens.\n-* Any usage of :doc:`cryptographic signing </topics/signing>`, unless a\n-  different key is provided.\n-\n-When a secret key is no longer set as :setting:`SECRET_KEY` or contained within\n-:setting:`SECRET_KEY_FALLBACKS` all of the above will be invalidated. When\n-rotating your secret key, you should move the old key to\n+2268  The secret key is used for:\n+        \n+  2269  * All :doc:`sessions </topics/http/sessions>` if you are using\n+  2270    any other session backend than ``django.contrib.sessions.backends.cache``,\n+  2271    or are using the default\n+  2272    :meth:`~django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash()`.\n+  2273  * All :doc:`messages </ref/contrib/messages>` if you are using\n+  2274    :class:`~django.contrib.messages.storage.cookie.CookieStorage` or\n+  2275    :class:`~django.contrib.messages.storage.fallback.FallbackStorage`.\n+  2276  * All :class:`~django.contrib.auth.views.PasswordResetView` tokens.\n+  2277  * Any usage of :doc:`cryptographic signing </topics/signing>`, unless a\n+  2278    different key is provided.\n+        \n+  2279  When a secret key is no longer set as :setting:`SECRET_KEY` or contained within\n+  2280  :setting:`SECRET_KEY_FALLBACKS` all of the above will be invalidated. When\n+  2281  rotating your secret key, you should move the old key to\n+  2282  :setting:`SECRET_KEY_FALLBACKS` temporarily. Secret keys are not used for\n+  2283  passwords of users and key rotation will not affect them.\n+  2284  \n+  2285  .. note::\n+  2286  \n+  2287      The default :file:`settings.py` file created by :djadmin:`django-admin\n+  2288      startproject <startproject>` creates a unique ``SECRET_KEY`` for\n+  2289      convenience.\n+        \n+  2290  .. setting:: SECRET_KEY_FALLBACKS\n+        \n+  2291  ``SECRET_KEY_FALLBACKS``\n+  2292  ------------------------\n+        \n+  2293  Default: ``[]``\n+        \n+  2294  A list of fallback secret keys for a particular Django installation. These are\n+  2295  used to allow rotation of the ``SECRET_KEY``.\n+        \n+  2296  In order to rotate your secret keys, set a new ``SECRET_KEY`` and move the\n+  2297  previous value to the beginning of ``SECRET_KEY_FALLBACKS``. Then remove the\n+  2298  old values from the end of the ``SECRET_KEY_FALLBACKS`` when you are ready to\n+  2299  expire the sessions, password reset tokens, and so on, that make use of them.\n+        \n+  2300  .. note::\n+        \n+  2301      Signing operations are computationally expensive. Having multiple old key\n+  2302      values in ``SECRET_KEY_FALLBACKS`` adds additional overhead to all checks\n+  2303      that don't match an earlier key.\n+        \n+  2304  A note about rotation and fallbacks\n+  2305  ------------------------------\n+  2306  \n+  2307  The signing framework (``django.core.signing`` and classes that use it,\n+  2308  such as cookie signers returned by :func:`django.core.signing.get_cookie_signer`)\n+  2309  supports ``SECRET_KEY_FALLBACKS``: Signer instances will try the current\n+  2310  :setting:`SECRET_KEY` and then any keys listed in ``SECRET_KEY_FALLBACKS`` when\n+  2311  validating signatures. However, not all code that derives HMACs consults\n+  2312  ``SECRET_KEY_FALLBACKS``. Some utilities (for example\n+  2313  :meth:`~django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash`)\n+  2314  call :func:`django.utils.crypto.salted_hmac` without providing an explicit\n+  2315  ``secret`` argument; ``salted_hmac`` defaults to using\n+  2316  :setting:`SECRET_KEY` only and therefore will not try fallback keys. As a\n+  2317  result, rotating the ``SECRET_KEY`` can still invalidate values produced by\n+  2318  such code even if the old key is present in ``SECRET_KEY_FALLBACKS``.\n+  2319  \n+  2320  For safe key rotation in multi-instance deployments, consider a phased rollout:\n+  2321  set the new ``SECRET_KEY`` on some instances while keeping the old key as\n+  2322  the current ``SECRET_KEY`` on others, or ensure any components that compute\n+  2323  HMACs directly (not via the signing framework) are updated to accept explicit\n+  2324  secrets or otherwise coordinate the rotation. Remove old keys from\n+  2325  ``SECRET_KEY_FALLBACKS`` once you are confident the values signed with them\n+  2326  have expired.\n :setting:`SECRET_KEY_FALLBACKS` temporarily. Secret keys are not used for\n passwords of users and key rotation will not affect them."
  },
  "django__django-12406": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-12406",
    "model_patch": "diff --git a/django/forms/widgets.py b/django/forms/widgets.py\nindex 40ac1d3162..109957d88f 100644\n--- a/django/forms/widgets.py\n+++ b/django/forms/widgets.py\n@@ -743,15 +743,22 @@ class SelectMultiple(Select):\n \n     def value_from_datadict(self, data, files, name):\n         try:\n-            getter = data.getlist\n-        except AttributeError:\n-            getter = data.get\n-        return getter(name)\n+class RadioSelect(ChoiceWidget):\n+    input_type = 'radio'\n+    template_name = 'django/forms/widgets/radio.html'\n+    option_template_name = 'django/forms/widgets/radio_option.html'\n \n-    def value_omitted_from_data(self, data, files, name):\n-        # An unselected <select multiple> doesn't appear in POST data, so it's\n-        # never known if the value is actually omitted.\n-        return False\n+    def format_value(self, value):\n+        \"\"\"\n+        For radio widgets, treat an uninitialized value (None) as no selection\n+        so that an empty choice isn't rendered as a checked radio by default.\n+        \"\"\"\n+        if value is None:\n+            return []\n+        return super().format_value(value)\n+\n+            return []\n+        return super().format_value(value)\n \n \n class RadioSelect(ChoiceWidget):"
  },
  "sphinx-doc__sphinx-7590": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-7590",
    "model_patch": "diff --git a/sphinx/domains/cpp.py b/sphinx/domains/cpp.py\nindex fe52d881d..919fbcd8d 100644\n--- a/sphinx/domains/cpp.py\n+++ b/sphinx/domains/cpp.py\n@@ -817,62 +817,98 @@ class ASTBooleanLiteral(ASTLiteral):\n         else:\n             return 'L0E'\n \n-    def describe_signature(self, signode: TextElement, mode: str,\n-                           env: \"BuildEnvironment\", symbol: \"Symbol\") -> None:\n-        signode.append(nodes.Text(str(self)))\n+class ASTNumberLiteral(ASTLiteral):\n+      def __init__(self, data: str) -> None:\n+          self.data = data\n \n+      def _stringify(self, transform: StringifyTransform) -> str:\n+          return self.data\n \n-class ASTNumberLiteral(ASTLiteral):\n-    def __init__(self, data: str) -> None:\n-        self.data = data\n+      def get_id(self, version: int) -> str:\n+          return \"L%sE\" % self.data\n \n-    def _stringify(self, transform: StringifyTransform) -> str:\n-        return self.data\n+      def describe_signature(self, signode: TextElement, mode: str,\n+                             env: \"BuildEnvironment\", symbol: \"Symbol\") -> None:\n+          txt = str(self)\n+          signode.append(nodes.Text(txt, txt))\n \n-    def get_id(self, version: int) -> str:\n-        return \"L%sE\" % self.data\n \n-    def describe_signature(self, signode: TextElement, mode: str,\n-                           env: \"BuildEnvironment\", symbol: \"Symbol\") -> None:\n-        txt = str(self)\n-        signode.append(nodes.Text(txt, txt))\n+  class ASTStringLiteral(ASTLiteral):\n+      def __init__(self, data: str) -> None:\n+          self.data = data\n \n+      def _stringify(self, transform: StringifyTransform) -> str:\n+          return self.data\n \n-class ASTStringLiteral(ASTLiteral):\n-    def __init__(self, data: str) -> None:\n-        self.data = data\n+      def get_id(self, version: int) -> str:\n+          # note: the length is not really correct with escaping\n+          return \"LA%d_KcE\" % (len(self.data) - 2)\n \n-    def _stringify(self, transform: StringifyTransform) -> str:\n-        return self.data\n+      def describe_signature(self, signode: TextElement, mode: str,\n+                             env: \"BuildEnvironment\", symbol: \"Symbol\") -> None:\n+          txt = str(self)\n+          signode.append(nodes.Text(txt, txt))\n \n-    def get_id(self, version: int) -> str:\n-        # note: the length is not really correct with escaping\n-        return \"LA%d_KcE\" % (len(self.data) - 2)\n \n-    def describe_signature(self, signode: TextElement, mode: str,\n-                           env: \"BuildEnvironment\", symbol: \"Symbol\") -> None:\n-        txt = str(self)\n-        signode.append(nodes.Text(txt, txt))\n+  class ASTCharLiteral(ASTLiteral):\n+      def __init__(self, prefix: str, data: str) -> None:\n+          self.prefix = prefix  # may be None when no prefix\n+          self.data = data\n+          assert prefix in _id_char_from_prefix\n+          self.type = _id_char_from_prefix[prefix]\n+          decoded = data.encode().decode('unicode-escape')\n+          if len(decoded) == 1:\n+              self.value = ord(decoded)\n+          else:\n+              raise UnsupportedMultiCharacterCharLiteral(decoded)\n \n+      def _stringify(self, transform: StringifyTransform) -> str:\n+          if self.prefix is None:\n+              return \"'\" + self.data + \"'\"\n+          else:\n+              return self.prefix + \"'\" + self.data + \"'\"\n \n-class ASTCharLiteral(ASTLiteral):\n-    def __init__(self, prefix: str, data: str) -> None:\n-        self.prefix = prefix  # may be None when no prefix\n-        self.data = data\n-        assert prefix in _id_char_from_prefix\n-        self.type = _id_char_from_prefix[prefix]\n-        decoded = data.encode().decode('unicode-escape')\n-        if len(decoded) == 1:\n-            self.value = ord(decoded)\n-        else:\n-            raise UnsupportedMultiCharacterCharLiteral(decoded)\n+      def get_id(self, version: int) -> str:\n+          return self.type + str(self.value)\n \n-    def _stringify(self, transform: StringifyTransform) -> str:\n-        if self.prefix is None:\n-            return \"'\" + self.data + \"'\"\n-        else:\n-            return self.prefix + \"'\" + self.data + \"'\"\n+      def describe_signature(self, signode: TextElement, mode: str,\n+                             env: \"BuildEnvironment\", symbol: \"Symbol\") -> None:\n+          txt = str(self)\n+          signode.append(nodes.Text(txt, txt))\n+\n+\n+  class ASTUserDefinedLiteral(ASTLiteral):\n+      def __init__(self, literal: str, suffix: str) -> None:\n+          # literal: the textual literal (number, char, or string) as it appears\n+          # suffix: the user-defined-literal suffix (e.g., _J, _km)\n+          self.literal = literal\n+          self.suffix = suffix\n+\n+      def _stringify(self, transform: StringifyTransform) -> str:\n+          return self.literal + self.suffix\n+\n+      def get_id(self, version: int) -> str:\n+          # produce a compact, deterministic id combining literal and suffix\n+          lit = self.literal.replace(' ', '_')\n+          suf = self.suffix.replace(' ', '_')\n+          return \"L%s_%sE\" % (lit, suf)\n \n+      def describe_signature(self, signode: TextElement, mode: str,\n+                             env: \"BuildEnvironment\", symbol: \"Symbol\") -> None:\n+          txt = str(self)\n+          signode.append(nodes.Text(txt, txt))\n+\n+\n+  class ASTThisLiteral(ASTExpression):\n+      def _stringify(self, transform: StringifyTransform) -> str:\n+          return \"this\"\n+\n+      def get_id(self, version: int) -> str:\n+          return \"fpT\"\n+\n+      def describe_signature(self, signode: TextElement, mode: str,\n+                             env: \"BuildEnvironment\", symbol: \"Symbol\") -> None:\n+          signode.append(nodes.Text(\"this\"))\n     def get_id(self, version: int) -> str:\n         return self.type + str(self.value)\n \n@@ -4617,33 +4653,7 @@ class DefinitionParser(BaseParser):\n         return 'C++'\n \n     @property\n-    def id_attributes(self):\n-        return self.config.cpp_id_attributes\n-\n-    @property\n-    def paren_attributes(self):\n-        return self.config.cpp_paren_attributes\n-\n-    def _parse_string(self) -> str:\n-        if self.current_char != '\"':\n-            return None\n-        startPos = self.pos\n-        self.pos += 1\n-        escape = False\n-        while True:\n-            if self.eof:\n-                self.fail(\"Unexpected end during inside string.\")\n-            elif self.current_char == '\"' and not escape:\n-                self.pos += 1\n-                break\n-            elif self.current_char == '\\\\':\n-                escape = True\n-            else:\n-                escape = False\n-            self.pos += 1\n-        return self.definition[startPos:self.pos]\n-\n-    def _parse_literal(self) -> ASTLiteral:\n+def _parse_literal(self) -> ASTLiteral:\n         # -> integer-literal\n         #  | character-literal\n         #  | floating-literal\n@@ -4662,18 +4672,54 @@ class DefinitionParser(BaseParser):\n                       integer_literal_re, octal_literal_re]:\n             pos = self.pos\n             if self.match(regex):\n+                # consume standard suffix letters like u, l, f\n                 while self.current_char in 'uUlLfF':\n                     self.pos += 1\n-                return ASTNumberLiteral(self.definition[pos:self.pos])\n-\n+                literal_text = self.definition[pos:self.pos]\n+                # check for a user-defined-literal suffix immediately after the literal\n+                if self.current_char is not None and (self.current_char.isalpha() or self.current_char == '_'):\n+                    start = self.pos\n+                    while self.current_char is not None and (self.current_char.isalnum() or self.current_char == '_'):\n+                        self.pos += 1\n+                    suffix = self.definition[start:self.pos]\n+                    return ASTUserDefinedLiteral(literal_text, suffix)\n+                return ASTNumberLiteral(literal_text)\n+    \n         string = self._parse_string()\n         if string is not None:\n+            # check for user-defined-literal suffix immediately after string-literal\n+            if self.current_char is not None and (self.current_char.isalpha() or self.current_char == '_'):\n+                start = self.pos\n+                while self.current_char is not None and (self.current_char.isalnum() or self.current_char == '_'):\n+                    self.pos += 1\n+                suffix = self.definition[start:self.pos]\n+                return ASTUserDefinedLiteral(string, suffix)\n             return ASTStringLiteral(string)\n-\n+    \n         # character-literal\n+        pos = self.pos\n         if self.match(char_literal_re):\n             prefix = self.last_match.group(1)  # may be None when no prefix\n             data = self.last_match.group(2)\n+            literal_text = self.definition[pos:self.pos]\n+            try:\n+                char_node = ASTCharLiteral(prefix, data)\n+            except UnicodeDecodeError as e:\n+                self.fail(\"Can not handle character literal. Internal error was: %s\" % e)\n+            except UnsupportedMultiCharacterCharLiteral:\n+                self.fail(\"Can not handle character literal\"\n+                          \" resulting in multiple decoded characters.\")\n+            # check for UDL suffix immediately after char literal\n+            if self.current_char is not None and (self.current_char.isalpha() or self.current_char == '_'):\n+                start = self.pos\n+                while self.current_char is not None and (self.current_char.isalnum() or self.current_char == '_'):\n+                    self.pos += 1\n+                suffix = self.definition[start:self.pos]\n+                return ASTUserDefinedLiteral(literal_text, suffix)\n+            return char_node\n+    \n+        # no literal found\n+        return None\n             try:\n                 return ASTCharLiteral(prefix, data)\n             except UnicodeDecodeError as e:"
  }
}