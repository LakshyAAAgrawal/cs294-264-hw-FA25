{
  "pytest-dev__pytest-7490": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "pytest-dev__pytest-7490",
    "model_patch": "diff --git a/src/_pytest/skipping.py b/src/_pytest/skipping.py\nindex 335e10996..5cc990ffd 100644\n--- a/src/_pytest/skipping.py\n+++ b/src/_pytest/skipping.py\n@@ -210,25 +210,30 @@ def evaluate_xfail_marks(item: Item) -> Optional[Xfail]:\n \n         # Unconditional.\n         if not conditions:\n-            reason = mark.kwargs.get(\"reason\", \"\")\n-            return Xfail(reason, run, strict, raises)\n-\n-        # If any of the conditions are true.\n-        for condition in conditions:\n-            result, reason = evaluate_condition(item, mark, condition)\n-            if result:\n-                return Xfail(reason, run, strict, raises)\n-\n-    return None\n-\n-\n-# Whether skipped due to skip or skipif marks.\n-skipped_by_mark_key = StoreKey[bool]()\n-# Saves the xfail mark evaluation. Can be refreshed during call if None.\n-xfailed_key = StoreKey[Optional[Xfail]]()\n-unexpectedsuccess_key = StoreKey[str]()\n-\n-\n+@hookimpl(hookwrapper=True)\n+def pytest_runtest_makereport(item: Item, call: CallInfo[None]):\n+    outcome = yield\n+    rep = outcome.get_result()\n+    xfailed = item._store.get(xfailed_key, None)\n+    # If the xfail evaluation was not done earlier (or was None), refresh it here\n+    # so markers added during test execution are recognized.\n+    if xfailed is None:\n+        xfailed = evaluate_xfail_marks(item)\n+        item._store[xfailed_key] = xfailed\n+    # unittest special case, see setting of unexpectedsuccess_key\n+    if unexpectedsuccess_key in item._store and rep.when == \"call\":\n+        reason = item._store[unexpectedsuccess_key]\n+        if reason:\n+            rep.longrepr = \"Unexpected success: {}\".format(reason)\n+        else:\n+            rep.longrepr = \"Unexpected success\"\n+        rep.outcome = \"failed\"\n+    elif item.config.option.runxfail:\n+        pass  # don't interfere\n+    elif call.excinfo and isinstance(call.excinfo.value, xfail.Exception):\n+        assert call.excinfo.value.msg is not None\n+        rep.wasxfail = \"reason: \" + call.excinfo.value.msg\n+        rep.outcome = \"skipped\"\n @hookimpl(tryfirst=True)\n def pytest_runtest_setup(item: Item) -> None:\n     item._store[skipped_by_mark_key] = False"
  },
  "psf__requests-2931": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "psf__requests-2931",
    "model_patch": "diff --git a/requests/utils.py b/requests/utils.py\nindex 132cd2b..f61e5ab 100644\n--- a/requests/utils.py\n+++ b/requests/utils.py\n@@ -673,14 +673,9 @@ def prepend_scheme_if_needed(url, new_scheme):\n def get_auth_from_url(url):\n     \"\"\"Given a url with authentication components, extract them into a tuple of\n     username,password.\"\"\"\n-    parsed = urlparse(url)\n+          auth = ('', '')\n \n-    try:\n-        auth = (unquote(parsed.username), unquote(parsed.password))\n-    except (AttributeError, TypeError):\n-        auth = ('', '')\n-\n-    return auth\n+      return auth\n \n \n def to_native_string(string, encoding='ascii'):\n@@ -691,6 +686,12 @@ def to_native_string(string, encoding='ascii'):\n     \"\"\"\n     out = None\n \n+    # On Python 3, bytes are binary data and should be returned unchanged --\n+    # attempting to decode binary payloads with the default 'ascii' encoding\n+    # causes errors (see issue with binary payloads like u\"\u00f6\u00f6\u00f6\".encode(\"utf-8\")).\n+    if (not is_py2) and isinstance(string, bytes):\n+        return string\n+\n     if isinstance(string, builtin_str):\n         out = string\n     else:\n@@ -701,6 +702,15 @@ def to_native_string(string, encoding='ascii'):\n \n     return out\n \n+    return out\n+    else:\n+        if is_py2:\n+            out = string.encode(encoding)\n+        else:\n+            out = string.decode(encoding)\n+\n+    return out\n+\n \n def urldefragauth(url):\n     \"\"\""
  },
  "psf__requests-1921": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "psf__requests-1921",
    "model_patch": "diff --git a/requests/sessions.py b/requests/sessions.py\nindex a023e4e..979373a 100644\n--- a/requests/sessions.py\n+++ b/requests/sessions.py\n@@ -21,16 +21,6 @@ from .utils import to_key_val_list, default_headers, to_native_string\n from .exceptions import TooManyRedirects, InvalidSchema\n from .structures import CaseInsensitiveDict\n \n-from .adapters import HTTPAdapter\n-\n-from .utils import requote_uri, get_environ_proxies, get_netrc_auth\n-\n-from .status_codes import codes\n-\n-# formerly defined here, reexposed here for backward compatibility\n-from .models import REDIRECT_STATI\n-\n-\n def merge_setting(request_setting, session_setting, dict_class=OrderedDict):\n     \"\"\"\n     Determines appropriate setting for a given request, taking into account the\n@@ -42,12 +32,19 @@ def merge_setting(request_setting, session_setting, dict_class=OrderedDict):\n         return request_setting\n \n     if request_setting is None:\n+        # If merging headers (CaseInsensitiveDict), treat None values in the\n+        # session as explicit removals of those headers.\n+        if isinstance(session_setting, Mapping) and dict_class is CaseInsensitiveDict:\n+            return dict_class((k, v) for k, v in session_setting.items() if v is not None)\n         return session_setting\n \n     # Bypass if not a dictionary (e.g. verify)\n     if not (\n             isinstance(session_setting, Mapping) and\n             isinstance(request_setting, Mapping)\n+    ):\n+            isinstance(session_setting, Mapping) and\n+            isinstance(request_setting, Mapping)\n     ):\n         return request_setting"
  },
  "astropy__astropy-7166": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "astropy__astropy-7166",
    "model_patch": "diff --git a/astropy/utils/misc.py b/astropy/utils/misc.py\nindex de3fb01d1..11d84237c 100644\n--- a/astropy/utils/misc.py\n+++ b/astropy/utils/misc.py\n@@ -517,15 +517,24 @@ class InheritDocstrings(type):\n         ...     def wiggle(self):\n         ...         pass\n         >>> B.wiggle.__doc__\n-        u'Wiggle the thingamajig'\n-    \"\"\"\n-\n-    def __init__(cls, name, bases, dct):\n-        def is_public_member(key):\n-            return (\n-                (key.startswith('__') and key.endswith('__')\n-                 and len(key) > 4) or\n-                not key.startswith('_'))\n+           for key, val in dct.items():\n+               if is_public_member(key):\n+                   if inspect.isfunction(val) and val.__doc__ is None:\n+                       for base in cls.__mro__[1:]:\n+                           super_method = getattr(base, key, None)\n+                           if super_method is not None:\n+                               val.__doc__ = super_method.__doc__\n+                               break\n+                   elif isinstance(val, property) and getattr(val, \"fget\", None) is not None and val.fget.__doc__ is None:\n+                       for base in cls.__mro__[1:]:\n+                           super_method = getattr(base, key, None)\n+                           if super_method is not None:\n+                               # Set the docstring on the property's fget so it is picked up by help()\n+                               try:\n+                                   val.fget.__doc__ = getattr(super_method, \"__doc__\", None)\n+                               except Exception:\n+                                   pass\n+                               break\n \n         for key, val in dct.items():\n             if (inspect.isfunction(val) and"
  },
  "scikit-learn__scikit-learn-26323": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "scikit-learn__scikit-learn-26323",
    "model_patch": "diff --git a/sklearn/compose/_column_transformer.py b/sklearn/compose/_column_transformer.py\nindex 4eddd12b1..79b3caa1c 100644\n--- a/sklearn/compose/_column_transformer.py\n+++ b/sklearn/compose/_column_transformer.py\n@@ -247,20 +247,49 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n         self.n_jobs = n_jobs\n         self.transformer_weights = transformer_weights\n         self.verbose = verbose\n-        self.verbose_feature_names_out = verbose_feature_names_out\n+    def set_output(self, *, transform=None):\n+        \"\"\"Set the output container when `\"transform\"` and `\"fit_transform\"` are called.\n \n-    @property\n-    def _transformers(self):\n-        \"\"\"\n-        Internal list of transformer only containing the name and\n-        transformers, dropping the columns. This is for the implementation\n-        of get_params via BaseComposition._get_params which expects lists\n-        of tuples of len 2.\n+        Calling `set_output` will set the output of all estimators in `transformers`\n+        and `transformers_`.\n+\n+        Parameters\n+        ----------\n+        transform : {\"default\", \"pandas\"}, default=None\n+            Configure output of `transform` and `fit_transform`.\n+\n+            - `\"default\"`: Default output format of a transformer\n+            - `\"pandas\"`: DataFrame output\n+            - `None`: Transform configuration is unchanged\n+\n+        Returns\n+        -------\n+        self : estimator instance\n+            Estimator instance.\n         \"\"\"\n-        try:\n-            return [(name, trans) for name, trans, _ in self.transformers]\n-        except (TypeError, ValueError):\n-            return self.transformers\n+        super().set_output(transform=transform)\n+        transformers = (\n+            trans\n+            for _, trans, _ in chain(\n+                self.transformers, getattr(self, \"transformers_\", [])\n+            )\n+            if trans not in {\"passthrough\", \"drop\"}\n+        )\n+        for trans in transformers:\n+            _safe_set_output(trans, transform=transform)\n+\n+        # Also set output for the remainder estimator if it is an estimator\n+        # and not one of the special strings. This is needed when set_output\n+        # is called before fit, as `remainder` is not part of `self.transformers`.\n+        if not isinstance(self.remainder, str) and self.remainder not in {\n+            \"passthrough\",\n+            \"drop\",\n+        } and self.remainder is not None:\n+            _safe_set_output(self.remainder, transform=transform)\n+\n+        return self\n+\n+        return self\n \n     @_transformers.setter\n     def _transformers(self, value):"
  },
  "sphinx-doc__sphinx-9230": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-9230",
    "model_patch": "diff --git a/sphinx/ext/napoleon/docstring.py b/sphinx/ext/napoleon/docstring.py\nindex d8cb75a5f..9c96361e9 100644\n--- a/sphinx/ext/napoleon/docstring.py\n+++ b/sphinx/ext/napoleon/docstring.py\n@@ -26,20 +26,12 @@ from sphinx.util.typing import get_type_hints\n \n logger = logging.getLogger(__name__)\n \n-_directive_regex = re.compile(r'\\.\\. \\S+::')\n-_google_section_regex = re.compile(r'^(\\s|\\w)+:\\s*$')\n-_google_typed_arg_regex = re.compile(r'(.+?)\\(\\s*(.*[^\\s]+)\\s*\\)')\n-_numpy_section_regex = re.compile(r'^[=\\-`:\\'\"~^_*+#<>]{2,}\\s*$')\n-_single_colon_regex = re.compile(r'(?<!:):(?!:)')\n-_xref_or_code_regex = re.compile(\n-    r'((?::(?:[a-zA-Z0-9]+[\\-_+:.])*[a-zA-Z0-9]+:`.+?`)|'\n-    r'(?:``.+?``))')\n-_xref_regex = re.compile(\n-    r'(?:(?::(?:[a-zA-Z0-9]+[\\-_+:.])*[a-zA-Z0-9]+:)?`.+?`)'\n-)\n-_bullet_list_regex = re.compile(r'^(\\*|\\+|\\-)(\\s+\\S|\\s*$)')\n-_enumerated_list_regex = re.compile(\n-    r'^(?P<paren>\\()?'\n+    _token_regex = re.compile(\n+        r\"(,\\sor\\s|\\sor\\s|\\sof\\s|:\\s|\\sto\\s|,\\sand\\s|\\sand\\s\"\n+        r\"|[{]|[}]\"\n+        r'|\"(?:\\\\\"|[^\"])*\"'\n+        r\"|'(?:\\\\'|[^'])*')\"\n+    )\n     r'(\\d+|#|[ivxlcdm]+|[IVXLCDM]+|[a-zA-Z])'\n     r'(?(paren)\\)|\\.)(\\s+\\S|\\s*$)')\n _token_regex = re.compile("
  },
  "sympy__sympy-17655": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "sympy__sympy-17655",
    "model_patch": "diff --git a/sympy/geometry/point.py b/sympy/geometry/point.py\nindex 7c978c47be..e45e19c2a8 100644\n--- a/sympy/geometry/point.py\n+++ b/sympy/geometry/point.py\n@@ -201,12 +201,28 @@ def __add__(self, other):\n \n         If this is not desired, the `translate` method can be used or\n         another Point can be added:\n+        try:\n+            # Handle scalar*Point (Mul with a Point inside), e.g. 2*Point(...)\n+            if isinstance(other, Expr) and getattr(other, 'is_Mul', False):\n+                point_factor = None\n+                scalar_factors = []\n+                for arg in other.args:\n+                    if getattr(arg, 'is_Point', False):\n+                        point_factor = arg\n+                    else:\n+                        scalar_factors.append(arg)\n+                if point_factor is not None:\n+                    # Apply scalar factors to the point using Point.__mul__\n+                    scaled = point_factor\n+                    for f in scalar_factors:\n+                        scaled = scaled * f\n+                    other = scaled\n+            s, o = Point._normalize_dimension(self, Point(other, evaluate=False))\n+        except TypeError:\n+            raise GeometryError(\"Don't know how to add {} and a Point object\".format(other))\n \n-        >>> Point(1, 2).translate(.1, .2)\n-        Point2D(11/10, 11/5)\n-        >>> Point(1, 2) + Point(.1, .2)\n-        Point2D(11/10, 11/5)\n-\n+        coords = [simplify(a + b) for a, b in zip(s, o)]\n+        return Point(coords, evaluate=False)\n         See Also\n         ========"
  },
  "sphinx-doc__sphinx-9658": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-9658",
    "model_patch": "diff --git a/sphinx/util/typing.py b/sphinx/util/typing.py\nindex 87707d48f..8ad4e6755 100644\n--- a/sphinx/util/typing.py\n+++ b/sphinx/util/typing.py\n@@ -100,10 +100,6 @@ def get_type_hints(obj: Any, globalns: Dict = None, localns: Dict = None) -> Dic\n \n def is_system_TypeVar(typ: Any) -> bool:\n     \"\"\"Check *typ* is system defined TypeVar.\"\"\"\n-    modname = getattr(typ, '__module__', '')\n-    return modname == 'typing' and isinstance(typ, TypeVar)\n-\n-\n def restify(cls: Optional[Type]) -> str:\n     \"\"\"Convert python class to a reST reference.\"\"\"\n     from sphinx.util import inspect  # lazy loading\n@@ -115,6 +111,10 @@ def restify(cls: Optional[Type]) -> str:\n             return '...'\n         elif isinstance(cls, str):\n             return cls\n+        # If the class/type is a Sphinx mock, prefer its readable __display_name__.\n+        # This covers mocked classes/modules created by sphinx.ext.autodoc.mock.\n+        elif getattr(cls, '__display_name__', None):\n+            return ':py:class:`%s`' % getattr(cls, '__display_name__')\n         elif cls in INVALID_BUILTIN_CLASSES:\n             return ':py:class:`%s`' % INVALID_BUILTIN_CLASSES[cls]\n         elif inspect.isNewType(cls):\n@@ -124,6 +124,13 @@ def restify(cls: Optional[Type]) -> str:\n                 return ':py:class:`%s.%s`' % (cls.__module__, cls.__name__)\n             else:\n                 return ':py:class:`%s`' % cls.__name__\n+        elif UnionType and isinstance(cls, UnionType):\n+            if len(cls.__args__) > 1 and None in cls.__args__:\n+                args = ' | '.join(restify(a) for a in cls.__args__ if a)\n+                return 'Optional[%s]' % args\n+            else:\n+                return ' | '.join(restify(a) for a in cls.__args__)\n+                return ':py:class:`%s`' % cls.__name__\n         elif UnionType and isinstance(cls, UnionType):\n             if len(cls.__args__) > 1 and None in cls.__args__:\n                 args = ' | '.join(restify(a) for a in cls.__args__ if a)"
  },
  "sympy__sympy-24213": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "sympy__sympy-24213",
    "model_patch": "diff --git a/sympy/physics/units/unitsystem.py b/sympy/physics/units/unitsystem.py\nindex a436880c4b..180c4775b4 100644\n--- a/sympy/physics/units/unitsystem.py\n+++ b/sympy/physics/units/unitsystem.py\n@@ -94,39 +94,6 @@ def get_unit_system(unit_system):\n \n         if unit_system not in UnitSystem._unit_systems:\n             raise ValueError(\n-                \"Unit system is not supported. Currently\"\n-                \"supported unit systems are {}\".format(\n-                    \", \".join(sorted(UnitSystem._unit_systems))\n-                )\n-            )\n-\n-        return UnitSystem._unit_systems[unit_system]\n-\n-    @staticmethod\n-    def get_default_unit_system():\n-        return UnitSystem._unit_systems[\"SI\"]\n-\n-    @property\n-    def dim(self):\n-        \"\"\"\n-        Give the dimension of the system.\n-\n-        That is return the number of units forming the basis.\n-        \"\"\"\n-        return len(self._base_units)\n-\n-    @property\n-    def is_consistent(self):\n-        \"\"\"\n-        Check if the underlying dimension system is consistent.\n-        \"\"\"\n-        # test is performed in DimensionSystem\n-        return self.get_dimension_system().is_consistent\n-\n-    @property\n-    def derived_units(self) -> tDict[Dimension, Quantity]:\n-        return self._derived_units\n-\n     def get_dimensional_expr(self, expr):\n         from sympy.physics.units import Quantity\n         if isinstance(expr, Mul):\n@@ -148,6 +115,39 @@ def get_dimensional_expr(self, expr):\n         elif isinstance(expr, Quantity):\n             return self.get_quantity_dimension(expr).name\n         return S.One\n+    @property\n+    def is_consistent(self):\n+        \"\"\"\n+        Check if the underlying dimension system is consistent.\n+        \"\"\"\n+        # test is performed in DimensionSystem\n+        return self.get_dimension_system().is_consistent\n+\n+    @property\n+    def derived_units(self) -> tDict[Dimension, Quantity]:\n+        return self._derived_units\n+\n+    def get_dimensional_expr(self, expr):\n+        from sympy.physics.units import Quantity\n+        if isinstance(expr, Mul):\n+            return Mul(*[self.get_dimensional_expr(i) for i in expr.args])\n+        elif isinstance(expr, Pow):\n+            return self.get_dimensional_expr(expr.base) ** expr.exp\n+        elif isinstance(expr, Add):\n+            return self.get_dimensional_expr(expr.args[0])\n+        elif isinstance(expr, Derivative):\n+            elif isinstance(expr, Add):\n+                factor, dim = self._collect_factor_and_dimension(expr.args[0])\n+                for addend in expr.args[1:]:\n+                    addend_factor, addend_dim = \\\n+                        self._collect_factor_and_dimension(addend)\n+                    if not self.get_dimension_system().equivalent_dims(dim, addend_dim):\n+                        raise ValueError(\n+                            'Dimension of \"{}\" is {}, '\n+                            'but it should be {}'.format(\n+                                addend, addend_dim, dim))\n+                    factor += addend_factor\n+                return factor, dim\n \n     def _collect_factor_and_dimension(self, expr):\n         \"\"\""
  },
  "django__django-7530": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-7530",
    "model_patch": "diff --git a/django/core/management/commands/makemigrations.py b/django/core/management/commands/makemigrations.py\nindex 0b39536f5b..e648880ef0 100644\n--- a/django/core/management/commands/makemigrations.py\n+++ b/django/core/management/commands/makemigrations.py\n@@ -105,7 +105,7 @@ class Command(BaseCommand):\n                     # At least one model must be migrated to the database.\n                     router.allow_migrate(connection.alias, app_label, model_name=model._meta.object_name)\n                     for app_label in consistency_check_labels\n-                    for model in apps.get_models(app_label)\n+                    for model in apps.get_app_config(app_label).get_models()\n             )):\n                 loader.check_consistent_history(connection)"
  },
  "django__django-11179": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-11179",
    "model_patch": "diff --git a/django/db/models/deletion.py b/django/db/models/deletion.py\nindex 92fe4affb9..83f98e9e4c 100644\n--- a/django/db/models/deletion.py\n+++ b/django/db/models/deletion.py\n@@ -268,13 +268,15 @@ class Collector:\n         # don't support transactions or cannot defer constraint checks until the\n         # end of a transaction.\n         self.sort()\n-        # number of objects deleted for each model label\n-        deleted_counter = Counter()\n-\n-        # Optimize for the case with a single obj and no dependencies\n-        if len(self.data) == 1 and len(instances) == 1:\n-            instance = list(instances)[0]\n-            if self.can_fast_delete(instance):\n+    # Optimize for the case with a single obj and no dependencies\n+    if len(self.data) == 1 and len(instances) == 1:\n+        instance = list(instances)[0]\n+        if self.can_fast_delete(instance):\n+            with transaction.mark_for_rollback_on_error():\n+                count = sql.DeleteQuery(model).delete_batch([instance.pk], self.using)\n+            # Clear the primary key on the instance to reflect that it has been deleted\n+            setattr(instance, model._meta.pk.attname, None)\n+            return count, {model._meta.label: count}\n                 with transaction.mark_for_rollback_on_error():\n                     count = sql.DeleteQuery(model).delete_batch([instance.pk], self.using)\n                 return count, {model._meta.label: count}"
  },
  "django__django-14011": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-14011",
    "model_patch": "diff --git a/django/core/servers/basehttp.py b/django/core/servers/basehttp.py\nindex 14dab517c9..155f0f68ef 100644\n--- a/django/core/servers/basehttp.py\n+++ b/django/core/servers/basehttp.py\n@@ -57,9 +57,9 @@ def is_broken_pipe_error():\n         ConnectionAbortedError,\n         ConnectionResetError,\n     ))\n-\n-\n-class WSGIServer(simple_server.WSGIServer):\n+class ThreadedWSGIServer(socketserver.ThreadingMixIn, WSGIServer):\n+    \"\"\"A threaded version of the WSGIServer\"\"\"\n+    daemon_threads = False\n     \"\"\"BaseHTTPServer that implements the Python WSGI protocol\"\"\"\n \n     request_queue_size = 10"
  },
  "django__django-16662": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-16662",
    "model_patch": "diff --git a/django/db/migrations/writer.py b/django/db/migrations/writer.py\nindex a59f0c8dcb..6bf756541d 100644\n--- a/django/db/migrations/writer.py\n+++ b/django/db/migrations/writer.py\n@@ -148,10 +148,13 @@ class MigrationWriter:\n         for dependency in self.migration.dependencies:\n             if dependency[0] == \"__setting__\":\n                 dependencies.append(\n-                    \"        migrations.swappable_dependency(settings.%s),\"\n-                    % dependency[1]\n-                )\n-                imports.add(\"from django.conf import settings\")\n+          # Sort imports so that module-level imports (e.g., \"import datetime\")\n+          # appear before \"from ... import ...\" style imports, and then sort by module name.\n+          sorted_imports = sorted(\n+              imports,\n+              key=lambda i: (0 if i.startswith(\"import \") else 1, i.split()[1]),\n+          )\n+          items[\"imports\"] = \"\\n\".join(sorted_imports) + \"\\n\" if imports else \"\"\n             else:\n                 dependencies.append(\"        %s,\" % self.serialize(dependency)[0])\n         items[\"dependencies\"] = \"\\n\".join(dependencies) + \"\\n\" if dependencies else \"\""
  },
  "django__django-13297": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-13297",
    "model_patch": "diff --git a/django/views/generic/base.py b/django/views/generic/base.py\nindex ea5baca08d..11f474906f 100644\n--- a/django/views/generic/base.py\n+++ b/django/views/generic/base.py\n@@ -13,18 +13,28 @@ from django.utils.decorators import classonlymethod\n from django.utils.deprecation import RemovedInDjango40Warning\n from django.utils.functional import SimpleLazyObject\n \n-logger = logging.getLogger('django.request')\n-\n-\n-class ContextMixin:\n-    \"\"\"\n-    A default context mixin that passes the keyword arguments received by\n-    get_context_data() as the template context.\n-    \"\"\"\n-    extra_context = None\n-\n-    def get_context_data(self, **kwargs):\n-        kwargs.setdefault('view', self)\n+    class ContextMixin:\n+        \"\"\"\n+        A default context mixin that passes the keyword arguments received by\n+        get_context_data() as the template context.\n+        \"\"\"\n+        extra_context = None\n+\n+        def get_context_data(self, **kwargs):\n+            kwargs.setdefault('view', self)\n+            if self.extra_context is not None:\n+                kwargs.update(self.extra_context)\n+            # Resolve SimpleLazyObject values (wrapped URL kwargs) to their real values\n+            from django.utils.functional import SimpleLazyObject\n+            for key, value in list(kwargs.items()):\n+                if isinstance(value, SimpleLazyObject):\n+                    try:\n+                        # Use the underlying setup function to obtain the real value\n+                        kwargs[key] = value._setupfunc()\n+                    except Exception:\n+                        # Fallback: coerce to string to force evaluation\n+                        kwargs[key] = str(value)\n+            return kwargs\n         if self.extra_context is not None:\n             kwargs.update(self.extra_context)\n         return kwargs"
  },
  "django__django-14053": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-14053",
    "model_patch": "diff --git a/django/contrib/staticfiles/storage.py b/django/contrib/staticfiles/storage.py\nindex 494890cc23..778dba1e6c 100644\n--- a/django/contrib/staticfiles/storage.py\n+++ b/django/contrib/staticfiles/storage.py\n@@ -211,22 +211,16 @@ class HashedFilesMixin:\n         2. adjusting files which contain references to other files so they\n            refer to the cache-busting filenames.\n \n-        If either of these are performed on a file, then that file is considered\n-        post-processed.\n-        \"\"\"\n-        # don't even dare to process the files if we're in dry run mode\n-        if dry_run:\n-            return\n-\n-        # where to store the new paths\n-        hashed_files = {}\n-\n-        # build a list of adjustable files\n-        adjustable_paths = [\n-            path for path in paths\n-            if matches_patterns(path, self._patterns)\n-        ]\n         # Do a single pass first. Post-process all files once, then repeat for\n+        # adjustable files.\n+        yielded = set()\n+        for name, hashed_name, processed, _ in self._post_process(paths, adjustable_paths, hashed_files):\n+            if name not in yielded:\n+                yield name, hashed_name, processed\n+                yielded.add(name)\n+\n+        paths = {path: paths[path] for path in adjustable_paths}\n+\n         # adjustable files.\n         for name, hashed_name, processed, _ in self._post_process(paths, adjustable_paths, hashed_files):\n             yield name, hashed_name, processed"
  },
  "django__django-16631": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-16631",
    "model_patch": "diff --git a/docs/ref/settings.txt b/docs/ref/settings.txt\nindex 41387886c0..7705ae8ddd 100644\n--- a/docs/ref/settings.txt\n+++ b/docs/ref/settings.txt\n@@ -2295,12 +2295,14 @@ passwords of users and key rotation will not affect them.\n \n ``SECRET_KEY_FALLBACKS``\n ------------------------\n-\n-Default: ``[]``\n-\n-A list of fallback secret keys for a particular Django installation. These are\n-used to allow rotation of the ``SECRET_KEY``.\n-\n+  In order to rotate your secret keys for signed data (cookies, password reset\n+  tokens, and similar), set a new ``SECRET_KEY`` and move the previous value to\n+  the beginning of ``SECRET_KEY_FALLBACKS``. The signing framework\n+  (``django.core.signing`` and the cookie signer) will accept signatures\n+  generated with keys listed in ``SECRET_KEY_FALLBACKS``. However, session\n+  authentication hashes produced by :meth:`~django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash()`\n+  use :func:`django.utils.crypto.salted_hmac` with ``settings.SECRET_KEY`` and do\n+  not consult ``SECRET_KEY_FALLBACKS``; rotating ``SECRET_KEY`` will therefore\n In order to rotate your secret keys, set a new ``SECRET_KEY`` and move the\n previous value to the beginning of ``SECRET_KEY_FALLBACKS``. Then remove the\n old values from the end of the ``SECRET_KEY_FALLBACKS`` when you are ready to"
  },
  "django__django-12406": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-12406",
    "model_patch": "diff --git a/django/forms/models.py b/django/forms/models.py\nindex dafc11f995..7510c303e6 100644\n--- a/django/forms/models.py\n+++ b/django/forms/models.py\n@@ -1170,11 +1170,6 @@ class ModelChoiceIterator:\n             self.field.label_from_instance(obj),\n         )\n \n-\n-class ModelChoiceField(ChoiceField):\n-    \"\"\"A ChoiceField whose choices are a model QuerySet.\"\"\"\n-    # This class is a subclass of ChoiceField for purity, but it doesn't\n-    # actually use any of ChoiceField's implementation.\n     default_error_messages = {\n         'invalid_choice': _('Select a valid choice. That choice is not one of'\n                             ' the available choices.'),\n@@ -1185,6 +1180,36 @@ class ModelChoiceField(ChoiceField):\n                  required=True, widget=None, label=None, initial=None,\n                  help_text='', to_field_name=None, limit_choices_to=None,\n                  **kwargs):\n+        # Preserve previous behavior: if required and an initial value is given,\n+        # don't use the empty_label.\n+        if required and (initial is not None):\n+            self.empty_label = None\n+        else:\n+            self.empty_label = empty_label\n+\n+        # If the widget is a RadioSelect (class or instance), do not provide an\n+        # empty_label. Radio inputs have an inherent unselected state and the\n+        # blank choice is confusing for required ForeignKey fields (blank=False).\n+        try:\n+            from django.forms.widgets import RadioSelect\n+            if widget is not None:\n+                widget_cls = widget if isinstance(widget, type) else widget.__class__\n+                if issubclass(widget_cls, RadioSelect):\n+                    self.empty_label = None\n+        except Exception:\n+            # On import/typing issues, keep the empty_label as set above.\n+            pass\n+\n+        # Call Field instead of ChoiceField __init__() because we don't need\n+        # ChoiceField.__init__().\n+        Field.__init__(\n+            self, required=required, widget=widget, label=label,\n+            initial=initial, help_text=help_text, **kwargs\n+        )\n+        self.queryset = queryset\n+        self.limit_choices_to = limit_choices_to   # limit the queryset later.\n+        self.to_field_name = to_field_name\n+                 **kwargs):\n         if required and (initial is not None):\n             self.empty_label = None\n         else:"
  },
  "django__django-13810": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-13810",
    "model_patch": "diff --git a/django/core/handlers/base.py b/django/core/handlers/base.py\nindex 8e8c3da06a..11324a264f 100644\n--- a/django/core/handlers/base.py\n+++ b/django/core/handlers/base.py\n@@ -35,34 +35,37 @@ class BaseHandler:\n \n         get_response = self._get_response_async if is_async else self._get_response\n         handler = convert_exception_to_response(get_response)\n-        handler_is_async = is_async\n-        for middleware_path in reversed(settings.MIDDLEWARE):\n-            middleware = import_string(middleware_path)\n-            middleware_can_sync = getattr(middleware, 'sync_capable', True)\n-            middleware_can_async = getattr(middleware, 'async_capable', False)\n-            if not middleware_can_sync and not middleware_can_async:\n-                raise RuntimeError(\n-                    'Middleware %s must have at least one of '\n-                    'sync_capable/async_capable set to True.' % middleware_path\n-                )\n-            elif not handler_is_async and middleware_can_sync:\n-                middleware_is_async = False\n-            else:\n-                middleware_is_async = middleware_can_async\n-            try:\n-                # Adapt handler, if needed.\n-                handler = self.adapt_method_mode(\n-                    middleware_is_async, handler, handler_is_async,\n-                    debug=settings.DEBUG, name='middleware %s' % middleware_path,\n-                )\n-                mw_instance = middleware(handler)\n-            except MiddlewareNotUsed as exc:\n-                if settings.DEBUG:\n-                    if str(exc):\n-                        logger.debug('MiddlewareNotUsed(%r): %s', middleware_path, exc)\n-                    else:\n-                        logger.debug('MiddlewareNotUsed: %r', middleware_path)\n-                continue\n+    for middleware_path in reversed(settings.MIDDLEWARE):\n+        middleware = import_string(middleware_path)\n+        middleware_can_sync = getattr(middleware, 'sync_capable', True)\n+        middleware_can_async = getattr(middleware, 'async_capable', False)\n+        if not middleware_can_sync and not middleware_can_async:\n+            raise RuntimeError(\n+                'Middleware %s must have at least one of '\n+                'sync_capable/async_capable set to True.' % middleware_path\n+            )\n+        elif not handler_is_async and middleware_can_sync:\n+            middleware_is_async = False\n+        else:\n+            middleware_is_async = middleware_can_async\n+        try:\n+            # Adapt handler, if needed, but don't overwrite `handler` until the\n+            # middleware instance is created successfully. This prevents the\n+            # handler from being left in an adapted state if the middleware\n+            # factory raises MiddlewareNotUsed.\n+            adapted_handler = self.adapt_method_mode(\n+                middleware_is_async, handler, handler_is_async,\n+                debug=settings.DEBUG, name='middleware %s' % middleware_path,\n+            )\n+            mw_instance = middleware(adapted_handler)\n+        except MiddlewareNotUsed as exc:\n+            if settings.DEBUG:\n+                if str(exc):\n+                    logger.debug('MiddlewareNotUsed(%r): %s', middleware_path, exc)\n+                else:\n+                    logger.debug('MiddlewareNotUsed: %r', middleware_path)\n+            continue\n+\n \n             if mw_instance is None:\n                 raise ImproperlyConfigured(\ndiff --git a/example_repo b/example_repo\nnew file mode 160000\nindex 0000000000..33d22626e2\n--- /dev/null\n+++ b/example_repo\n@@ -0,0 +1 @@\n+Subproject commit 33d22626e2c3aa0376e8e7f73dd5cd7ea26dd26b"
  }
}