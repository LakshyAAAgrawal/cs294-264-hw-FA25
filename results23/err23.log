ðŸ‘‹ This is mini-swe-agent version 1.13.3.
Loading global config from '/home/eecs/lakshyaaagrawal/.config/mini-swe-agent/.env'
Results will be saved to results23
Loading dataset lynnliu030/swebench-eval-subset, split test...
Running on 20 instances...
Processing instance sphinx-doc__sphinx-9230
minisweagent.environment: DEBUG: Starting container with command: docker run -d --name minisweagent-772660aa -w      
/testbed --rm docker.io/swebench/sweb.eval.x86_64.sphinx-doc_1776_sphinx-9230:latest sleep 2h                        
Processing instance django__django-14053
minisweagent.environment: DEBUG: Starting container with command: docker run -d --name minisweagent-baea70fc -w      
/testbed --rm docker.io/swebench/sweb.eval.x86_64.django_1776_django-14053:latest sleep 2h                           
Processing instance django__django-16662
minisweagent.environment: DEBUG: Starting container with command: docker run -d --name minisweagent-a06c701f -w      
/testbed --rm docker.io/swebench/sweb.eval.x86_64.django_1776_django-16662:latest sleep 2h                           
Processing instance scikit-learn__scikit-learn-26323
minisweagent.environment: DEBUG: Starting container with command: docker run -d --name minisweagent-804a12b4 -w      
/testbed --rm docker.io/swebench/sweb.eval.x86_64.scikit-learn_1776_scikit-learn-26323:latest sleep 2h               
Processing instance astropy__astropy-7166
minisweagent.environment: DEBUG: Starting container with command: docker run -d --name minisweagent-136bb835 -w      
/testbed --rm docker.io/swebench/sweb.eval.x86_64.astropy_1776_astropy-7166:latest sleep 2h                          
Processing instance django__django-7530
minisweagent.environment: DEBUG: Starting container with command: docker run -d --name minisweagent-798c2de6 -w      
/testbed --rm docker.io/swebench/sweb.eval.x86_64.django_1776_django-7530:latest sleep 2h                            
Processing instance sympy__sympy-24213
minisweagent.environment: DEBUG: Starting container with command: docker run -d --name minisweagent-f71badea -w      
/testbed --rm docker.io/swebench/sweb.eval.x86_64.sympy_1776_sympy-24213:latest sleep 2h                             
Processing instance django__django-11179
Processing instance django__django-12406
Processing instance django__django-16631
Processing instance sphinx-doc__sphinx-7590
Processing instance sphinx-doc__sphinx-9658
Processing instance pytest-dev__pytest-7490
Processing instance sympy__sympy-17655
Processing instance django__django-13297
Processing instance psf__requests-2931
Processing instance django__django-14011
Processing instance django__django-13810
minisweagent.environment: DEBUG: Starting container with command: docker run -d --name minisweagent-2ebd2a6f -w      
/testbed --rm docker.io/swebench/sweb.eval.x86_64.django_1776_django-11179:latest sleep 2h                           
minisweagent.environment: DEBUG: Starting container with command: docker run -d --name minisweagent-1eb42232 -w      
/testbed --rm docker.io/swebench/sweb.eval.x86_64.django_1776_django-12406:latest sleep 2h                           
Processing instance django__django-10973
minisweagent.environment: DEBUG: Starting container with command: docker run -d --name minisweagent-f497d12d -w      
/testbed --rm docker.io/swebench/sweb.eval.x86_64.django_1776_django-16631:latest sleep 2h                           
minisweagent.environment: DEBUG: Starting container with command: docker run -d --name minisweagent-4633deeb -w      
/testbed --rm docker.io/swebench/sweb.eval.x86_64.sphinx-doc_1776_sphinx-7590:latest sleep 2h                        
minisweagent.environment: DEBUG: Starting container with command: docker run -d --name minisweagent-27ddf6e8 -w      
/testbed --rm docker.io/swebench/sweb.eval.x86_64.sphinx-doc_1776_sphinx-9658:latest sleep 2h                        
minisweagent.environment: DEBUG: Starting container with command: docker run -d --name minisweagent-4e103fa4 -w      
/testbed --rm docker.io/swebench/sweb.eval.x86_64.pytest-dev_1776_pytest-7490:latest sleep 2h                        
minisweagent.environment: DEBUG: Starting container with command: docker run -d --name minisweagent-983b6c18 -w      
/testbed --rm docker.io/swebench/sweb.eval.x86_64.sympy_1776_sympy-17655:latest sleep 2h                             
Processing instance psf__requests-1921
minisweagent.environment: DEBUG: Starting container with command: docker run -d --name minisweagent-91e44ee0 -w      
/testbed --rm docker.io/swebench/sweb.eval.x86_64.django_1776_django-13297:latest sleep 2h                           
minisweagent.environment: DEBUG: Starting container with command: docker run -d --name minisweagent-3e0e2910 -w      
/testbed --rm docker.io/swebench/sweb.eval.x86_64.psf_1776_requests-2931:latest sleep 2h                             
minisweagent.environment: DEBUG: Starting container with command: docker run -d --name minisweagent-80e5fcdf -w      
/testbed --rm docker.io/swebench/sweb.eval.x86_64.django_1776_django-14011:latest sleep 2h                           
minisweagent.environment: DEBUG: Starting container with command: docker run -d --name minisweagent-19bfac3a -w      
/testbed --rm docker.io/swebench/sweb.eval.x86_64.django_1776_django-13810:latest sleep 2h                           
minisweagent.environment: DEBUG: Starting container with command: docker run -d --name minisweagent-c083a9b3 -w      
/testbed --rm docker.io/swebench/sweb.eval.x86_64.django_1776_django-10973:latest sleep 2h                           
minisweagent.environment: DEBUG: Starting container with command: docker run -d --name minisweagent-1e9e8da1 -w      
/testbed --rm docker.io/swebench/sweb.eval.x86_64.psf_1776_requests-1921:latest sleep 2h                             
minisweagent.environment: INFO: Started container minisweagent-772660aa with ID                                      
1b45f497fdafa0584a6d79fcefe28427c4a964a8844c53cb633070db74a74cde                                                     
minisweagent.environment: INFO: Started container minisweagent-baea70fc with ID                                      
4d1486738d07d30d9b368bba9c91cd89ddff76835956897b669adf2b04f85a91                                                     
minisweagent.environment: INFO: Started container minisweagent-804a12b4 with ID                                      
c66ca5e37c89cb648875561ce66d5ff90f9a344759df00c47a78e5b7bcd981dd                                                     
minisweagent.environment: INFO: Started container minisweagent-136bb835 with ID                                      
37ba5fe0f6701745e499b897c464e551d509508091713be117600b9f8c4d2410                                                     
minisweagent.environment: INFO: Started container minisweagent-27ddf6e8 with ID                                      
8fb4e301c7006edea135b4217f36ef6d2cce961d3e6bccf3a9a37e068149c192                                                     
minisweagent.environment: INFO: Started container minisweagent-c083a9b3 with ID                                      
dc2c0877bcbbd7e410b536cc9437ba337ac32cfe5793437be8a3fea4d6fe4d69                                                     
minisweagent.environment: INFO: Started container minisweagent-80e5fcdf with ID                                      
4adff2aa9b18816215b3f6197e8df5795e6c2d861249ffcab54755d36d3a6e5b                                                     
minisweagent.environment: INFO: Started container minisweagent-4633deeb with ID                                      
59fd798143c4dc2862d9f4bf37430a50c479e3e37bd0311ef6423f1a860631f3                                                     
minisweagent.environment: INFO: Started container minisweagent-1e9e8da1 with ID                                      
cc6e28a01fc9853e9e57db76bcf4b8720be464cd7f0c12388ef37d5718829365                                                     
minisweagent.environment: INFO: Started container minisweagent-19bfac3a with ID                                      
673e16a20c098dc7ad382ffef3fcdef19350c95706544a7e44a6d235eed6a2ae                                                     
minisweagent.environment: INFO: Started container minisweagent-a06c701f with ID                                      
b0b06ac37228a44de9b06e4df2ca5269909717a2694042551b555de3eeb00f37                                                     
minisweagent.environment: INFO: Started container minisweagent-1eb42232 with ID                                      
25c914bdba9ff136c3581971a4dd7c26cb866117ec3f2180a16aa9c5848ecb3b                                                     
minisweagent.environment: INFO: Started container minisweagent-4e103fa4 with ID                                      
66617d418daf619c99fff66c05e496de09c481df54b07cfcf5d5d36dcccdcb30                                                     
minisweagent.environment: INFO: Started container minisweagent-3e0e2910 with ID                                      
46b3067c042061e99c5650060298887fede7ac57bada67bf94037e925dc8318c                                                     
minisweagent.environment: INFO: Started container minisweagent-f497d12d with ID                                      
906d25d32c8f6ef6ce0f0020bea931b35a19a56341e93acea390f99b57ee9c5c                                                     
minisweagent.environment: INFO: Started container minisweagent-2ebd2a6f with ID                                      
dc028dcd7d77fc8fc0fc1ae91bd2415a50b5f75c24ab09eaefbd3b252c64657b                                                     
minisweagent.environment: INFO: Started container minisweagent-983b6c18 with ID                                      
4d13cec8dfb838f5b69198ec93b59e8673525f90915d7d34034da984e26f822a                                                     
minisweagent.environment: INFO: Started container minisweagent-798c2de6 with ID                                      
743236ea8c179ec49973df3a56170a865a48ad8ea33acf6cf86d70019ae9108f                                                     
minisweagent.environment: INFO: Started container minisweagent-f71badea with ID                                      
b11af1aaa11cdef7ceb8b150a9a047f53b7f11f63c80693598b503f9990c395e                                                     
minisweagent.environment: INFO: Started container minisweagent-91e44ee0 with ID                                      
8ef521e3e7c3deda6c1f74f7d3085d82d881c5761c6d955aaaa7d007a1a5fa1f                                                     
Saved trajectory to 'results23/psf__requests-2931/psf__requests-2931.traj.json'
Completed instance psf__requests-2931, result: diff --git a/requests/utils.py b/requests/utils.py
index 132cd2b..afcf187 100644
--- a/requests/utils.py
+++ b/requests/utils.py
@@ -697,7 +697,16 @@ def to_native_string(string, encoding='ascii'):
         if is_py2:
             out = string.encode(encoding)
         else:
-            out = string.decode(encoding)
+            # On Python 3 we may be passed a bytes instance. Decode bytes using
+            # UTF-8 first (for common usage), falling back to the provided
+            # encoding on failure. For non-bytes, coerce to str.
+            if isinstance(string, bytes):
+                try:
+                    out = string.decode('utf-8')
+                except UnicodeDecodeError:
+                    out = string.decode(encoding)
+            else:
+                out = str(string)
 
     return out
Saved trajectory to 'results23/psf__requests-1921/psf__requests-1921.traj.json'
Completed instance psf__requests-1921, result: diff --git a/requests/models.py b/requests/models.py
index cd232e6..5c813b3 100644
--- a/requests/models.py
+++ b/requests/models.py
@@ -361,11 +361,7 @@ class PreparedRequest(RequestEncodingMixin, RequestHooksMixin):
         if port:
             netloc += ':' + str(port)
 
-        # Bare domains aren't valid URLs.
-        if not path:
-            path = '/'
-
-        if is_py2:
+if is_py2:
             if isinstance(scheme, str):
                 scheme = scheme.encode('utf-8')
             if isinstance(netloc, str):
@@ -382,14 +378,28 @@ class PreparedRequest(RequestEncodingMixin, RequestHooksMixin):
             if query:
                 query = '%s&%s' % (query, enc_params)
             else:
-                query = enc_params
-
-        url = requote_uri(urlunparse([scheme, netloc, path, None, query, fragment]))
+url = requote_uri(urlunparse([scheme, netloc, path, None, query, fragment]))
         self.url = url
 
     def prepare_headers(self, headers):
         """Prepares the given HTTP headers."""
 
+        if headers:
+            # Skip any headers whose value is None so they are not sent as the string "None".
+            self.headers = CaseInsensitiveDict(
+                (to_native_string(name), value)
+                for name, value in headers.items()
+                if value is not None
+            )
+        else:
+            self.headers = CaseInsensitiveDict()
+                for name, value in headers.items()
+                if value is not None
+            )
+        else:
+            self.headers = CaseInsensitiveDict()
+        """Prepares the given HTTP headers."""
+
         if headers:
             self.headers = CaseInsensitiveDict((to_native_string(name), value) for name, value in headers.items())
         else:
Saved trajectory to 'results23/astropy__astropy-7166/astropy__astropy-7166.traj.json'
Completed instance astropy__astropy-7166, result: diff --git a/astropy/utils/misc.py b/astropy/utils/misc.py
index de3fb01d1..6a92d7a7e 100644
--- a/astropy/utils/misc.py
+++ b/astropy/utils/misc.py
@@ -517,15 +517,24 @@ class InheritDocstrings(type):
         ...     def wiggle(self):
         ...         pass
         >>> B.wiggle.__doc__
-        u'Wiggle the thingamajig'
-    """
-
-    def __init__(cls, name, bases, dct):
-        def is_public_member(key):
-            return (
-                (key.startswith('__') and key.endswith('__')
-                 and len(key) > 4) or
-                not key.startswith('_'))
+for key, val in dct.items():
+              if (inspect.isfunction(val) and
+                  is_public_member(key) and
+                  val.__doc__ is None):
+                  for base in cls.__mro__[1:]:
+                      super_method = getattr(base, key, None)
+                      if super_method is not None:
+                          val.__doc__ = super_method.__doc__
+                          break
+              elif (isinstance(val, property) and
+                    is_public_member(key) and
+                    val.__doc__ is None):
+                  for base in cls.__mro__[1:]:
+                      super_prop = getattr(base, key, None)
+                      if isinstance(super_prop, property) and super_prop.__doc__ is not None:
+                          # replace the property in the class dict with one that has the inherited doc
+                          dct[key] = property(val.fget, val.fset, val.fdel, super_prop.__doc__)
+                          break
 
         for key, val in dct.items():
             if (inspect.isfunction(val) and
Saved trajectory to 'results23/sphinx-doc__sphinx-9230/sphinx-doc__sphinx-9230.traj.json'
Completed instance sphinx-doc__sphinx-9230, result: diff --git a/sphinx/ext/napoleon/docstring.py b/sphinx/ext/napoleon/docstring.py
index d8cb75a5f..a251761fd 100644
--- a/sphinx/ext/napoleon/docstring.py
+++ b/sphinx/ext/napoleon/docstring.py
@@ -1155,12 +1155,30 @@ class NumpyDocstring(GoogleDocstring):
         elif filepath is None:
             filepath = ""
 
-        return ":".join([filepath, "docstring of %s" % name])
-
-    def _escape_args_and_kwargs(self, name: str) -> str:
+def _escape_args_and_kwargs(self, name: str) -> str:
         func = super()._escape_args_and_kwargs
-
-        if ", " in name:
+        # Split on commas that are not inside any parentheses/brackets/braces.
+        if ", " not in name:
+            return func(name)
+        parts: List[str] = []
+        buf: List[str] = []
+        depth = 0
+        for ch in name:
+            if ch in "([{":
+                depth += 1
+            elif ch in ")]}":
+                if depth:
+                    depth -= 1
+            if ch == "," and depth == 0:
+                parts.append("".join(buf).strip())
+                buf = []
+                continue
+            buf.append(ch)
+        if buf:
+            parts.append("".join(buf).strip())
+        if len(parts) == 1:
+            return func(name)
+        return ", ".join(func(param) for param in parts)
             return ", ".join(func(param) for param in name.split(", "))
         else:
             return func(name)
Saved trajectory to 'results23/pytest-dev__pytest-7490/pytest-dev__pytest-7490.traj.json'
Completed instance pytest-dev__pytest-7490, result: diff --git a/src/_pytest/skipping.py b/src/_pytest/skipping.py
index 335e10996..015780b84 100644
--- a/src/_pytest/skipping.py
+++ b/src/_pytest/skipping.py
@@ -245,18 +245,15 @@ def pytest_runtest_setup(item: Item) -> None:
 
 
 @hookimpl(hookwrapper=True)
-def pytest_runtest_call(item: Item) -> Generator[None, None, None]:
-    xfailed = item._store.get(xfailed_key, None)
-    if xfailed is None:
-        item._store[xfailed_key] = xfailed = evaluate_xfail_marks(item)
-
-    if not item.config.option.runxfail:
+if not item.config.option.runxfail:
         if xfailed and not xfailed.run:
             xfail("[NOTRUN] " + xfailed.reason)
 
     yield
-
-
+    # Re-evaluate xfail marks if not yet evaluated (e.g., marker added during the test's call)
+    if xfailed is None:
+        xfailed = evaluate_xfail_marks(item)
+        item._store[xfailed_key] = xfailed
 @hookimpl(hookwrapper=True)
 def pytest_runtest_makereport(item: Item, call: CallInfo[None]):
     outcome = yield
Saved trajectory to 'results23/sphinx-doc__sphinx-9658/sphinx-doc__sphinx-9658.traj.json'
Completed instance sphinx-doc__sphinx-9658, result: diff --git a/sphinx/util/typing.py b/sphinx/util/typing.py
index 87707d48f..1ba0a1112 100644
--- a/sphinx/util/typing.py
+++ b/sphinx/util/typing.py
@@ -160,10 +160,7 @@ def _restify_py37(cls: Optional[Type]) -> str:
                 return ':py:obj:`~typing.Optional`\\ [:obj:`~typing.Union`\\ [%s]]' % args
             else:
                 return ':py:obj:`~typing.Optional`\\ [%s]' % restify(cls.__args__[0])
-        else:
-            args = ', '.join(restify(a) for a in cls.__args__)
-            return ':py:obj:`~typing.Union`\\ [%s]' % args
-    elif inspect.isgenericalias(cls):
+elif inspect.isgenericalias(cls):
         if isinstance(cls.__origin__, typing._SpecialForm):
             text = restify(cls.__origin__)  # type: ignore
         elif getattr(cls, '_name', None):
@@ -171,6 +168,10 @@ def _restify_py37(cls: Optional[Type]) -> str:
                 text = ':py:class:`~%s.%s`' % (cls.__module__, cls._name)
             else:
                 text = ':py:class:`%s.%s`' % (cls.__module__, cls._name)
+        else:
+            text = restify(cls.__origin__)
+                return ':py:obj:`%s.%s`' % (cls.__module__, name)
+                text = ':py:class:`%s.%s`' % (cls.__module__, cls._name)
         else:
             text = restify(cls.__origin__)
Saved trajectory to 'results23/scikit-learn__scikit-learn-26323/scikit-learn__scikit-learn-26323.traj.json'
Completed instance scikit-learn__scikit-learn-26323, result: diff --git a/sklearn/compose/_column_transformer.py b/sklearn/compose/_column_transformer.py
index 4eddd12b1..5d1ca21b8 100644
--- a/sklearn/compose/_column_transformer.py
+++ b/sklearn/compose/_column_transformer.py
@@ -263,48 +263,61 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):
             return self.transformers
 
     @_transformers.setter
-    def _transformers(self, value):
-        try:
-            self.transformers = [
-                (name, trans, col)
-                for ((name, trans), (_, _, col)) in zip(value, self.transformers)
-            ]
-        except (TypeError, ValueError):
-            self.transformers = value
+@_transformers.setter
+def _transformers(self, value):
+    try:
+        self.transformers = [
+            (name, trans, col)
+            for ((name, trans), (_, _, col)) in zip(value, self.transformers)
+        ]
+    except (TypeError, ValueError):
+        self.transformers = value
 
-    def set_output(self, *, transform=None):
-        """Set the output container when `"transform"` and `"fit_transform"` are called.
+def set_output(self, *, transform=None):
+    """Set the output container when `"transform"` and `"fit_transform"` are called.
 
-        Calling `set_output` will set the output of all estimators in `transformers`
-        and `transformers_`.
+    Calling `set_output` will set the output of all estimators in `transformers`
+    and `transformers_`.
 
-        Parameters
-        ----------
-        transform : {"default", "pandas"}, default=None
-            Configure output of `transform` and `fit_transform`.
+    Parameters
+    ----------
+    transform : {"default", "pandas"}, default=None
+        Configure output of `transform` and `fit_transform`.
 
-            - `"default"`: Default output format of a transformer
-            - `"pandas"`: DataFrame output
-            - `None`: Transform configuration is unchanged
+        - `"default"`: Default output format of a transformer
+        - `"pandas"`: DataFrame output
+        - `None`: Transform configuration is unchanged
 
-        Returns
-        -------
-        self : estimator instance
-            Estimator instance.
-        """
-        super().set_output(transform=transform)
-        transformers = (
-            trans
-            for _, trans, _ in chain(
-                self.transformers, getattr(self, "transformers_", [])
-            )
-            if trans not in {"passthrough", "drop"}
+    Returns
+    -------
+    self : estimator instance
+        Estimator instance.
+    """
+    super().set_output(transform=transform)
+    # Set output for all named transformers (excluding "passthrough" and "drop").
+    transformers = (
+        trans
+        for _, trans, _ in chain(
+            self.transformers, getattr(self, "transformers_", [])
         )
-        for trans in transformers:
-            _safe_set_output(trans, transform=transform)
+        if trans not in {"passthrough", "drop"}
+    )
 
-        return self
+    # Include the remainder transformer if it is an estimator (not "passthrough"/"drop").
+    remainder_trans = None
+    if hasattr(self, "_remainder"):
+        # self._remainder is a tuple ('remainder', transformer, columns)
+        _, rem_trans, _ = self._remainder
+        if rem_trans not in {"passthrough", "drop"}:
+            remainder_trans = rem_trans
+    else:
+        if self.remainder not in {"passthrough", "drop"}:
+            remainder_trans = self.remainder
+
+    for trans in chain(transformers, [remainder_trans] if remainder_trans is not None else []):
+        _safe_set_output(trans, transform=transform)
 
+    return self
     def get_params(self, deep=True):
         """Get parameters for this estimator.
Saved trajectory to 'results23/sympy__sympy-17655/sympy__sympy-17655.traj.json'
Completed instance sympy__sympy-17655, result: diff --git a/sympy/geometry/point.py b/sympy/geometry/point.py
index 7c978c47be..e58295c52d 100644
--- a/sympy/geometry/point.py
+++ b/sympy/geometry/point.py
@@ -145,34 +145,57 @@ def __new__(cls, *args, **kwargs):
                 raise ValueError(message)
             elif on_morph == 'warn':
                 warnings.warn(message)
-            else:
-                raise ValueError(filldedent('''
-                        on_morph value should be 'error',
-                        'warn' or 'ignore'.'''))
-        if any(coords[dim:]):
-            raise ValueError('Nonzero coordinates cannot be removed.')
-        if any(a.is_number and im(a) for a in coords):
-            raise ValueError('Imaginary coordinates are not permitted.')
-        if not all(isinstance(a, Expr) for a in coords):
-            raise TypeError('Coordinates must be valid SymPy expressions.')
-
-        # pad with zeros appropriately
-        coords = coords[:dim] + (S.Zero,)*(dim - len(coords))
-
-        # Turn any Floats into rationals and simplify
-        # any expressions before we instantiate
-        if evaluate:
-            coords = coords.xreplace(dict(
-                [(f, simplify(nsimplify(f, rational=True)))
-                 for f in coords.atoms(Float)]))
-
-        # return 2D or 3D instances
-        if len(coords) == 2:
-            kwargs['_nocheck'] = True
-            return Point2D(*coords, **kwargs)
-        elif len(coords) == 3:
-            kwargs['_nocheck'] = True
-            return Point3D(*coords, **kwargs)
+def __add__(self, other):
+        """Add other to self by incrementing self's coordinates by
+        those of other.
+    
+        Notes
+        =====
+    
+        >>> from sympy.geometry.point import Point
+    
+        When sequences of coordinates are passed to Point methods, they
+        are converted to a Point internally. This __add__ method does
+        not do that so if floating point values are used, a floating
+        point result (in terms of SymPy Floats) will be returned.
+    
+        >>> Point(1, 2) + (.1, .2)
+        Point2D(1.1, 2.2)
+    
+        If this is not desired, the `translate` method can be used or
+        another Point can be added:
+    
+        >>> Point(1, 2).translate(.1, .2)
+        Point2D(11/10, 11/5)
+        >>> Point(1, 2) + Point(.1, .2)
+        Point2D(11/10, 11/5)
+    
+        See Also
+        ========
+    
+        sympy.geometry.point.Point.translate
+    
+        """
+        # Handle cases like 2*Point(...) where the left operand's Mul was
+        # constructed by SymPy (so scalar.__mul__(Point) returned a Mul).
+        # Convert such Mul into Point * scalar so Point.__mul__ is used.
+        if getattr(other, 'is_Mul', False):
+            for arg in other.args:
+                if isinstance(arg, Point):
+                    scalar = S.One
+                    for a in other.args:
+                        if a is not arg:
+                            scalar = scalar * a
+                    other = arg * scalar
+                    break
+
+        try:
+            s, o = Point._normalize_dimension(self, Point(other, evaluate=False))
+        except TypeError:
+            raise GeometryError("Don't know how to add {} and a Point object".format(other))
+    
+        coords = [simplify(a + b) for a, b in zip(s, o)]
+        return Point(coords, evaluate=False)
 
         # the general Point
         return GeometryEntity.__new__(cls, *coords)
Saved trajectory to 'results23/sphinx-doc__sphinx-7590/sphinx-doc__sphinx-7590.traj.json'
Completed instance sphinx-doc__sphinx-7590, result: diff --git a/sphinx/domains/cpp.py b/sphinx/domains/cpp.py
index fe52d881d..8d58e9f29 100644
--- a/sphinx/domains/cpp.py
+++ b/sphinx/domains/cpp.py
@@ -871,17 +871,39 @@ class ASTCharLiteral(ASTLiteral):
         if self.prefix is None:
             return "'" + self.data + "'"
         else:
-            return self.prefix + "'" + self.data + "'"
-
-    def get_id(self, version: int) -> str:
+def get_id(self, version: int) -> str:
         return self.type + str(self.value)
-
+    
     def describe_signature(self, signode: TextElement, mode: str,
                            env: "BuildEnvironment", symbol: "Symbol") -> None:
         txt = str(self)
         signode.append(nodes.Text(txt, txt))
+        txt = str(self)
+        signode.append(nodes.Text(txt, txt))
+
+
+class ASTUserDefinedLiteral(ASTLiteral):
+        def __init__(self, operand: ASTLiteral, suffix: str) -> None:
+            # operand is the literal (number, string, or char) the UDL is attached to
+            self.operand = operand
+            self.suffix = suffix
 
+        def _stringify(self, transform: StringifyTransform) -> str:
+            # Represent the UDL as the operand followed immediately by the suffix
+            return transform(self.operand) + self.suffix
 
+        def get_id(self, version: int) -> str:
+            # Include the operand id (when available) and the suffix for uniqueness
+            try:
+                op_id = self.operand.get_id(version)
+            except Exception:
+                op_id = str(self.operand)
+            return "LUDL_%s_%s" % (self.suffix, op_id)
+
+        def describe_signature(self, signode: TextElement, mode: str,
+                               env: "BuildEnvironment", symbol: "Symbol") -> None:
+            txt = str(self)
+            signode.append(nodes.Text(txt, txt))
 class ASTThisLiteral(ASTExpression):
     def _stringify(self, transform: StringifyTransform) -> str:
         return "this"
@@ -4653,34 +4675,61 @@ class DefinitionParser(BaseParser):
         #  | user-defined-literal
         self.skip_ws()
         if self.skip_word('nullptr'):
-            return ASTPointerLiteral()
-        if self.skip_word('true'):
-            return ASTBooleanLiteral(True)
-        if self.skip_word('false'):
-            return ASTBooleanLiteral(False)
-        for regex in [float_literal_re, binary_literal_re, hex_literal_re,
+for regex in [float_literal_re, binary_literal_re, hex_literal_re,
                       integer_literal_re, octal_literal_re]:
             pos = self.pos
             if self.match(regex):
                 while self.current_char in 'uUlLfF':
                     self.pos += 1
+                # detect user-defined-literal suffix (identifier) immediately after literal
+                if (self.current_char is not None and
+                        (self.current_char.isalpha() or self.current_char == '_')):
+                    start_suffix = self.pos
+                    while (self.current_char is not None and
+                           (self.current_char.isalnum() or self.current_char == '_')):
+                        self.pos += 1
+                    suffix = self.definition[start_suffix:self.pos]
+                    number_text = self.definition[pos:start_suffix]
+                    num_node = ASTNumberLiteral(number_text)
+                    return ASTUserDefinedLiteral(num_node, suffix)
                 return ASTNumberLiteral(self.definition[pos:self.pos])
-
-        string = self._parse_string()
+string = self._parse_string()
         if string is not None:
+            # check for ud-suffix after string literal
+            if (self.current_char is not None and
+                    (self.current_char.isalpha() or self.current_char == '_')):
+                start_suffix = self.pos
+                while (self.current_char is not None and
+                       (self.current_char.isalnum() or self.current_char == '_')):
+                    self.pos += 1
+                suffix = self.definition[start_suffix:self.pos]
+                str_node = ASTStringLiteral(string)
+                return ASTUserDefinedLiteral(str_node, suffix)
             return ASTStringLiteral(string)
-
+    
         # character-literal
         if self.match(char_literal_re):
             prefix = self.last_match.group(1)  # may be None when no prefix
             data = self.last_match.group(2)
             try:
-                return ASTCharLiteral(prefix, data)
+                char_node = ASTCharLiteral(prefix, data)
             except UnicodeDecodeError as e:
                 self.fail("Can not handle character literal. Internal error was: %s" % e)
             except UnsupportedMultiCharacterCharLiteral:
                 self.fail("Can not handle character literal"
                           " resulting in multiple decoded characters.")
+            # check for ud-suffix after char literal
+            if (self.current_char is not None and
+                    (self.current_char.isalpha() or self.current_char == '_')):
+                start_suffix = self.pos
+                while (self.current_char is not None and
+                       (self.current_char.isalnum() or self.current_char == '_')):
+                    self.pos += 1
+                suffix = self.definition[start_suffix:self.pos]
+                return ASTUserDefinedLiteral(char_node, suffix)
+            return char_node
+                self.fail("Can not handle character literal"
+                          " resulting in multiple decoded characters.")
 
         # TODO: user-defined lit
         return None
Saved trajectory to 'results23/sympy__sympy-24213/sympy__sympy-24213.traj.json'
Completed instance sympy__sympy-24213, result: diff --git a/sympy/physics/units/unitsystem.py b/sympy/physics/units/unitsystem.py
index a436880c4b..54f51142bc 100644
--- a/sympy/physics/units/unitsystem.py
+++ b/sympy/physics/units/unitsystem.py
@@ -120,14 +120,7 @@ def is_consistent(self):
         """
         Check if the underlying dimension system is consistent.
         """
-        # test is performed in DimensionSystem
-        return self.get_dimension_system().is_consistent
-
-    @property
-    def derived_units(self) -> tDict[Dimension, Quantity]:
-        return self._derived_units
-
-    def get_dimensional_expr(self, expr):
+def get_dimensional_expr(self, expr):
         from sympy.physics.units import Quantity
         if isinstance(expr, Mul):
             return Mul(*[self.get_dimensional_expr(i) for i in expr.args])
@@ -148,6 +141,13 @@ def get_dimensional_expr(self, expr):
         elif isinstance(expr, Quantity):
             return self.get_quantity_dimension(expr).name
         return S.One
+                       ds.get_dimensional_dependencies(addend_dim, mark_dimensionless=True):
+                        raise ValueError(
+                            'Dimension of "{}" is {}, '
+                            'but it should be {}'.format(
+                                addend, addend_dim, dim))
+                    factor += addend_factor
+                return factor, dim
 
     def _collect_factor_and_dimension(self, expr):
         """
Saved trajectory to 'results23/django__django-7530/django__django-7530.traj.json'
Completed instance django__django-7530, result: diff --git a/django/core/management/commands/makemigrations.py b/django/core/management/commands/makemigrations.py
index 0b39536f5b..ee2abef5d6 100644
--- a/django/core/management/commands/makemigrations.py
+++ b/django/core/management/commands/makemigrations.py
@@ -89,25 +89,16 @@ class Command(BaseCommand):
         if bad_app_labels:
             for app_label in bad_app_labels:
                 self.stderr.write("App '%s' could not be found. Is it in INSTALLED_APPS?" % app_label)
-            sys.exit(2)
-
-        # Load the current graph state. Pass in None for the connection so
-        # the loader doesn't try to resolve replaced migrations from DB.
-        loader = MigrationLoader(None, ignore_no_migrations=True)
-
-        # Raise an error if any migrations are applied before their dependencies.
-        consistency_check_labels = set(config.label for config in apps.get_app_configs())
-        # Non-default databases are only checked if database routers used.
-        aliases_to_check = connections if settings.DATABASE_ROUTERS else [DEFAULT_DB_ALIAS]
-        for alias in sorted(aliases_to_check):
+for alias in sorted(aliases_to_check):
             connection = connections[alias]
             if (connection.settings_dict['ENGINE'] != 'django.db.backends.dummy' and any(
                     # At least one model must be migrated to the database.
                     router.allow_migrate(connection.alias, app_label, model_name=model._meta.object_name)
                     for app_label in consistency_check_labels
-                    for model in apps.get_models(app_label)
+                    for model in apps.get_app_config(app_label).get_models()
             )):
                 loader.check_consistent_history(connection)
+                loader.check_consistent_history(connection)
 
         # Before anything else, see if there's conflicting apps and drop out
         # hard if there are any and they don't want to merge
Saved trajectory to 'results23/django__django-11179/django__django-11179.traj.json'
Completed instance django__django-11179, result: diff --git a/django/db/models/deletion.py b/django/db/models/deletion.py
index 92fe4affb9..e7483772c6 100644
--- a/django/db/models/deletion.py
+++ b/django/db/models/deletion.py
@@ -265,16 +265,15 @@ class Collector:
             self.data[model] = sorted(instances, key=attrgetter("pk"))
 
         # if possible, bring the models in an order suitable for databases that
-        # don't support transactions or cannot defer constraint checks until the
-        # end of a transaction.
-        self.sort()
-        # number of objects deleted for each model label
-        deleted_counter = Counter()
-
-        # Optimize for the case with a single obj and no dependencies
-        if len(self.data) == 1 and len(instances) == 1:
-            instance = list(instances)[0]
-            if self.can_fast_delete(instance):
+# Optimize for the case with a single obj and no dependencies
+    if len(self.data) == 1 and len(instances) == 1:
+        instance = list(instances)[0]
+        if self.can_fast_delete(instance):
+            with transaction.mark_for_rollback_on_error():
+                count = sql.DeleteQuery(model).delete_batch([instance.pk], self.using)
+            # Clear the primary key on the instance since it has been deleted from the DB.
+            instance.pk = None
+            return count, {model._meta.label: count}
                 with transaction.mark_for_rollback_on_error():
                     count = sql.DeleteQuery(model).delete_batch([instance.pk], self.using)
                 return count, {model._meta.label: count}
Saved trajectory to 'results23/django__django-16631/django__django-16631.traj.json'
Completed instance django__django-16631, result: diff --git a/docs/ref/settings.txt b/docs/ref/settings.txt
index 41387886c0..74ef84dd4b 100644
--- a/docs/ref/settings.txt
+++ b/docs/ref/settings.txt
@@ -2293,14 +2293,16 @@ passwords of users and key rotation will not affect them.
 
 .. setting:: SECRET_KEY_FALLBACKS
 
-``SECRET_KEY_FALLBACKS``
-------------------------
-
-Default: ``[]``
-
 A list of fallback secret keys for a particular Django installation. These are
 used to allow rotation of the ``SECRET_KEY``.
 
+In order to rotate your secret keys, set a new ``SECRET_KEY`` and move the
+previous value to the beginning of ``SECRET_KEY_FALLBACKS``. Note that not all
+uses of ``SECRET_KEY`` consult ``SECRET_KEY_FALLBACKS``; for example,
+``AbstractBaseUser.get_session_auth_hash()`` (used to validate logged-in sessions)
+uses the current ``SECRET_KEY`` only, so changing ``SECRET_KEY`` will invalidate
+existing sessions even if previous keys are present in
+
 In order to rotate your secret keys, set a new ``SECRET_KEY`` and move the
 previous value to the beginning of ``SECRET_KEY_FALLBACKS``. Then remove the
 old values from the end of the ``SECRET_KEY_FALLBACKS`` when you are ready to
Saved trajectory to 'results23/django__django-14053/django__django-14053.traj.json'
Completed instance django__django-14053, result: diff --git a/django/contrib/staticfiles/storage.py b/django/contrib/staticfiles/storage.py
index 494890cc23..b1a5f811aa 100644
--- a/django/contrib/staticfiles/storage.py
+++ b/django/contrib/staticfiles/storage.py
@@ -228,23 +228,30 @@ class HashedFilesMixin:
         ]
         # Do a single pass first. Post-process all files once, then repeat for
         # adjustable files.
+        results = {}
         for name, hashed_name, processed, _ in self._post_process(paths, adjustable_paths, hashed_files):
-            yield name, hashed_name, processed
+            results[name] = (hashed_name, processed)
 
         paths = {path: paths[path] for path in adjustable_paths}
 
         for i in range(self.max_post_process_passes):
             substitutions = False
             for name, hashed_name, processed, subst in self._post_process(paths, adjustable_paths, hashed_files):
-                yield name, hashed_name, processed
+                # Keep the latest result for each original name so we only yield once,
+                # with the final hashed name/processed flag after all passes.
+                results[name] = (hashed_name, processed)
                 substitutions = substitutions or subst
 
             if not substitutions:
                 break
 
         if substitutions:
+            # If we exceeded max passes, preserve previous behavior of signaling error.
             yield 'All', None, RuntimeError('Max post-process passes exceeded.')
 
+        # After all passes are complete, yield each file exactly once with its final values.
+        for name, (hashed_name, processed) in results.items():
+            yield name, hashed_name, processed
         # Store the processed paths
         self.hashed_files.update(hashed_files)
Saved trajectory to 'results23/django__django-16662/django__django-16662.traj.json'
Completed instance django__django-16662, result: diff --git a/django/db/migrations/writer.py b/django/db/migrations/writer.py
index a59f0c8dcb..4094522ada 100644
--- a/django/db/migrations/writer.py
+++ b/django/db/migrations/writer.py
@@ -148,10 +148,15 @@ class MigrationWriter:
         for dependency in self.migration.dependencies:
             if dependency[0] == "__setting__":
                 dependencies.append(
-                    "        migrations.swappable_dependency(settings.%s),"
-                    % dependency[1]
-                )
-                imports.add("from django.conf import settings")
+# Sort imports so that module-style imports (import X) come before
+          # from-style imports (from X import Y), then sort by the module/package.
+          def _import_sort_key(i):
+              parts = i.split()
+              if parts[0] == 'import':
+                  return (0, parts[1])
+              return (1, parts[1])
+          sorted_imports = sorted(imports, key=_import_sort_key)
+          items["imports"] = "\n".join(sorted_imports) + "\n" if imports else ""
             else:
                 dependencies.append("        %s," % self.serialize(dependency)[0])
         items["dependencies"] = "\n".join(dependencies) + "\n" if dependencies else ""
Saved trajectory to 'results23/django__django-14011/django__django-14011.traj.json'
Completed instance django__django-14011, result: diff --git a/django/core/servers/basehttp.py b/django/core/servers/basehttp.py
index 14dab517c9..6e77465745 100644
--- a/django/core/servers/basehttp.py
+++ b/django/core/servers/basehttp.py
@@ -30,24 +30,11 @@ def get_internal_wsgi_application():
     this will be the ``application`` object in ``projectname/wsgi.py``.
 
     This function, and the ``WSGI_APPLICATION`` setting itself, are only useful
-    for Django's internal server (runserver); external WSGI servers should just
-    be configured to point to the correct application object directly.
-
-    If settings.WSGI_APPLICATION is not set (is ``None``), return
-    whatever ``django.core.wsgi.get_wsgi_application`` returns.
-    """
-    from django.conf import settings
-    app_path = getattr(settings, 'WSGI_APPLICATION')
-    if app_path is None:
-        return get_wsgi_application()
-
-    try:
-        return import_string(app_path)
-    except ImportError as err:
-        raise ImproperlyConfigured(
-            "WSGI application '%s' could not be loaded; "
-            "Error importing module." % app_path
-        ) from err
+except ImportError as err:
+          raise ImproperlyConfigured(
+              "WSGI application '%s' could not be loaded; "
+              "Error importing module." % app_path
+          ) from err
 
 
 def is_broken_pipe_error():
@@ -77,6 +64,25 @@ class WSGIServer(simple_server.WSGIServer):
             super().handle_error(request, client_address)
 
 
+class ThreadedWSGIServer(socketserver.ThreadingMixIn, WSGIServer):
+    """A threaded version of the WSGIServer"""
+    daemon_threads = False
+            logger.info("- Broken pipe from %s\n", client_address)
+        else:
+            super().handle_error(request, client_address)
+
+
+class ThreadedWSGIServer(socketserver.ThreadingMixIn, WSGIServer):
+    """A threaded version of the WSGIServer"""
+    daemon_threads = False
+
+    def handle_error(self, request, client_address):
+        if is_broken_pipe_error():
+            logger.info("- Broken pipe from %s\n", client_address)
+        else:
+            super().handle_error(request, client_address)
+
+
 class ThreadedWSGIServer(socketserver.ThreadingMixIn, WSGIServer):
     """A threaded version of the WSGIServer"""
     daemon_threads = True
Saved trajectory to 'results23/django__django-10973/django__django-10973.traj.json'
Completed instance django__django-10973, result: diff --git a/django/db/backends/postgresql/client.py b/django/db/backends/postgresql/client.py
index 7fca6eff30..28e60cab92 100644
--- a/django/db/backends/postgresql/client.py
+++ b/django/db/backends/postgresql/client.py
@@ -18,29 +18,22 @@ class DatabaseClient(BaseDatabaseClient):
 
     @classmethod
     def runshell_db(cls, conn_params):
-        args = [cls.executable_name]
-
-        host = conn_params.get('host', '')
-        port = conn_params.get('port', '')
-        dbname = conn_params.get('database', '')
-        user = conn_params.get('user', '')
-        passwd = conn_params.get('password', '')
-
-        if user:
-            args += ['-U', user]
-        if host:
-            args += ['-h', host]
-        if port:
-            args += ['-p', str(port)]
-        args += [dbname]
-
-        temp_pgpass = None
+temp_pgpass = None
+        env = None
         sigint_handler = signal.getsignal(signal.SIGINT)
         try:
             if passwd:
-                # Create temporary .pgpass file.
-                temp_pgpass = NamedTemporaryFile(mode='w+')
+                # Prefer PGPASSWORD in the child environment to avoid a temporary .pgpass file.
                 try:
+                    env = os.environ.copy()
+                    env['PGPASSWORD'] = passwd
+                except UnicodeEncodeError:
+                    # Fallback to temporary .pgpass file if the password can't be encoded.
+                    temp_pgpass = NamedTemporaryFile(mode='w+')
+                    try:
+                    # If the current locale can't encode the data, let the
+                    # user input the password manually (leave env as None).
+                    env = None
                     print(
                         _escape_pgpass(host) or '*',
                         str(port) or '*',
Saved trajectory to 'results23/django__django-13297/django__django-13297.traj.json'
Completed instance django__django-13297, result: diff --git a/django/views/generic/base.py b/django/views/generic/base.py
index ea5baca08d..95daeff4bd 100644
--- a/django/views/generic/base.py
+++ b/django/views/generic/base.py
@@ -12,10 +12,6 @@ from django.urls import reverse
 from django.utils.decorators import classonlymethod
 from django.utils.deprecation import RemovedInDjango40Warning
 from django.utils.functional import SimpleLazyObject
-
-logger = logging.getLogger('django.request')
-
-
 class ContextMixin:
     """
     A default context mixin that passes the keyword arguments received by
@@ -27,6 +23,12 @@ class ContextMixin:
         kwargs.setdefault('view', self)
         if self.extra_context is not None:
             kwargs.update(self.extra_context)
+        # Resolve any SimpleLazyObject values (e.g. wrapped URL kwargs) to concrete values
+        for key, value in list(kwargs.items()):
+            if isinstance(value, SimpleLazyObject):
+                # URL kwargs are expected to be strings; force evaluation.
+                kwargs[key] = str(value)
+        return kwargs
         return kwargs
Saved trajectory to 'results23/django__django-12406/django__django-12406.traj.json'
Completed instance django__django-12406, result: diff --git a/django/forms/models.py b/django/forms/models.py
index dafc11f995..aeb86bfb1e 100644
--- a/django/forms/models.py
+++ b/django/forms/models.py
@@ -133,14 +133,7 @@ def fields_for_model(model, fields=None, exclude=None, widgets=None,
     ``field_classes`` is a dictionary of model field names mapped to a form
     field class.
 
-    ``apply_limit_choices_to`` is a boolean indicating if limit_choices_to
-    should be applied to a field's queryset.
-    """
-    field_dict = {}
-    ignored = []
-    opts = model._meta
-    # Avoid circular import
-    from django.db.models import Field as ModelField
+from django.db.models import Field as ModelField
     sortable_private_fields = [f for f in opts.private_fields if isinstance(f, ModelField)]
     for f in sorted(chain(opts.concrete_fields, sortable_private_fields, opts.many_to_many)):
         if not getattr(f, 'editable', False):
@@ -151,6 +144,18 @@ def fields_for_model(model, fields=None, exclude=None, widgets=None,
                         f.name, model.__name__)
                 )
             continue
+            if _RadioSelect is not None and issubclass(widget_cls, _RadioSelect) and getattr(f, 'blank', True) is False:
+                kwargs.setdefault('empty_label', None)
+        formfield = f.formfield(**kwargs)
+    elif not callable(formfield_callback):
+        raise TypeError('formfield_callback must be a function or callable')
+    else:
+        formfield = formfield_callback(f, **kwargs)
+                raise FieldError(
+                    "'%s' cannot be specified for %s model form as it is a non-editable field" % (
+                        f.name, model.__name__)
+                )
+            continue
         if fields is not None and f.name not in fields:
             continue
         if exclude and f.name in exclude:
@@ -169,12 +174,24 @@ def fields_for_model(model, fields=None, exclude=None, widgets=None,
             kwargs['error_messages'] = error_messages[f.name]
         if field_classes and f.name in field_classes:
             kwargs['form_class'] = field_classes[f.name]
-
-        if formfield_callback is None:
-            formfield = f.formfield(**kwargs)
-        elif not callable(formfield_callback):
-            raise TypeError('formfield_callback must be a function or callable')
-        else:
+if formfield_callback is None:
+        # If a RadioSelect widget is explicitly provided for a related field
+        # and the model field doesn't allow blank, don't add an empty choice.
+        widget = kwargs.get('widget')
+        if widget is not None:
+            # widget may be a class or an instance
+            widget_cls = widget if isinstance(widget, type) else widget.__class__
+            try:
+                from django.forms.widgets import RadioSelect as _RadioSelect
+            except Exception:
+                _RadioSelect = None
+            if _RadioSelect is not None and issubclass(widget_cls, _RadioSelect) and getattr(f, 'blank', True) is False:
+                kwargs.setdefault('empty_label', None)
+        formfield = f.formfield(**kwargs)
+    elif not callable(formfield_callback):
+        raise TypeError('formfield_callback must be a function or callable')
+    else:
+        formfield = formfield_callback(f, **kwargs)
             formfield = formfield_callback(f, **kwargs)
 
         if formfield:
Saved trajectory to 'results23/django__django-13810/django__django-13810.traj.json'
Completed instance django__django-13810, result: diff --git a/django/core/handlers/base.py b/django/core/handlers/base.py
index 8e8c3da06a..1ec2e714da 100644
--- a/django/core/handlers/base.py
+++ b/django/core/handlers/base.py
@@ -29,18 +29,18 @@ class BaseHandler:
 
         Must be called after the environment is fixed (see __call__ in subclasses).
         """
-        self._view_middleware = []
-        self._template_response_middleware = []
-        self._exception_middleware = []
-
-        get_response = self._get_response_async if is_async else self._get_response
-        handler = convert_exception_to_response(get_response)
-        handler_is_async = is_async
-        for middleware_path in reversed(settings.MIDDLEWARE):
-            middleware = import_string(middleware_path)
-            middleware_can_sync = getattr(middleware, 'sync_capable', True)
-            middleware_can_async = getattr(middleware, 'async_capable', False)
-            if not middleware_can_sync and not middleware_can_async:
+middleware_can_sync = getattr(middleware, 'sync_capable', True)
+                middleware_can_async = getattr(middleware, 'async_capable', False)
+                if not middleware_can_sync and not middleware_can_async:
+                    raise RuntimeError(
+                        'Middleware %s must have at least one of '
+                        'sync_capable/async_capable set to True.' % middleware_path
+                    )
+                elif not handler_is_async and middleware_can_sync:
+                    middleware_is_async = False
+                else:
+                    middleware_is_async = middleware_can_async
+if not middleware_can_sync and not middleware_can_async:
                 raise RuntimeError(
                     'Middleware %s must have at least one of '
                     'sync_capable/async_capable set to True.' % middleware_path
@@ -50,11 +50,22 @@ class BaseHandler:
             else:
                 middleware_is_async = middleware_can_async
             try:
-                # Adapt handler, if needed.
-                handler = self.adapt_method_mode(
+                # Adapt handler, if needed, but don't overwrite the current handler
+                # until we know the middleware will be used. Use a candidate_handler
+                # for instantiation to avoid "poisoning" the chain when
+                # MiddlewareNotUsed is raised.
+                candidate_handler = self.adapt_method_mode(
                     middleware_is_async, handler, handler_is_async,
                     debug=settings.DEBUG, name='middleware %s' % middleware_path,
                 )
+                mw_instance = middleware(candidate_handler)
+            except MiddlewareNotUsed as exc:
+                if settings.DEBUG:
+                    if str(exc):
+                        logger.debug('MiddlewareNotUsed(%r): %s', middleware_path, exc)
+                    else:
+                        logger.debug('MiddlewareNotUsed: %r', middleware_path)
+                continue
                 mw_instance = middleware(handler)
             except MiddlewareNotUsed as exc:
                 if settings.DEBUG:
