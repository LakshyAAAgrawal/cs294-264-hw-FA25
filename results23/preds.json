{
  "psf__requests-2931": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "psf__requests-2931",
    "model_patch": "diff --git a/requests/utils.py b/requests/utils.py\nindex 132cd2b..afcf187 100644\n--- a/requests/utils.py\n+++ b/requests/utils.py\n@@ -697,7 +697,16 @@ def to_native_string(string, encoding='ascii'):\n         if is_py2:\n             out = string.encode(encoding)\n         else:\n-            out = string.decode(encoding)\n+            # On Python 3 we may be passed a bytes instance. Decode bytes using\n+            # UTF-8 first (for common usage), falling back to the provided\n+            # encoding on failure. For non-bytes, coerce to str.\n+            if isinstance(string, bytes):\n+                try:\n+                    out = string.decode('utf-8')\n+                except UnicodeDecodeError:\n+                    out = string.decode(encoding)\n+            else:\n+                out = str(string)\n \n     return out"
  },
  "psf__requests-1921": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "psf__requests-1921",
    "model_patch": "diff --git a/requests/models.py b/requests/models.py\nindex cd232e6..5c813b3 100644\n--- a/requests/models.py\n+++ b/requests/models.py\n@@ -361,11 +361,7 @@ class PreparedRequest(RequestEncodingMixin, RequestHooksMixin):\n         if port:\n             netloc += ':' + str(port)\n \n-        # Bare domains aren't valid URLs.\n-        if not path:\n-            path = '/'\n-\n-        if is_py2:\n+if is_py2:\n             if isinstance(scheme, str):\n                 scheme = scheme.encode('utf-8')\n             if isinstance(netloc, str):\n@@ -382,14 +378,28 @@ class PreparedRequest(RequestEncodingMixin, RequestHooksMixin):\n             if query:\n                 query = '%s&%s' % (query, enc_params)\n             else:\n-                query = enc_params\n-\n-        url = requote_uri(urlunparse([scheme, netloc, path, None, query, fragment]))\n+url = requote_uri(urlunparse([scheme, netloc, path, None, query, fragment]))\n         self.url = url\n \n     def prepare_headers(self, headers):\n         \"\"\"Prepares the given HTTP headers.\"\"\"\n \n+        if headers:\n+            # Skip any headers whose value is None so they are not sent as the string \"None\".\n+            self.headers = CaseInsensitiveDict(\n+                (to_native_string(name), value)\n+                for name, value in headers.items()\n+                if value is not None\n+            )\n+        else:\n+            self.headers = CaseInsensitiveDict()\n+                for name, value in headers.items()\n+                if value is not None\n+            )\n+        else:\n+            self.headers = CaseInsensitiveDict()\n+        \"\"\"Prepares the given HTTP headers.\"\"\"\n+\n         if headers:\n             self.headers = CaseInsensitiveDict((to_native_string(name), value) for name, value in headers.items())\n         else:"
  },
  "astropy__astropy-7166": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "astropy__astropy-7166",
    "model_patch": "diff --git a/astropy/utils/misc.py b/astropy/utils/misc.py\nindex de3fb01d1..6a92d7a7e 100644\n--- a/astropy/utils/misc.py\n+++ b/astropy/utils/misc.py\n@@ -517,15 +517,24 @@ class InheritDocstrings(type):\n         ...     def wiggle(self):\n         ...         pass\n         >>> B.wiggle.__doc__\n-        u'Wiggle the thingamajig'\n-    \"\"\"\n-\n-    def __init__(cls, name, bases, dct):\n-        def is_public_member(key):\n-            return (\n-                (key.startswith('__') and key.endswith('__')\n-                 and len(key) > 4) or\n-                not key.startswith('_'))\n+for key, val in dct.items():\n+              if (inspect.isfunction(val) and\n+                  is_public_member(key) and\n+                  val.__doc__ is None):\n+                  for base in cls.__mro__[1:]:\n+                      super_method = getattr(base, key, None)\n+                      if super_method is not None:\n+                          val.__doc__ = super_method.__doc__\n+                          break\n+              elif (isinstance(val, property) and\n+                    is_public_member(key) and\n+                    val.__doc__ is None):\n+                  for base in cls.__mro__[1:]:\n+                      super_prop = getattr(base, key, None)\n+                      if isinstance(super_prop, property) and super_prop.__doc__ is not None:\n+                          # replace the property in the class dict with one that has the inherited doc\n+                          dct[key] = property(val.fget, val.fset, val.fdel, super_prop.__doc__)\n+                          break\n \n         for key, val in dct.items():\n             if (inspect.isfunction(val) and"
  },
  "sphinx-doc__sphinx-9230": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-9230",
    "model_patch": "diff --git a/sphinx/ext/napoleon/docstring.py b/sphinx/ext/napoleon/docstring.py\nindex d8cb75a5f..a251761fd 100644\n--- a/sphinx/ext/napoleon/docstring.py\n+++ b/sphinx/ext/napoleon/docstring.py\n@@ -1155,12 +1155,30 @@ class NumpyDocstring(GoogleDocstring):\n         elif filepath is None:\n             filepath = \"\"\n \n-        return \":\".join([filepath, \"docstring of %s\" % name])\n-\n-    def _escape_args_and_kwargs(self, name: str) -> str:\n+def _escape_args_and_kwargs(self, name: str) -> str:\n         func = super()._escape_args_and_kwargs\n-\n-        if \", \" in name:\n+        # Split on commas that are not inside any parentheses/brackets/braces.\n+        if \", \" not in name:\n+            return func(name)\n+        parts: List[str] = []\n+        buf: List[str] = []\n+        depth = 0\n+        for ch in name:\n+            if ch in \"([{\":\n+                depth += 1\n+            elif ch in \")]}\":\n+                if depth:\n+                    depth -= 1\n+            if ch == \",\" and depth == 0:\n+                parts.append(\"\".join(buf).strip())\n+                buf = []\n+                continue\n+            buf.append(ch)\n+        if buf:\n+            parts.append(\"\".join(buf).strip())\n+        if len(parts) == 1:\n+            return func(name)\n+        return \", \".join(func(param) for param in parts)\n             return \", \".join(func(param) for param in name.split(\", \"))\n         else:\n             return func(name)"
  },
  "pytest-dev__pytest-7490": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "pytest-dev__pytest-7490",
    "model_patch": "diff --git a/src/_pytest/skipping.py b/src/_pytest/skipping.py\nindex 335e10996..015780b84 100644\n--- a/src/_pytest/skipping.py\n+++ b/src/_pytest/skipping.py\n@@ -245,18 +245,15 @@ def pytest_runtest_setup(item: Item) -> None:\n \n \n @hookimpl(hookwrapper=True)\n-def pytest_runtest_call(item: Item) -> Generator[None, None, None]:\n-    xfailed = item._store.get(xfailed_key, None)\n-    if xfailed is None:\n-        item._store[xfailed_key] = xfailed = evaluate_xfail_marks(item)\n-\n-    if not item.config.option.runxfail:\n+if not item.config.option.runxfail:\n         if xfailed and not xfailed.run:\n             xfail(\"[NOTRUN] \" + xfailed.reason)\n \n     yield\n-\n-\n+    # Re-evaluate xfail marks if not yet evaluated (e.g., marker added during the test's call)\n+    if xfailed is None:\n+        xfailed = evaluate_xfail_marks(item)\n+        item._store[xfailed_key] = xfailed\n @hookimpl(hookwrapper=True)\n def pytest_runtest_makereport(item: Item, call: CallInfo[None]):\n     outcome = yield"
  },
  "sphinx-doc__sphinx-9658": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-9658",
    "model_patch": "diff --git a/sphinx/util/typing.py b/sphinx/util/typing.py\nindex 87707d48f..1ba0a1112 100644\n--- a/sphinx/util/typing.py\n+++ b/sphinx/util/typing.py\n@@ -160,10 +160,7 @@ def _restify_py37(cls: Optional[Type]) -> str:\n                 return ':py:obj:`~typing.Optional`\\\\ [:obj:`~typing.Union`\\\\ [%s]]' % args\n             else:\n                 return ':py:obj:`~typing.Optional`\\\\ [%s]' % restify(cls.__args__[0])\n-        else:\n-            args = ', '.join(restify(a) for a in cls.__args__)\n-            return ':py:obj:`~typing.Union`\\\\ [%s]' % args\n-    elif inspect.isgenericalias(cls):\n+elif inspect.isgenericalias(cls):\n         if isinstance(cls.__origin__, typing._SpecialForm):\n             text = restify(cls.__origin__)  # type: ignore\n         elif getattr(cls, '_name', None):\n@@ -171,6 +168,10 @@ def _restify_py37(cls: Optional[Type]) -> str:\n                 text = ':py:class:`~%s.%s`' % (cls.__module__, cls._name)\n             else:\n                 text = ':py:class:`%s.%s`' % (cls.__module__, cls._name)\n+        else:\n+            text = restify(cls.__origin__)\n+                return ':py:obj:`%s.%s`' % (cls.__module__, name)\n+                text = ':py:class:`%s.%s`' % (cls.__module__, cls._name)\n         else:\n             text = restify(cls.__origin__)"
  },
  "scikit-learn__scikit-learn-26323": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "scikit-learn__scikit-learn-26323",
    "model_patch": "diff --git a/sklearn/compose/_column_transformer.py b/sklearn/compose/_column_transformer.py\nindex 4eddd12b1..5d1ca21b8 100644\n--- a/sklearn/compose/_column_transformer.py\n+++ b/sklearn/compose/_column_transformer.py\n@@ -263,48 +263,61 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n             return self.transformers\n \n     @_transformers.setter\n-    def _transformers(self, value):\n-        try:\n-            self.transformers = [\n-                (name, trans, col)\n-                for ((name, trans), (_, _, col)) in zip(value, self.transformers)\n-            ]\n-        except (TypeError, ValueError):\n-            self.transformers = value\n+@_transformers.setter\n+def _transformers(self, value):\n+    try:\n+        self.transformers = [\n+            (name, trans, col)\n+            for ((name, trans), (_, _, col)) in zip(value, self.transformers)\n+        ]\n+    except (TypeError, ValueError):\n+        self.transformers = value\n \n-    def set_output(self, *, transform=None):\n-        \"\"\"Set the output container when `\"transform\"` and `\"fit_transform\"` are called.\n+def set_output(self, *, transform=None):\n+    \"\"\"Set the output container when `\"transform\"` and `\"fit_transform\"` are called.\n \n-        Calling `set_output` will set the output of all estimators in `transformers`\n-        and `transformers_`.\n+    Calling `set_output` will set the output of all estimators in `transformers`\n+    and `transformers_`.\n \n-        Parameters\n-        ----------\n-        transform : {\"default\", \"pandas\"}, default=None\n-            Configure output of `transform` and `fit_transform`.\n+    Parameters\n+    ----------\n+    transform : {\"default\", \"pandas\"}, default=None\n+        Configure output of `transform` and `fit_transform`.\n \n-            - `\"default\"`: Default output format of a transformer\n-            - `\"pandas\"`: DataFrame output\n-            - `None`: Transform configuration is unchanged\n+        - `\"default\"`: Default output format of a transformer\n+        - `\"pandas\"`: DataFrame output\n+        - `None`: Transform configuration is unchanged\n \n-        Returns\n-        -------\n-        self : estimator instance\n-            Estimator instance.\n-        \"\"\"\n-        super().set_output(transform=transform)\n-        transformers = (\n-            trans\n-            for _, trans, _ in chain(\n-                self.transformers, getattr(self, \"transformers_\", [])\n-            )\n-            if trans not in {\"passthrough\", \"drop\"}\n+    Returns\n+    -------\n+    self : estimator instance\n+        Estimator instance.\n+    \"\"\"\n+    super().set_output(transform=transform)\n+    # Set output for all named transformers (excluding \"passthrough\" and \"drop\").\n+    transformers = (\n+        trans\n+        for _, trans, _ in chain(\n+            self.transformers, getattr(self, \"transformers_\", [])\n         )\n-        for trans in transformers:\n-            _safe_set_output(trans, transform=transform)\n+        if trans not in {\"passthrough\", \"drop\"}\n+    )\n \n-        return self\n+    # Include the remainder transformer if it is an estimator (not \"passthrough\"/\"drop\").\n+    remainder_trans = None\n+    if hasattr(self, \"_remainder\"):\n+        # self._remainder is a tuple ('remainder', transformer, columns)\n+        _, rem_trans, _ = self._remainder\n+        if rem_trans not in {\"passthrough\", \"drop\"}:\n+            remainder_trans = rem_trans\n+    else:\n+        if self.remainder not in {\"passthrough\", \"drop\"}:\n+            remainder_trans = self.remainder\n+\n+    for trans in chain(transformers, [remainder_trans] if remainder_trans is not None else []):\n+        _safe_set_output(trans, transform=transform)\n \n+    return self\n     def get_params(self, deep=True):\n         \"\"\"Get parameters for this estimator."
  },
  "sympy__sympy-17655": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "sympy__sympy-17655",
    "model_patch": "diff --git a/sympy/geometry/point.py b/sympy/geometry/point.py\nindex 7c978c47be..e58295c52d 100644\n--- a/sympy/geometry/point.py\n+++ b/sympy/geometry/point.py\n@@ -145,34 +145,57 @@ def __new__(cls, *args, **kwargs):\n                 raise ValueError(message)\n             elif on_morph == 'warn':\n                 warnings.warn(message)\n-            else:\n-                raise ValueError(filldedent('''\n-                        on_morph value should be 'error',\n-                        'warn' or 'ignore'.'''))\n-        if any(coords[dim:]):\n-            raise ValueError('Nonzero coordinates cannot be removed.')\n-        if any(a.is_number and im(a) for a in coords):\n-            raise ValueError('Imaginary coordinates are not permitted.')\n-        if not all(isinstance(a, Expr) for a in coords):\n-            raise TypeError('Coordinates must be valid SymPy expressions.')\n-\n-        # pad with zeros appropriately\n-        coords = coords[:dim] + (S.Zero,)*(dim - len(coords))\n-\n-        # Turn any Floats into rationals and simplify\n-        # any expressions before we instantiate\n-        if evaluate:\n-            coords = coords.xreplace(dict(\n-                [(f, simplify(nsimplify(f, rational=True)))\n-                 for f in coords.atoms(Float)]))\n-\n-        # return 2D or 3D instances\n-        if len(coords) == 2:\n-            kwargs['_nocheck'] = True\n-            return Point2D(*coords, **kwargs)\n-        elif len(coords) == 3:\n-            kwargs['_nocheck'] = True\n-            return Point3D(*coords, **kwargs)\n+def __add__(self, other):\n+        \"\"\"Add other to self by incrementing self's coordinates by\n+        those of other.\n+    \n+        Notes\n+        =====\n+    \n+        >>> from sympy.geometry.point import Point\n+    \n+        When sequences of coordinates are passed to Point methods, they\n+        are converted to a Point internally. This __add__ method does\n+        not do that so if floating point values are used, a floating\n+        point result (in terms of SymPy Floats) will be returned.\n+    \n+        >>> Point(1, 2) + (.1, .2)\n+        Point2D(1.1, 2.2)\n+    \n+        If this is not desired, the `translate` method can be used or\n+        another Point can be added:\n+    \n+        >>> Point(1, 2).translate(.1, .2)\n+        Point2D(11/10, 11/5)\n+        >>> Point(1, 2) + Point(.1, .2)\n+        Point2D(11/10, 11/5)\n+    \n+        See Also\n+        ========\n+    \n+        sympy.geometry.point.Point.translate\n+    \n+        \"\"\"\n+        # Handle cases like 2*Point(...) where the left operand's Mul was\n+        # constructed by SymPy (so scalar.__mul__(Point) returned a Mul).\n+        # Convert such Mul into Point * scalar so Point.__mul__ is used.\n+        if getattr(other, 'is_Mul', False):\n+            for arg in other.args:\n+                if isinstance(arg, Point):\n+                    scalar = S.One\n+                    for a in other.args:\n+                        if a is not arg:\n+                            scalar = scalar * a\n+                    other = arg * scalar\n+                    break\n+\n+        try:\n+            s, o = Point._normalize_dimension(self, Point(other, evaluate=False))\n+        except TypeError:\n+            raise GeometryError(\"Don't know how to add {} and a Point object\".format(other))\n+    \n+        coords = [simplify(a + b) for a, b in zip(s, o)]\n+        return Point(coords, evaluate=False)\n \n         # the general Point\n         return GeometryEntity.__new__(cls, *coords)"
  },
  "sphinx-doc__sphinx-7590": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-7590",
    "model_patch": "diff --git a/sphinx/domains/cpp.py b/sphinx/domains/cpp.py\nindex fe52d881d..8d58e9f29 100644\n--- a/sphinx/domains/cpp.py\n+++ b/sphinx/domains/cpp.py\n@@ -871,17 +871,39 @@ class ASTCharLiteral(ASTLiteral):\n         if self.prefix is None:\n             return \"'\" + self.data + \"'\"\n         else:\n-            return self.prefix + \"'\" + self.data + \"'\"\n-\n-    def get_id(self, version: int) -> str:\n+def get_id(self, version: int) -> str:\n         return self.type + str(self.value)\n-\n+    \n     def describe_signature(self, signode: TextElement, mode: str,\n                            env: \"BuildEnvironment\", symbol: \"Symbol\") -> None:\n         txt = str(self)\n         signode.append(nodes.Text(txt, txt))\n+        txt = str(self)\n+        signode.append(nodes.Text(txt, txt))\n+\n+\n+class ASTUserDefinedLiteral(ASTLiteral):\n+        def __init__(self, operand: ASTLiteral, suffix: str) -> None:\n+            # operand is the literal (number, string, or char) the UDL is attached to\n+            self.operand = operand\n+            self.suffix = suffix\n \n+        def _stringify(self, transform: StringifyTransform) -> str:\n+            # Represent the UDL as the operand followed immediately by the suffix\n+            return transform(self.operand) + self.suffix\n \n+        def get_id(self, version: int) -> str:\n+            # Include the operand id (when available) and the suffix for uniqueness\n+            try:\n+                op_id = self.operand.get_id(version)\n+            except Exception:\n+                op_id = str(self.operand)\n+            return \"LUDL_%s_%s\" % (self.suffix, op_id)\n+\n+        def describe_signature(self, signode: TextElement, mode: str,\n+                               env: \"BuildEnvironment\", symbol: \"Symbol\") -> None:\n+            txt = str(self)\n+            signode.append(nodes.Text(txt, txt))\n class ASTThisLiteral(ASTExpression):\n     def _stringify(self, transform: StringifyTransform) -> str:\n         return \"this\"\n@@ -4653,34 +4675,61 @@ class DefinitionParser(BaseParser):\n         #  | user-defined-literal\n         self.skip_ws()\n         if self.skip_word('nullptr'):\n-            return ASTPointerLiteral()\n-        if self.skip_word('true'):\n-            return ASTBooleanLiteral(True)\n-        if self.skip_word('false'):\n-            return ASTBooleanLiteral(False)\n-        for regex in [float_literal_re, binary_literal_re, hex_literal_re,\n+for regex in [float_literal_re, binary_literal_re, hex_literal_re,\n                       integer_literal_re, octal_literal_re]:\n             pos = self.pos\n             if self.match(regex):\n                 while self.current_char in 'uUlLfF':\n                     self.pos += 1\n+                # detect user-defined-literal suffix (identifier) immediately after literal\n+                if (self.current_char is not None and\n+                        (self.current_char.isalpha() or self.current_char == '_')):\n+                    start_suffix = self.pos\n+                    while (self.current_char is not None and\n+                           (self.current_char.isalnum() or self.current_char == '_')):\n+                        self.pos += 1\n+                    suffix = self.definition[start_suffix:self.pos]\n+                    number_text = self.definition[pos:start_suffix]\n+                    num_node = ASTNumberLiteral(number_text)\n+                    return ASTUserDefinedLiteral(num_node, suffix)\n                 return ASTNumberLiteral(self.definition[pos:self.pos])\n-\n-        string = self._parse_string()\n+string = self._parse_string()\n         if string is not None:\n+            # check for ud-suffix after string literal\n+            if (self.current_char is not None and\n+                    (self.current_char.isalpha() or self.current_char == '_')):\n+                start_suffix = self.pos\n+                while (self.current_char is not None and\n+                       (self.current_char.isalnum() or self.current_char == '_')):\n+                    self.pos += 1\n+                suffix = self.definition[start_suffix:self.pos]\n+                str_node = ASTStringLiteral(string)\n+                return ASTUserDefinedLiteral(str_node, suffix)\n             return ASTStringLiteral(string)\n-\n+    \n         # character-literal\n         if self.match(char_literal_re):\n             prefix = self.last_match.group(1)  # may be None when no prefix\n             data = self.last_match.group(2)\n             try:\n-                return ASTCharLiteral(prefix, data)\n+                char_node = ASTCharLiteral(prefix, data)\n             except UnicodeDecodeError as e:\n                 self.fail(\"Can not handle character literal. Internal error was: %s\" % e)\n             except UnsupportedMultiCharacterCharLiteral:\n                 self.fail(\"Can not handle character literal\"\n                           \" resulting in multiple decoded characters.\")\n+            # check for ud-suffix after char literal\n+            if (self.current_char is not None and\n+                    (self.current_char.isalpha() or self.current_char == '_')):\n+                start_suffix = self.pos\n+                while (self.current_char is not None and\n+                       (self.current_char.isalnum() or self.current_char == '_')):\n+                    self.pos += 1\n+                suffix = self.definition[start_suffix:self.pos]\n+                return ASTUserDefinedLiteral(char_node, suffix)\n+            return char_node\n+                self.fail(\"Can not handle character literal\"\n+                          \" resulting in multiple decoded characters.\")\n \n         # TODO: user-defined lit\n         return None"
  },
  "sympy__sympy-24213": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "sympy__sympy-24213",
    "model_patch": "diff --git a/sympy/physics/units/unitsystem.py b/sympy/physics/units/unitsystem.py\nindex a436880c4b..54f51142bc 100644\n--- a/sympy/physics/units/unitsystem.py\n+++ b/sympy/physics/units/unitsystem.py\n@@ -120,14 +120,7 @@ def is_consistent(self):\n         \"\"\"\n         Check if the underlying dimension system is consistent.\n         \"\"\"\n-        # test is performed in DimensionSystem\n-        return self.get_dimension_system().is_consistent\n-\n-    @property\n-    def derived_units(self) -> tDict[Dimension, Quantity]:\n-        return self._derived_units\n-\n-    def get_dimensional_expr(self, expr):\n+def get_dimensional_expr(self, expr):\n         from sympy.physics.units import Quantity\n         if isinstance(expr, Mul):\n             return Mul(*[self.get_dimensional_expr(i) for i in expr.args])\n@@ -148,6 +141,13 @@ def get_dimensional_expr(self, expr):\n         elif isinstance(expr, Quantity):\n             return self.get_quantity_dimension(expr).name\n         return S.One\n+                       ds.get_dimensional_dependencies(addend_dim, mark_dimensionless=True):\n+                        raise ValueError(\n+                            'Dimension of \"{}\" is {}, '\n+                            'but it should be {}'.format(\n+                                addend, addend_dim, dim))\n+                    factor += addend_factor\n+                return factor, dim\n \n     def _collect_factor_and_dimension(self, expr):\n         \"\"\""
  },
  "django__django-7530": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-7530",
    "model_patch": "diff --git a/django/core/management/commands/makemigrations.py b/django/core/management/commands/makemigrations.py\nindex 0b39536f5b..ee2abef5d6 100644\n--- a/django/core/management/commands/makemigrations.py\n+++ b/django/core/management/commands/makemigrations.py\n@@ -89,25 +89,16 @@ class Command(BaseCommand):\n         if bad_app_labels:\n             for app_label in bad_app_labels:\n                 self.stderr.write(\"App '%s' could not be found. Is it in INSTALLED_APPS?\" % app_label)\n-            sys.exit(2)\n-\n-        # Load the current graph state. Pass in None for the connection so\n-        # the loader doesn't try to resolve replaced migrations from DB.\n-        loader = MigrationLoader(None, ignore_no_migrations=True)\n-\n-        # Raise an error if any migrations are applied before their dependencies.\n-        consistency_check_labels = set(config.label for config in apps.get_app_configs())\n-        # Non-default databases are only checked if database routers used.\n-        aliases_to_check = connections if settings.DATABASE_ROUTERS else [DEFAULT_DB_ALIAS]\n-        for alias in sorted(aliases_to_check):\n+for alias in sorted(aliases_to_check):\n             connection = connections[alias]\n             if (connection.settings_dict['ENGINE'] != 'django.db.backends.dummy' and any(\n                     # At least one model must be migrated to the database.\n                     router.allow_migrate(connection.alias, app_label, model_name=model._meta.object_name)\n                     for app_label in consistency_check_labels\n-                    for model in apps.get_models(app_label)\n+                    for model in apps.get_app_config(app_label).get_models()\n             )):\n                 loader.check_consistent_history(connection)\n+                loader.check_consistent_history(connection)\n \n         # Before anything else, see if there's conflicting apps and drop out\n         # hard if there are any and they don't want to merge"
  },
  "django__django-11179": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-11179",
    "model_patch": "diff --git a/django/db/models/deletion.py b/django/db/models/deletion.py\nindex 92fe4affb9..e7483772c6 100644\n--- a/django/db/models/deletion.py\n+++ b/django/db/models/deletion.py\n@@ -265,16 +265,15 @@ class Collector:\n             self.data[model] = sorted(instances, key=attrgetter(\"pk\"))\n \n         # if possible, bring the models in an order suitable for databases that\n-        # don't support transactions or cannot defer constraint checks until the\n-        # end of a transaction.\n-        self.sort()\n-        # number of objects deleted for each model label\n-        deleted_counter = Counter()\n-\n-        # Optimize for the case with a single obj and no dependencies\n-        if len(self.data) == 1 and len(instances) == 1:\n-            instance = list(instances)[0]\n-            if self.can_fast_delete(instance):\n+# Optimize for the case with a single obj and no dependencies\n+    if len(self.data) == 1 and len(instances) == 1:\n+        instance = list(instances)[0]\n+        if self.can_fast_delete(instance):\n+            with transaction.mark_for_rollback_on_error():\n+                count = sql.DeleteQuery(model).delete_batch([instance.pk], self.using)\n+            # Clear the primary key on the instance since it has been deleted from the DB.\n+            instance.pk = None\n+            return count, {model._meta.label: count}\n                 with transaction.mark_for_rollback_on_error():\n                     count = sql.DeleteQuery(model).delete_batch([instance.pk], self.using)\n                 return count, {model._meta.label: count}"
  },
  "django__django-16631": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-16631",
    "model_patch": "diff --git a/docs/ref/settings.txt b/docs/ref/settings.txt\nindex 41387886c0..74ef84dd4b 100644\n--- a/docs/ref/settings.txt\n+++ b/docs/ref/settings.txt\n@@ -2293,14 +2293,16 @@ passwords of users and key rotation will not affect them.\n \n .. setting:: SECRET_KEY_FALLBACKS\n \n-``SECRET_KEY_FALLBACKS``\n-------------------------\n-\n-Default: ``[]``\n-\n A list of fallback secret keys for a particular Django installation. These are\n used to allow rotation of the ``SECRET_KEY``.\n \n+In order to rotate your secret keys, set a new ``SECRET_KEY`` and move the\n+previous value to the beginning of ``SECRET_KEY_FALLBACKS``. Note that not all\n+uses of ``SECRET_KEY`` consult ``SECRET_KEY_FALLBACKS``; for example,\n+``AbstractBaseUser.get_session_auth_hash()`` (used to validate logged-in sessions)\n+uses the current ``SECRET_KEY`` only, so changing ``SECRET_KEY`` will invalidate\n+existing sessions even if previous keys are present in\n+\n In order to rotate your secret keys, set a new ``SECRET_KEY`` and move the\n previous value to the beginning of ``SECRET_KEY_FALLBACKS``. Then remove the\n old values from the end of the ``SECRET_KEY_FALLBACKS`` when you are ready to"
  },
  "django__django-14053": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-14053",
    "model_patch": "diff --git a/django/contrib/staticfiles/storage.py b/django/contrib/staticfiles/storage.py\nindex 494890cc23..b1a5f811aa 100644\n--- a/django/contrib/staticfiles/storage.py\n+++ b/django/contrib/staticfiles/storage.py\n@@ -228,23 +228,30 @@ class HashedFilesMixin:\n         ]\n         # Do a single pass first. Post-process all files once, then repeat for\n         # adjustable files.\n+        results = {}\n         for name, hashed_name, processed, _ in self._post_process(paths, adjustable_paths, hashed_files):\n-            yield name, hashed_name, processed\n+            results[name] = (hashed_name, processed)\n \n         paths = {path: paths[path] for path in adjustable_paths}\n \n         for i in range(self.max_post_process_passes):\n             substitutions = False\n             for name, hashed_name, processed, subst in self._post_process(paths, adjustable_paths, hashed_files):\n-                yield name, hashed_name, processed\n+                # Keep the latest result for each original name so we only yield once,\n+                # with the final hashed name/processed flag after all passes.\n+                results[name] = (hashed_name, processed)\n                 substitutions = substitutions or subst\n \n             if not substitutions:\n                 break\n \n         if substitutions:\n+            # If we exceeded max passes, preserve previous behavior of signaling error.\n             yield 'All', None, RuntimeError('Max post-process passes exceeded.')\n \n+        # After all passes are complete, yield each file exactly once with its final values.\n+        for name, (hashed_name, processed) in results.items():\n+            yield name, hashed_name, processed\n         # Store the processed paths\n         self.hashed_files.update(hashed_files)"
  },
  "django__django-16662": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-16662",
    "model_patch": "diff --git a/django/db/migrations/writer.py b/django/db/migrations/writer.py\nindex a59f0c8dcb..4094522ada 100644\n--- a/django/db/migrations/writer.py\n+++ b/django/db/migrations/writer.py\n@@ -148,10 +148,15 @@ class MigrationWriter:\n         for dependency in self.migration.dependencies:\n             if dependency[0] == \"__setting__\":\n                 dependencies.append(\n-                    \"        migrations.swappable_dependency(settings.%s),\"\n-                    % dependency[1]\n-                )\n-                imports.add(\"from django.conf import settings\")\n+# Sort imports so that module-style imports (import X) come before\n+          # from-style imports (from X import Y), then sort by the module/package.\n+          def _import_sort_key(i):\n+              parts = i.split()\n+              if parts[0] == 'import':\n+                  return (0, parts[1])\n+              return (1, parts[1])\n+          sorted_imports = sorted(imports, key=_import_sort_key)\n+          items[\"imports\"] = \"\\n\".join(sorted_imports) + \"\\n\" if imports else \"\"\n             else:\n                 dependencies.append(\"        %s,\" % self.serialize(dependency)[0])\n         items[\"dependencies\"] = \"\\n\".join(dependencies) + \"\\n\" if dependencies else \"\""
  },
  "django__django-14011": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-14011",
    "model_patch": "diff --git a/django/core/servers/basehttp.py b/django/core/servers/basehttp.py\nindex 14dab517c9..6e77465745 100644\n--- a/django/core/servers/basehttp.py\n+++ b/django/core/servers/basehttp.py\n@@ -30,24 +30,11 @@ def get_internal_wsgi_application():\n     this will be the ``application`` object in ``projectname/wsgi.py``.\n \n     This function, and the ``WSGI_APPLICATION`` setting itself, are only useful\n-    for Django's internal server (runserver); external WSGI servers should just\n-    be configured to point to the correct application object directly.\n-\n-    If settings.WSGI_APPLICATION is not set (is ``None``), return\n-    whatever ``django.core.wsgi.get_wsgi_application`` returns.\n-    \"\"\"\n-    from django.conf import settings\n-    app_path = getattr(settings, 'WSGI_APPLICATION')\n-    if app_path is None:\n-        return get_wsgi_application()\n-\n-    try:\n-        return import_string(app_path)\n-    except ImportError as err:\n-        raise ImproperlyConfigured(\n-            \"WSGI application '%s' could not be loaded; \"\n-            \"Error importing module.\" % app_path\n-        ) from err\n+except ImportError as err:\n+          raise ImproperlyConfigured(\n+              \"WSGI application '%s' could not be loaded; \"\n+              \"Error importing module.\" % app_path\n+          ) from err\n \n \n def is_broken_pipe_error():\n@@ -77,6 +64,25 @@ class WSGIServer(simple_server.WSGIServer):\n             super().handle_error(request, client_address)\n \n \n+class ThreadedWSGIServer(socketserver.ThreadingMixIn, WSGIServer):\n+    \"\"\"A threaded version of the WSGIServer\"\"\"\n+    daemon_threads = False\n+            logger.info(\"- Broken pipe from %s\\n\", client_address)\n+        else:\n+            super().handle_error(request, client_address)\n+\n+\n+class ThreadedWSGIServer(socketserver.ThreadingMixIn, WSGIServer):\n+    \"\"\"A threaded version of the WSGIServer\"\"\"\n+    daemon_threads = False\n+\n+    def handle_error(self, request, client_address):\n+        if is_broken_pipe_error():\n+            logger.info(\"- Broken pipe from %s\\n\", client_address)\n+        else:\n+            super().handle_error(request, client_address)\n+\n+\n class ThreadedWSGIServer(socketserver.ThreadingMixIn, WSGIServer):\n     \"\"\"A threaded version of the WSGIServer\"\"\"\n     daemon_threads = True"
  },
  "django__django-10973": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-10973",
    "model_patch": "diff --git a/django/db/backends/postgresql/client.py b/django/db/backends/postgresql/client.py\nindex 7fca6eff30..28e60cab92 100644\n--- a/django/db/backends/postgresql/client.py\n+++ b/django/db/backends/postgresql/client.py\n@@ -18,29 +18,22 @@ class DatabaseClient(BaseDatabaseClient):\n \n     @classmethod\n     def runshell_db(cls, conn_params):\n-        args = [cls.executable_name]\n-\n-        host = conn_params.get('host', '')\n-        port = conn_params.get('port', '')\n-        dbname = conn_params.get('database', '')\n-        user = conn_params.get('user', '')\n-        passwd = conn_params.get('password', '')\n-\n-        if user:\n-            args += ['-U', user]\n-        if host:\n-            args += ['-h', host]\n-        if port:\n-            args += ['-p', str(port)]\n-        args += [dbname]\n-\n-        temp_pgpass = None\n+temp_pgpass = None\n+        env = None\n         sigint_handler = signal.getsignal(signal.SIGINT)\n         try:\n             if passwd:\n-                # Create temporary .pgpass file.\n-                temp_pgpass = NamedTemporaryFile(mode='w+')\n+                # Prefer PGPASSWORD in the child environment to avoid a temporary .pgpass file.\n                 try:\n+                    env = os.environ.copy()\n+                    env['PGPASSWORD'] = passwd\n+                except UnicodeEncodeError:\n+                    # Fallback to temporary .pgpass file if the password can't be encoded.\n+                    temp_pgpass = NamedTemporaryFile(mode='w+')\n+                    try:\n+                    # If the current locale can't encode the data, let the\n+                    # user input the password manually (leave env as None).\n+                    env = None\n                     print(\n                         _escape_pgpass(host) or '*',\n                         str(port) or '*',"
  },
  "django__django-13297": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-13297",
    "model_patch": "diff --git a/django/views/generic/base.py b/django/views/generic/base.py\nindex ea5baca08d..95daeff4bd 100644\n--- a/django/views/generic/base.py\n+++ b/django/views/generic/base.py\n@@ -12,10 +12,6 @@ from django.urls import reverse\n from django.utils.decorators import classonlymethod\n from django.utils.deprecation import RemovedInDjango40Warning\n from django.utils.functional import SimpleLazyObject\n-\n-logger = logging.getLogger('django.request')\n-\n-\n class ContextMixin:\n     \"\"\"\n     A default context mixin that passes the keyword arguments received by\n@@ -27,6 +23,12 @@ class ContextMixin:\n         kwargs.setdefault('view', self)\n         if self.extra_context is not None:\n             kwargs.update(self.extra_context)\n+        # Resolve any SimpleLazyObject values (e.g. wrapped URL kwargs) to concrete values\n+        for key, value in list(kwargs.items()):\n+            if isinstance(value, SimpleLazyObject):\n+                # URL kwargs are expected to be strings; force evaluation.\n+                kwargs[key] = str(value)\n+        return kwargs\n         return kwargs"
  },
  "django__django-12406": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-12406",
    "model_patch": "diff --git a/django/forms/models.py b/django/forms/models.py\nindex dafc11f995..aeb86bfb1e 100644\n--- a/django/forms/models.py\n+++ b/django/forms/models.py\n@@ -133,14 +133,7 @@ def fields_for_model(model, fields=None, exclude=None, widgets=None,\n     ``field_classes`` is a dictionary of model field names mapped to a form\n     field class.\n \n-    ``apply_limit_choices_to`` is a boolean indicating if limit_choices_to\n-    should be applied to a field's queryset.\n-    \"\"\"\n-    field_dict = {}\n-    ignored = []\n-    opts = model._meta\n-    # Avoid circular import\n-    from django.db.models import Field as ModelField\n+from django.db.models import Field as ModelField\n     sortable_private_fields = [f for f in opts.private_fields if isinstance(f, ModelField)]\n     for f in sorted(chain(opts.concrete_fields, sortable_private_fields, opts.many_to_many)):\n         if not getattr(f, 'editable', False):\n@@ -151,6 +144,18 @@ def fields_for_model(model, fields=None, exclude=None, widgets=None,\n                         f.name, model.__name__)\n                 )\n             continue\n+            if _RadioSelect is not None and issubclass(widget_cls, _RadioSelect) and getattr(f, 'blank', True) is False:\n+                kwargs.setdefault('empty_label', None)\n+        formfield = f.formfield(**kwargs)\n+    elif not callable(formfield_callback):\n+        raise TypeError('formfield_callback must be a function or callable')\n+    else:\n+        formfield = formfield_callback(f, **kwargs)\n+                raise FieldError(\n+                    \"'%s' cannot be specified for %s model form as it is a non-editable field\" % (\n+                        f.name, model.__name__)\n+                )\n+            continue\n         if fields is not None and f.name not in fields:\n             continue\n         if exclude and f.name in exclude:\n@@ -169,12 +174,24 @@ def fields_for_model(model, fields=None, exclude=None, widgets=None,\n             kwargs['error_messages'] = error_messages[f.name]\n         if field_classes and f.name in field_classes:\n             kwargs['form_class'] = field_classes[f.name]\n-\n-        if formfield_callback is None:\n-            formfield = f.formfield(**kwargs)\n-        elif not callable(formfield_callback):\n-            raise TypeError('formfield_callback must be a function or callable')\n-        else:\n+if formfield_callback is None:\n+        # If a RadioSelect widget is explicitly provided for a related field\n+        # and the model field doesn't allow blank, don't add an empty choice.\n+        widget = kwargs.get('widget')\n+        if widget is not None:\n+            # widget may be a class or an instance\n+            widget_cls = widget if isinstance(widget, type) else widget.__class__\n+            try:\n+                from django.forms.widgets import RadioSelect as _RadioSelect\n+            except Exception:\n+                _RadioSelect = None\n+            if _RadioSelect is not None and issubclass(widget_cls, _RadioSelect) and getattr(f, 'blank', True) is False:\n+                kwargs.setdefault('empty_label', None)\n+        formfield = f.formfield(**kwargs)\n+    elif not callable(formfield_callback):\n+        raise TypeError('formfield_callback must be a function or callable')\n+    else:\n+        formfield = formfield_callback(f, **kwargs)\n             formfield = formfield_callback(f, **kwargs)\n \n         if formfield:"
  },
  "django__django-13810": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-13810",
    "model_patch": "diff --git a/django/core/handlers/base.py b/django/core/handlers/base.py\nindex 8e8c3da06a..1ec2e714da 100644\n--- a/django/core/handlers/base.py\n+++ b/django/core/handlers/base.py\n@@ -29,18 +29,18 @@ class BaseHandler:\n \n         Must be called after the environment is fixed (see __call__ in subclasses).\n         \"\"\"\n-        self._view_middleware = []\n-        self._template_response_middleware = []\n-        self._exception_middleware = []\n-\n-        get_response = self._get_response_async if is_async else self._get_response\n-        handler = convert_exception_to_response(get_response)\n-        handler_is_async = is_async\n-        for middleware_path in reversed(settings.MIDDLEWARE):\n-            middleware = import_string(middleware_path)\n-            middleware_can_sync = getattr(middleware, 'sync_capable', True)\n-            middleware_can_async = getattr(middleware, 'async_capable', False)\n-            if not middleware_can_sync and not middleware_can_async:\n+middleware_can_sync = getattr(middleware, 'sync_capable', True)\n+                middleware_can_async = getattr(middleware, 'async_capable', False)\n+                if not middleware_can_sync and not middleware_can_async:\n+                    raise RuntimeError(\n+                        'Middleware %s must have at least one of '\n+                        'sync_capable/async_capable set to True.' % middleware_path\n+                    )\n+                elif not handler_is_async and middleware_can_sync:\n+                    middleware_is_async = False\n+                else:\n+                    middleware_is_async = middleware_can_async\n+if not middleware_can_sync and not middleware_can_async:\n                 raise RuntimeError(\n                     'Middleware %s must have at least one of '\n                     'sync_capable/async_capable set to True.' % middleware_path\n@@ -50,11 +50,22 @@ class BaseHandler:\n             else:\n                 middleware_is_async = middleware_can_async\n             try:\n-                # Adapt handler, if needed.\n-                handler = self.adapt_method_mode(\n+                # Adapt handler, if needed, but don't overwrite the current handler\n+                # until we know the middleware will be used. Use a candidate_handler\n+                # for instantiation to avoid \"poisoning\" the chain when\n+                # MiddlewareNotUsed is raised.\n+                candidate_handler = self.adapt_method_mode(\n                     middleware_is_async, handler, handler_is_async,\n                     debug=settings.DEBUG, name='middleware %s' % middleware_path,\n                 )\n+                mw_instance = middleware(candidate_handler)\n+            except MiddlewareNotUsed as exc:\n+                if settings.DEBUG:\n+                    if str(exc):\n+                        logger.debug('MiddlewareNotUsed(%r): %s', middleware_path, exc)\n+                    else:\n+                        logger.debug('MiddlewareNotUsed: %r', middleware_path)\n+                continue\n                 mw_instance = middleware(handler)\n             except MiddlewareNotUsed as exc:\n                 if settings.DEBUG:"
  }
}