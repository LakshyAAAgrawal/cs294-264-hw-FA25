{
  "django__django-14011": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-14011",
    "model_patch": "diff --git a/django/core/servers/basehttp.py b/django/core/servers/basehttp.py\nindex 14dab517c9..6758440afd 100644\n--- a/django/core/servers/basehttp.py\n+++ b/django/core/servers/basehttp.py\n@@ -79,7 +79,7 @@ class WSGIServer(simple_server.WSGIServer):\n \n class ThreadedWSGIServer(socketserver.ThreadingMixIn, WSGIServer):\n     \"\"\"A threaded version of the WSGIServer\"\"\"\n-    daemon_threads = True\n+    daemon_threads = False\n \n \n class ServerHandler(simple_server.ServerHandler):"
  },
  "sympy__sympy-17655": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "sympy__sympy-17655",
    "model_patch": "diff --git a/sympy/geometry/point.py b/sympy/geometry/point.py\nindex 7c978c47be..bf06e0ccbb 100644\n--- a/sympy/geometry/point.py\n+++ b/sympy/geometry/point.py\n@@ -199,10 +199,25 @@ def __add__(self, other):\n         >>> Point(1, 2) + (.1, .2)\n         Point2D(1.1, 2.2)\n \n-        If this is not desired, the `translate` method can be used or\n-        another Point can be added:\n-\n-        >>> Point(1, 2).translate(.1, .2)\n+        try:\n+            # If `other` is a Mul containing a Point (e.g. 2*Point(...)),\n+            # try to coerce it so the Point.__mul__/__rmul__ logic runs and\n+            # returns a Point. If coercion fails, fall back to original behavior.\n+            from sympy import Mul\n+            if isinstance(other, Mul):\n+                for factor in other.args:\n+                    if isinstance(factor, Point):\n+                        scalar = other / factor\n+                        try:\n+                            coerced = factor * scalar\n+                        except Exception:\n+                            coerced = other\n+                        else:\n+                            other = coerced\n+                        break\n+            s, o = Point._normalize_dimension(self, Point(other, evaluate=False))\n+        except TypeError:\n+            raise GeometryError(\"Don't know how to add {} and a Point object\".format(other))\n         Point2D(11/10, 11/5)\n         >>> Point(1, 2) + Point(.1, .2)\n         Point2D(11/10, 11/5)"
  },
  "django__django-10973": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-10973",
    "model_patch": "diff --git a/django/db/backends/postgresql/client.py b/django/db/backends/postgresql/client.py\nindex 7fca6eff30..a9b0e6affe 100644\n--- a/django/db/backends/postgresql/client.py\n+++ b/django/db/backends/postgresql/client.py\n@@ -34,38 +34,17 @@ class DatabaseClient(BaseDatabaseClient):\n             args += ['-p', str(port)]\n         args += [dbname]\n \n-        temp_pgpass = None\n+        env = os.environ.copy()\n         sigint_handler = signal.getsignal(signal.SIGINT)\n         try:\n             if passwd:\n-                # Create temporary .pgpass file.\n-                temp_pgpass = NamedTemporaryFile(mode='w+')\n-                try:\n-                    print(\n-                        _escape_pgpass(host) or '*',\n-                        str(port) or '*',\n-                        _escape_pgpass(dbname) or '*',\n-                        _escape_pgpass(user) or '*',\n-                        _escape_pgpass(passwd),\n-                        file=temp_pgpass,\n-                        sep=':',\n-                        flush=True,\n-                    )\n-                    os.environ['PGPASSFILE'] = temp_pgpass.name\n-                except UnicodeEncodeError:\n-                    # If the current locale can't encode the data, let the\n-                    # user input the password manually.\n-                    pass\n+                env['PGPASSWORD'] = passwd\n             # Allow SIGINT to pass to psql to abort queries.\n             signal.signal(signal.SIGINT, signal.SIG_IGN)\n-            subprocess.check_call(args)\n+            subprocess.run(args, env=env, check=True)\n         finally:\n             # Restore the original SIGINT handler.\n             signal.signal(signal.SIGINT, sigint_handler)\n-            if temp_pgpass:\n-                temp_pgpass.close()\n-                if 'PGPASSFILE' in os.environ:  # unit tests need cleanup\n-                    del os.environ['PGPASSFILE']\n \n     def runshell(self):\n         DatabaseClient.runshell_db(self.connection.get_connection_params())"
  },
  "sphinx-doc__sphinx-9230": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-9230",
    "model_patch": "diff --git a/sphinx/util/docfields.py b/sphinx/util/docfields.py\nindex 3a3367ebe..7f5676b54 100644\n--- a/sphinx/util/docfields.py\n+++ b/sphinx/util/docfields.py\n@@ -238,7 +238,7 @@ class DocFieldTransformer:\n             field_body = cast(nodes.field_body, field[1])\n             try:\n                 # split into field type and argument\n-                fieldtype_name, fieldarg = field_name.astext().split(None, 1)\n+                fieldtype_name, fieldarg = field_name.astext().rsplit(None, 1)\n             except ValueError:\n                 # maybe an argument-less field type?\n                 fieldtype_name, fieldarg = field_name.astext(), ''"
  },
  "django__django-16631": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-16631",
    "model_patch": "diff --git a/docs/ref/settings.txt b/docs/ref/settings.txt\nindex 41387886c0..ff501852b7 100644\n--- a/docs/ref/settings.txt\n+++ b/docs/ref/settings.txt\n@@ -2290,15 +2290,21 @@ passwords of users and key rotation will not affect them.\n     The default :file:`settings.py` file created by :djadmin:`django-admin\n     startproject <startproject>` creates a unique ``SECRET_KEY`` for\n     convenience.\n+A list of fallback secret keys for a particular Django installation. These are\n+used to allow rotation of the ``SECRET_KEY``.\n \n-.. setting:: SECRET_KEY_FALLBACKS\n-\n-``SECRET_KEY_FALLBACKS``\n-------------------------\n-\n-Default: ``[]``\n+In order to rotate your secret keys, set a new ``SECRET_KEY`` and move the\n+previous value to the beginning of ``SECRET_KEY_FALLBACKS``. Then remove the\n+old values from the end of the ``SECRET_KEY_FALLBACKS`` when you are ready to\n+expire the sessions, password reset tokens, and so on, that make use of them.\n \n-A list of fallback secret keys for a particular Django installation. These are\n+Note: not all HMAC/signing code paths consult ``SECRET_KEY_FALLBACKS``. For\n+example, ``django.contrib.auth.base_user.AbstractBaseUser.get_session_auth_hash``\n+calls :func:`django.utils.crypto.salted_hmac` without passing an explicit\n+``secret`` argument and therefore uses only the current ``SECRET_KEY``. As a\n+result, moving a previous key into ``SECRET_KEY_FALLBACKS`` will not preserve\n+existing session authentication hashes; additional code changes are required to\n+verify those values against fallback keys.\n used to allow rotation of the ``SECRET_KEY``.\n \n In order to rotate your secret keys, set a new ``SECRET_KEY`` and move the"
  },
  "django__django-12406": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-12406",
    "model_patch": "diff --git a/django/forms/widgets.py b/django/forms/widgets.py\nindex 40ac1d3162..903cb447a7 100644\n--- a/django/forms/widgets.py\n+++ b/django/forms/widgets.py\n@@ -759,7 +759,17 @@ class RadioSelect(ChoiceWidget):\n     template_name = 'django/forms/widgets/radio.html'\n     option_template_name = 'django/forms/widgets/radio_option.html'\n \n+    def format_value(self, value):\n+        \"\"\"\n+        Return selected values as a list.\n \n+        For RadioSelect, treat None as \"no selection\" so an empty choice\n+        (''/None) is not auto-selected when rendering a new form instance.\n+        This prevents a checked blank radio option for required model fields.\n+        \"\"\"\n+        if value is None:\n+            return []\n+        return super().format_value(value)\n class CheckboxSelectMultiple(ChoiceWidget):\n     allow_multiple_selected = True\n     input_type = 'checkbox'"
  },
  "django__django-7530": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-7530",
    "model_patch": "diff --git a/django/core/management/commands/makemigrations.py b/django/core/management/commands/makemigrations.py\nindex 0b39536f5b..b1528e3b28 100644\n--- a/django/core/management/commands/makemigrations.py\n+++ b/django/core/management/commands/makemigrations.py\n@@ -89,8 +89,6 @@ class Command(BaseCommand):\n         if bad_app_labels:\n             for app_label in bad_app_labels:\n                 self.stderr.write(\"App '%s' could not be found. Is it in INSTALLED_APPS?\" % app_label)\n-            sys.exit(2)\n-\n         # Load the current graph state. Pass in None for the connection so\n         # the loader doesn't try to resolve replaced migrations from DB.\n         loader = MigrationLoader(None, ignore_no_migrations=True)\n@@ -105,7 +103,7 @@ class Command(BaseCommand):\n                     # At least one model must be migrated to the database.\n                     router.allow_migrate(connection.alias, app_label, model_name=model._meta.object_name)\n                     for app_label in consistency_check_labels\n-                    for model in apps.get_models(app_label)\n+                    for model in apps.get_app_config(app_label).get_models()\n             )):\n                 loader.check_consistent_history(connection)"
  },
  "django__django-14053": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-14053",
    "model_patch": "diff --git a/django/contrib/staticfiles/storage.py b/django/contrib/staticfiles/storage.py\nindex 494890cc23..9c0811eda2 100644\n--- a/django/contrib/staticfiles/storage.py\n+++ b/django/contrib/staticfiles/storage.py\n@@ -172,34 +172,6 @@ class HashedFilesMixin:\n                 return matched\n \n             # Strip off the fragment so a path-like fragment won't interfere.\n-            url_path, fragment = urldefrag(url)\n-\n-            if url_path.startswith('/'):\n-                # Otherwise the condition above would have returned prematurely.\n-                assert url_path.startswith(settings.STATIC_URL)\n-                target_name = url_path[len(settings.STATIC_URL):]\n-            else:\n-                # We're using the posixpath module to mix paths and URLs conveniently.\n-                source_name = name if os.sep == '/' else name.replace(os.sep, '/')\n-                target_name = posixpath.join(posixpath.dirname(source_name), url_path)\n-\n-            # Determine the hashed name of the target file with the storage backend.\n-            hashed_url = self._url(\n-                self._stored_name, unquote(target_name),\n-                force=True, hashed_files=hashed_files,\n-            )\n-\n-            transformed_url = '/'.join(url_path.split('/')[:-1] + hashed_url.split('/')[-1:])\n-\n-            # Restore the fragment that was stripped off earlier.\n-            if fragment:\n-                transformed_url += ('?#' if '?#' in url else '#') + fragment\n-\n-            # Return the hashed version to the file\n-            return template % unquote(transformed_url)\n-\n-        return converter\n-\n     def post_process(self, paths, dry_run=False, **options):\n         \"\"\"\n         Post process the given dictionary of files (called from collectstatic).\n@@ -226,19 +198,28 @@ class HashedFilesMixin:\n             path for path in paths\n             if matches_patterns(path, self._patterns)\n         ]\n+\n+        # track which original names we've yielded so we don't yield duplicates\n+        yielded = set()\n+\n         # Do a single pass first. Post-process all files once, then repeat for\n         # adjustable files.\n         for name, hashed_name, processed, _ in self._post_process(paths, adjustable_paths, hashed_files):\n-            yield name, hashed_name, processed\n+            if name not in yielded:\n+                yield name, hashed_name, processed\n+                yielded.add(name)\n \n         paths = {path: paths[path] for path in adjustable_paths}\n \n         for i in range(self.max_post_process_passes):\n             substitutions = False\n             for name, hashed_name, processed, subst in self._post_process(paths, adjustable_paths, hashed_files):\n-                yield name, hashed_name, processed\n+                if name not in yielded:\n+                    yield name, hashed_name, processed\n+                    yielded.add(name)\n                 substitutions = substitutions or subst\n \n+\n             if not substitutions:\n                 break"
  },
  "django__django-13810": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-13810",
    "model_patch": "diff --git a/django/core/handlers/base.py b/django/core/handlers/base.py\nindex 8e8c3da06a..dfd2e613f9 100644\n--- a/django/core/handlers/base.py\n+++ b/django/core/handlers/base.py\n@@ -48,23 +48,20 @@ class BaseHandler:\n             elif not handler_is_async and middleware_can_sync:\n                 middleware_is_async = False\n             else:\n-                middleware_is_async = middleware_can_async\n-            try:\n-                # Adapt handler, if needed.\n-                handler = self.adapt_method_mode(\n-                    middleware_is_async, handler, handler_is_async,\n-                    debug=settings.DEBUG, name='middleware %s' % middleware_path,\n-                )\n-                mw_instance = middleware(handler)\n-            except MiddlewareNotUsed as exc:\n-                if settings.DEBUG:\n-                    if str(exc):\n-                        logger.debug('MiddlewareNotUsed(%r): %s', middleware_path, exc)\n-                    else:\n-                        logger.debug('MiddlewareNotUsed: %r', middleware_path)\n-                continue\n-\n-            if mw_instance is None:\n+                try:\n+                    # Adapt handler, if needed.\n+                    adapted_handler = self.adapt_method_mode(\n+                        middleware_is_async, handler, handler_is_async,\n+                        debug=settings.DEBUG, name='middleware %s' % middleware_path,\n+                    )\n+                    mw_instance = middleware(adapted_handler)\n+                except MiddlewareNotUsed as exc:\n+                    if settings.DEBUG:\n+                        if str(exc):\n+                            logger.debug('MiddlewareNotUsed(%r): %s', middleware_path, exc)\n+                        else:\n+                            logger.debug('MiddlewareNotUsed: %r', middleware_path)\n+                    continue\n                 raise ImproperlyConfigured(\n                     'Middleware factory %s returned None.' % middleware_path\n                 )"
  },
  "psf__requests-2931": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "psf__requests-2931",
    "model_patch": "diff --git a/requests/utils.py b/requests/utils.py\nindex 132cd2b..6be5601 100644\n--- a/requests/utils.py\n+++ b/requests/utils.py\n@@ -681,8 +681,6 @@ def get_auth_from_url(url):\n         auth = ('', '')\n \n     return auth\n-\n-\n def to_native_string(string, encoding='ascii'):\n     \"\"\"\n     Given a string object, regardless of type, returns a representation of that\n@@ -692,16 +690,24 @@ def to_native_string(string, encoding='ascii'):\n     out = None\n \n     if isinstance(string, builtin_str):\n-        out = string\n+        return string\n     else:\n         if is_py2:\n-            out = string.encode(encoding)\n+            try:\n+                return string.encode(encoding)\n+            except Exception:\n+                return str(string)\n         else:\n-            out = string.decode(encoding)\n-\n-    return out\n-\n-\n+            # On Py3, bytes-like objects must be decoded to str. Try the\n+            # requested encoding, then fall back to UTF-8, and finally coerce\n+            # to str() as a last resort.\n+            try:\n+                return string.decode(encoding)\n+            except (AttributeError, UnicodeDecodeError):\n+                try:\n+                    return string.decode('utf-8')\n+                except Exception:\n+                    return str(string)\n def urldefragauth(url):\n     \"\"\"\n     Given a url remove the fragment and the authentication part"
  },
  "astropy__astropy-7166": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "astropy__astropy-7166",
    "model_patch": "diff --git a/astropy/utils/misc.py b/astropy/utils/misc.py\nindex de3fb01d1..95c3b3b02 100644\n--- a/astropy/utils/misc.py\n+++ b/astropy/utils/misc.py\n@@ -491,9 +491,6 @@ def did_you_mean(s, candidates, n=3, cutoff=0.8, fix=None):\n                        matches[-1])\n         return 'Did you mean {0}?'.format(matches)\n \n-    return ''\n-\n-\n class InheritDocstrings(type):\n     \"\"\"\n     This metaclass makes methods of a class automatically have their\n@@ -519,24 +516,30 @@ class InheritDocstrings(type):\n         >>> B.wiggle.__doc__\n         u'Wiggle the thingamajig'\n     \"\"\"\n-\n     def __init__(cls, name, bases, dct):\n         def is_public_member(key):\n             return (\n                 (key.startswith('__') and key.endswith('__')\n                  and len(key) > 4) or\n                 not key.startswith('_'))\n-\n         for key, val in dct.items():\n-            if (inspect.isfunction(val) and\n-                is_public_member(key) and\n-                val.__doc__ is None):\n-                for base in cls.__mro__[1:]:\n-                    super_method = getattr(base, key, None)\n-                    if super_method is not None:\n-                        val.__doc__ = super_method.__doc__\n-                        break\n-\n+            if is_public_member(key):\n+                # Handle regular functions/methods\n+                if inspect.isfunction(val) and val.__doc__ is None:\n+                    for base in cls.__mro__[1:]:\n+                        super_method = getattr(base, key, None)\n+                        if super_method is not None:\n+                            val.__doc__ = super_method.__doc__\n+                            break\n+                # Handle property descriptors: inherit fget docstring if missing\n+                elif isinstance(val, property):\n+                    fget = val.fget\n+                    if fget is not None and getattr(fget, '__doc__', None) is None:\n+                        for base in cls.__mro__[1:]:\n+                            super_method = getattr(base, key, None)\n+                            if isinstance(super_method, property) and super_method.fget is not None:\n+                                fget.__doc__ = super_method.fget.__doc__\n+                                break\n         super().__init__(name, bases, dct)"
  },
  "sphinx-doc__sphinx-7590": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-7590",
    "model_patch": "diff --git a/sphinx/domains/cpp.py b/sphinx/domains/cpp.py\nindex fe52d881d..eeeb9c186 100644\n--- a/sphinx/domains/cpp.py\n+++ b/sphinx/domains/cpp.py\n@@ -4658,13 +4658,20 @@ class DefinitionParser(BaseParser):\n             return ASTBooleanLiteral(True)\n         if self.skip_word('false'):\n             return ASTBooleanLiteral(False)\n-        for regex in [float_literal_re, binary_literal_re, hex_literal_re,\n-                      integer_literal_re, octal_literal_re]:\n-            pos = self.pos\n-            if self.match(regex):\n-                while self.current_char in 'uUlLfF':\n-                    self.pos += 1\n-                return ASTNumberLiteral(self.definition[pos:self.pos])\n+            for regex in [float_literal_re, binary_literal_re, hex_literal_re,\n+                            integer_literal_re, octal_literal_re]:\n+                pos = self.pos\n+                if self.match(regex):\n+                    # If an identifier-style user-defined-literal (UDL) follows\n+                    # (starts with letter or '_'), consume the full identifier first.\n+                    if (self.current_char is not None) and (self.current_char.isalpha() or self.current_char == '_'):\n+                        while (self.current_char.isalnum() or self.current_char == '_'):\n+                            self.pos += 1\n+                    else:\n+                        # otherwise consume builtin numeric suffix letters (e.g., u, U, l, L, f, F, or combinations)\n+                        while self.current_char in 'uUlLfF':\n+                            self.pos += 1\n+                    return ASTNumberLiteral(self.definition[pos:self.pos])\n \n         string = self._parse_string()\n         if string is not None:"
  },
  "django__django-16662": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-16662",
    "model_patch": "diff --git a/django/db/migrations/writer.py b/django/db/migrations/writer.py\nindex a59f0c8dcb..3aea62d079 100644\n--- a/django/db/migrations/writer.py\n+++ b/django/db/migrations/writer.py\n@@ -175,7 +175,7 @@ class MigrationWriter:\n \n         # Sort imports by the package / module to be imported (the part after\n         # \"from\" in \"from ... import ...\" or after \"import\" in \"import ...\").\n-        sorted_imports = sorted(imports, key=lambda i: i.split()[1])\n+        sorted_imports = sorted(imports, key=lambda i: (0 if i.lstrip().startswith('import ') else 1, i.split(maxsplit=1)[1]))\n         items[\"imports\"] = \"\\n\".join(sorted_imports) + \"\\n\" if imports else \"\"\n         if migration_imports:\n             items[\"imports\"] += ("
  },
  "django__django-11179": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-11179",
    "model_patch": "diff --git a/django/db/models/deletion.py b/django/db/models/deletion.py\nindex 92fe4affb9..9f40a44381 100644\n--- a/django/db/models/deletion.py\n+++ b/django/db/models/deletion.py\n@@ -257,8 +257,6 @@ class Collector:\n                     found = True\n             if not found:\n                 return\n-        self.data = {model: self.data[model] for model in sorted_models}\n-\n     def delete(self):\n         # sort instance collections\n         for model, instances in self.data.items():\n@@ -277,6 +275,8 @@ class Collector:\n             if self.can_fast_delete(instance):\n                 with transaction.mark_for_rollback_on_error():\n                     count = sql.DeleteQuery(model).delete_batch([instance.pk], self.using)\n+                # Clear the instance PK to reflect that it has been deleted.\n+                setattr(instance, model._meta.pk.attname, None)\n                 return count, {model._meta.label: count}\n \n         with transaction.atomic(using=self.using, savepoint=False):"
  },
  "sympy__sympy-24213": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "sympy__sympy-24213",
    "model_patch": "diff --git a/sympy/physics/units/unitsystem.py b/sympy/physics/units/unitsystem.py\nindex a436880c4b..f2d40a1a85 100644\n--- a/sympy/physics/units/unitsystem.py\n+++ b/sympy/physics/units/unitsystem.py\n@@ -91,38 +91,6 @@ def get_quantity_scale_factor(self, unit):\n     def get_unit_system(unit_system):\n         if isinstance(unit_system, UnitSystem):\n             return unit_system\n-\n-        if unit_system not in UnitSystem._unit_systems:\n-            raise ValueError(\n-                \"Unit system is not supported. Currently\"\n-                \"supported unit systems are {}\".format(\n-                    \", \".join(sorted(UnitSystem._unit_systems))\n-                )\n-            )\n-\n-        return UnitSystem._unit_systems[unit_system]\n-\n-    @staticmethod\n-    def get_default_unit_system():\n-        return UnitSystem._unit_systems[\"SI\"]\n-\n-    @property\n-    def dim(self):\n-        \"\"\"\n-        Give the dimension of the system.\n-\n-        That is return the number of units forming the basis.\n-        \"\"\"\n-        return len(self._base_units)\n-\n-    @property\n-    def is_consistent(self):\n-        \"\"\"\n-        Check if the underlying dimension system is consistent.\n-        \"\"\"\n-        # test is performed in DimensionSystem\n-        return self.get_dimension_system().is_consistent\n-\n     @property\n     def derived_units(self) -> tDict[Dimension, Quantity]:\n         return self._derived_units\n@@ -173,13 +141,16 @@ def _collect_factor_and_dimension(self, expr):\n         elif isinstance(expr, Add):\n             factor, dim = self._collect_factor_and_dimension(expr.args[0])\n             for addend in expr.args[1:]:\n-                addend_factor, addend_dim = \\\n-                    self._collect_factor_and_dimension(addend)\n-                if dim != addend_dim:\n+                addend_factor, addend_dim = self._collect_factor_and_dimension(addend)\n+                # consider equivalent dimensions according to the current\n+                # dimension system rather than requiring exact object equality\n+                dim_sys = self.get_dimension_system()\n+                deps1 = dim_sys.get_dimensional_dependencies(dim, mark_dimensionless=True)\n+                deps2 = dim_sys.get_dimensional_dependencies(addend_dim, mark_dimensionless=True)\n+                if deps1 != deps2:\n                     raise ValueError(\n                         'Dimension of \"{}\" is {}, '\n-                        'but it should be {}'.format(\n-                            addend, addend_dim, dim))\n+                        'but it should be {}'.format(addend, addend_dim, dim))\n                 factor += addend_factor\n             return factor, dim\n         elif isinstance(expr, Derivative):"
  },
  "pytest-dev__pytest-7490": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "pytest-dev__pytest-7490",
    "model_patch": "diff --git a/src/_pytest/skipping.py b/src/_pytest/skipping.py\nindex 335e10996..3e751778b 100644\n--- a/src/_pytest/skipping.py\n+++ b/src/_pytest/skipping.py\n@@ -220,8 +220,6 @@ def evaluate_xfail_marks(item: Item) -> Optional[Xfail]:\n                 return Xfail(reason, run, strict, raises)\n \n     return None\n-\n-\n # Whether skipped due to skip or skipif marks.\n skipped_by_mark_key = StoreKey[bool]()\n # Saves the xfail mark evaluation. Can be refreshed during call if None.\n@@ -260,8 +258,11 @@ def pytest_runtest_call(item: Item) -> Generator[None, None, None]:\n @hookimpl(hookwrapper=True)\n def pytest_runtest_makereport(item: Item, call: CallInfo[None]):\n     outcome = yield\n-    rep = outcome.get_result()\n+    # Re-evaluate xfail marks in case they were added during test execution.\n     xfailed = item._store.get(xfailed_key, None)\n+    if xfailed is None:\n+        item._store[xfailed_key] = xfailed = evaluate_xfail_marks(item)\n+    rep = outcome.get_result()\n     # unittest special case, see setting of unexpectedsuccess_key\n     if unexpectedsuccess_key in item._store and rep.when == \"call\":\n         reason = item._store[unexpectedsuccess_key]\n@@ -291,21 +292,6 @@ def pytest_runtest_makereport(item: Item, call: CallInfo[None]):\n             else:\n                 rep.outcome = \"passed\"\n                 rep.wasxfail = xfailed.reason\n-\n-    if (\n-        item._store.get(skipped_by_mark_key, True)\n-        and rep.skipped\n-        and type(rep.longrepr) is tuple\n-    ):\n-        # skipped by mark.skipif; change the location of the failure\n-        # to point to the item definition, otherwise it will display\n-        # the location of where the skip exception was raised within pytest\n-        _, _, reason = rep.longrepr\n-        filename, line = item.reportinfo()[:2]\n-        assert line is not None\n-        rep.longrepr = str(filename), line + 1, reason\n-\n-\n def pytest_report_teststatus(report: BaseReport) -> Optional[Tuple[str, str, str]]:\n     if hasattr(report, \"wasxfail\"):\n         if report.skipped:"
  },
  "django__django-13297": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "django__django-13297",
    "model_patch": "diff --git a/django/views/generic/base.py b/django/views/generic/base.py\nindex ea5baca08d..d3402959e2 100644\n--- a/django/views/generic/base.py\n+++ b/django/views/generic/base.py\n@@ -9,13 +9,12 @@ from django.http import (\n )\n from django.template.response import TemplateResponse\n from django.urls import reverse\n-from django.utils.decorators import classonlymethod\n from django.utils.deprecation import RemovedInDjango40Warning\n-from django.utils.functional import SimpleLazyObject\n+from django.utils.decorators import classonlymethod\n+from django.utils.functional import SimpleLazyObject, empty\n \n logger = logging.getLogger('django.request')\n \n-\n class ContextMixin:\n     \"\"\"\n     A default context mixin that passes the keyword arguments received by\n@@ -27,9 +26,26 @@ class ContextMixin:\n         kwargs.setdefault('view', self)\n         if self.extra_context is not None:\n             kwargs.update(self.extra_context)\n+        # Resolve any SimpleLazyObject values so consumers (e.g. ORM filters)\n+        # receive a sensible value rather than passing a LazyObject directly.\n+        for key, value in list(kwargs.items()):\n+            if isinstance(value, SimpleLazyObject):\n+                # If the proxy is already initialized, unwrap to the real object\n+                wrapped = getattr(value, '_wrapped', empty)\n+                if wrapped is not empty:\n+                    kwargs[key] = wrapped\n+                else:\n+                    # Not yet initialized: coerce to str for common URL kwargs\n+                    # (slugs) to avoid DB parameter binding errors; otherwise\n+                    # fall back to leaving the lazy object.\n+                    try:\n+                        kwargs[key] = str(value)\n+                    except Exception:\n+                        kwargs[key] = value\n         return kwargs\n \n \n+\n class View:\n     \"\"\"\n     Intentionally simple parent class for all views. Only implements"
  },
  "scikit-learn__scikit-learn-26323": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "scikit-learn__scikit-learn-26323",
    "model_patch": "diff --git a/sklearn/compose/_column_transformer.py b/sklearn/compose/_column_transformer.py\nindex 4eddd12b1..be91727c7 100644\n--- a/sklearn/compose/_column_transformer.py\n+++ b/sklearn/compose/_column_transformer.py\n@@ -229,7 +229,6 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n         \"verbose\": [\"verbose\"],\n         \"verbose_feature_names_out\": [\"boolean\"],\n     }\n-\n     def __init__(\n         self,\n         transformers,\n@@ -261,7 +260,6 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n             return [(name, trans) for name, trans, _ in self.transformers]\n         except (TypeError, ValueError):\n             return self.transformers\n-\n     @_transformers.setter\n     def _transformers(self, value):\n         try:\n@@ -303,6 +301,19 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n         for trans in transformers:\n             _safe_set_output(trans, transform=transform)\n \n+        # Also ensure the remainder estimator (if any) has its output configured.\n+        # `remainder` can be \"drop\", \"passthrough\" or an estimator instance.\n+        if self.remainder not in {\"passthrough\", \"drop\", None}:\n+            _safe_set_output(self.remainder, transform=transform)\n+\n+        return self\n+        # Also ensure the remainder estimator (if any) has its output configured.\n+        # `remainder` can be \"drop\", \"passthrough\" or an estimator instance.\n+        if self.remainder not in {\"passthrough\", \"drop\", None}:\n+            _safe_set_output(self.remainder, transform=transform)\n+\n+        return self\n+\n         return self\n \n     def get_params(self, deep=True):"
  },
  "psf__requests-1921": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "psf__requests-1921",
    "model_patch": "diff --git a/requests/sessions.py b/requests/sessions.py\nindex a023e4e..d9a7d6b 100644\n--- a/requests/sessions.py\n+++ b/requests/sessions.py\n@@ -20,7 +20,6 @@ from .hooks import default_hooks, dispatch_hook\n from .utils import to_key_val_list, default_headers, to_native_string\n from .exceptions import TooManyRedirects, InvalidSchema\n from .structures import CaseInsensitiveDict\n-\n from .adapters import HTTPAdapter\n \n from .utils import requote_uri, get_environ_proxies, get_netrc_auth\n@@ -29,15 +28,12 @@ from .status_codes import codes\n \n # formerly defined here, reexposed here for backward compatibility\n from .models import REDIRECT_STATI\n-\n-\n def merge_setting(request_setting, session_setting, dict_class=OrderedDict):\n     \"\"\"\n     Determines appropriate setting for a given request, taking into account the\n     explicit setting on that request, and the setting in the session. If a\n     setting is a dictionary, they will be merged together using `dict_class`\n     \"\"\"\n-\n     if session_setting is None:\n         return request_setting\n \n@@ -46,14 +42,33 @@ def merge_setting(request_setting, session_setting, dict_class=OrderedDict):\n \n     # Bypass if not a dictionary (e.g. verify)\n     if not (\n-            isinstance(session_setting, Mapping) and\n-            isinstance(request_setting, Mapping)\n+        isinstance(session_setting, Mapping) and\n+        isinstance(request_setting, Mapping)\n     ):\n         return request_setting\n-\n     merged_setting = dict_class(to_key_val_list(session_setting))\n     merged_setting.update(to_key_val_list(request_setting))\n \n+    # Remove keys that are set to None in the request.\n+    for (k, v) in request_setting.items():\n+        if v is None:\n+            try:\n+                del merged_setting[k]\n+            except KeyError:\n+                pass\n+\n+    # Remove keys that are set to None in the session if not overridden by\n+    # the request. This allows e.g. `session.headers['Accept-Encoding'] = None`\n+    # to remove a default header instead of sending the literal value \"None\".\n+    for (k, v) in session_setting.items():\n+        if v is None and k not in request_setting:\n+            try:\n+                del merged_setting[k]\n+            except KeyError:\n+                pass\n+\n+    return merged_setting\n+\n     # Remove keys that are set to None.\n     for (k, v) in request_setting.items():\n         if v is None:"
  },
  "sphinx-doc__sphinx-9658": {
    "model_name_or_path": "gpt-5-mini",
    "instance_id": "sphinx-doc__sphinx-9658",
    "model_patch": "diff --git a/sphinx/util/typing.py b/sphinx/util/typing.py\nindex 87707d48f..f82ea66f6 100644\n--- a/sphinx/util/typing.py\n+++ b/sphinx/util/typing.py\n@@ -40,7 +40,7 @@ except ImportError:\n \n if False:\n     # For type annotation\n-    from typing import Type  # NOQA # for python3.5.1\n+    pass  # noqa: duplicate import removed\n \n \n # builtin classes that have incorrect __module__\n@@ -115,6 +115,11 @@ def restify(cls: Optional[Type]) -> str:\n             return '...'\n         elif isinstance(cls, str):\n             return cls\n+        # If the object was created by autodoc.mock, it may expose a\n+        # '__display_name__' attribute like \"torch.nn.Module\". Prefer that\n+        # to avoid truncated names such as \"torch.nn.\" when rendering bases.\n+        elif getattr(cls, '__display_name__', None):\n+            return ':py:class:`%s`' % getattr(cls, '__display_name__')\n         elif cls in INVALID_BUILTIN_CLASSES:\n             return ':py:class:`%s`' % INVALID_BUILTIN_CLASSES[cls]\n         elif inspect.isNewType(cls):"
  }
}