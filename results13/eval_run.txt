<frozen runpy>:128: RuntimeWarning: 'swebench.harness.run_evaluation' found in sys.modules after import of package 'swebench.harness', but prior to execution of 'swebench.harness.run_evaluation'; this may result in unpredictable behaviour
Running 13 instances...
Evaluation:   0%|          | 0/13 [00:00<?, ?it/s, error=0, ✓=0, ✖=0]Evaluation:   0%|          | 0/13 [00:34<?, ?it/s, ✓=0, ✖=0, error=1]Evaluation:   8%|▊         | 1/13 [00:34<06:48, 34.04s/it, ✓=0, ✖=0, error=1]Evaluation:   8%|▊         | 1/13 [00:34<06:48, 34.04s/it, ✓=0, ✖=0, error=2]Evaluation:  15%|█▌        | 2/13 [00:39<06:14, 34.04s/it, ✓=0, ✖=1, error=2]Evaluation:  23%|██▎       | 3/13 [00:39<01:48, 10.83s/it, ✓=0, ✖=1, error=2]Evaluation:  23%|██▎       | 3/13 [00:44<01:48, 10.83s/it, ✓=0, ✖=2, error=2]Evaluation:  31%|███       | 4/13 [00:44<01:19,  8.87s/it, ✓=0, ✖=2, error=2]Evaluation:  31%|███       | 4/13 [00:46<01:19,  8.87s/it, ✓=0, ✖=3, error=2]Evaluation:  38%|███▊      | 5/13 [00:46<00:51,  6.44s/it, ✓=0, ✖=3, error=2]Evaluation:  38%|███▊      | 5/13 [00:53<00:51,  6.44s/it, ✓=0, ✖=4, error=2]Evaluation:  46%|████▌     | 6/13 [00:53<00:47,  6.79s/it, ✓=0, ✖=4, error=2]Evaluation:  46%|████▌     | 6/13 [00:53<00:47,  6.79s/it, ✓=0, ✖=5, error=2]Evaluation:  54%|█████▍    | 7/13 [00:55<00:40,  6.79s/it, ✓=0, ✖=6, error=2]Evaluation:  62%|██████▏   | 8/13 [00:55<00:19,  3.88s/it, ✓=0, ✖=6, error=2]Evaluation:  62%|██████▏   | 8/13 [01:02<00:19,  3.88s/it, ✓=0, ✖=7, error=2]Evaluation:  69%|██████▉   | 9/13 [01:02<00:19,  4.90s/it, ✓=0, ✖=7, error=2]Evaluation:  69%|██████▉   | 9/13 [01:13<00:19,  4.90s/it, ✓=0, ✖=8, error=2]Evaluation:  77%|███████▋  | 10/13 [01:13<00:18,  6.32s/it, ✓=0, ✖=8, error=2]Evaluation:  77%|███████▋  | 10/13 [01:16<00:18,  6.32s/it, ✓=0, ✖=9, error=2]Evaluation:  85%|████████▍ | 11/13 [01:16<00:11,  5.59s/it, ✓=0, ✖=9, error=2]Evaluation:  85%|████████▍ | 11/13 [01:17<00:11,  5.59s/it, ✓=0, ✖=10, error=2]Evaluation:  92%|█████████▏| 12/13 [01:17<00:04,  4.13s/it, ✓=0, ✖=10, error=2]Evaluation:  92%|█████████▏| 12/13 [01:22<00:04,  4.13s/it, ✓=0, ✖=11, error=2]Evaluation: 100%|██████████| 13/13 [01:22<00:00,  4.44s/it, ✓=0, ✖=11, error=2]Evaluation: 100%|██████████| 13/13 [01:22<00:00,  6.35s/it, ✓=0, ✖=11, error=2]
django__django-14053: >>>>> Patch Apply Failed:
patching file django-hashedfiles-fix-1.11.patch
patch unexpectedly ends in middle of line
patch: **** malformed patch at line 146:  


Check (logs/run_evaluation/my_evaluation_run_13/gpt-5-mini/django__django-14053/run_instance.log) for more information.
django__django-14011: >>>>> Patch Apply Failed:
patching file tests/utils/live_server_fix.py
patch unexpectedly ends in middle of line
patch: **** malformed patch at line 40:  


Check (logs/run_evaluation/my_evaluation_run_13/gpt-5-mini/django__django-14011/run_instance.log) for more information.
All instances run.
Cleaning cached images...
Removed 0 images.
Total instances: 20
Instances submitted: 13
Instances completed: 11
Instances incomplete: 7
Instances resolved: 0
Instances unresolved: 11
Instances with empty patches: 0
Instances with errors: 2
Unstopped containers: 0
Unremoved images: 0
Report written to gpt-5-mini.my_evaluation_run_13.json
<frozen runpy>:128: RuntimeWarning: 'swebench.harness.run_evaluation' found in sys.modules after import of package 'swebench.harness', but prior to execution of 'swebench.harness.run_evaluation'; this may result in unpredictable behaviour
11 instances already run, skipping...
Running 8 instances...
Evaluation:   0%|          | 0/8 [00:00<?, ?it/s, error=0, ✓=0, ✖=0]Evaluation:   0%|          | 0/8 [00:31<?, ?it/s, ✓=0, ✖=0, error=1]Evaluation:  12%|█▎        | 1/8 [00:31<03:38, 31.24s/it, ✓=0, ✖=0, error=1]Evaluation:  12%|█▎        | 1/8 [00:31<03:38, 31.24s/it, ✓=0, ✖=0, error=2]Evaluation:  25%|██▌       | 2/8 [00:31<03:07, 31.24s/it, ✓=0, ✖=0, error=3]Evaluation:  38%|███▊      | 3/8 [00:32<02:36, 31.24s/it, ✓=0, ✖=0, error=4]Evaluation:  50%|█████     | 4/8 [00:32<00:24,  6.18s/it, ✓=0, ✖=0, error=4]Evaluation:  50%|█████     | 4/8 [00:32<00:24,  6.18s/it, ✓=0, ✖=0, error=5]Evaluation:  62%|██████▎   | 5/8 [00:32<00:13,  4.49s/it, ✓=0, ✖=0, error=5]Evaluation:  62%|██████▎   | 5/8 [00:33<00:13,  4.49s/it, ✓=0, ✖=0, error=6]Evaluation:  75%|███████▌  | 6/8 [00:33<00:06,  3.40s/it, ✓=0, ✖=0, error=6]Evaluation:  75%|███████▌  | 6/8 [00:33<00:06,  3.40s/it, ✓=0, ✖=0, error=7]Evaluation:  88%|████████▊ | 7/8 [00:42<00:03,  3.40s/it, ✓=0, ✖=1, error=7]Evaluation: 100%|██████████| 8/8 [00:42<00:00,  4.04s/it, ✓=0, ✖=1, error=7]Evaluation: 100%|██████████| 8/8 [00:42<00:00,  5.33s/it, ✓=0, ✖=1, error=7]
django__django-13810: >>>>> Patch Apply Failed:
patch unexpectedly ends in middle of line
patch: **** Only garbage was found in the patch input.

Check (logs/run_evaluation/my_evaluation_run_13/gpt-5-mini/django__django-13810/run_instance.log) for more information.
psf__requests-1921: >>>>> Patch Apply Failed:
patch unexpectedly ends in middle of line
patch: **** Only garbage was found in the patch input.

Check (logs/run_evaluation/my_evaluation_run_13/gpt-5-mini/psf__requests-1921/run_instance.log) for more information.
django__django-13297: >>>>> Patch Apply Failed:
patch unexpectedly ends in middle of line
patch: **** Only garbage was found in the patch input.

Check (logs/run_evaluation/my_evaluation_run_13/gpt-5-mini/django__django-13297/run_instance.log) for more information.
pytest-dev__pytest-7490: >>>>> Patch Apply Failed:
patch unexpectedly ends in middle of line
patch: **** Only garbage was found in the patch input.

Check (logs/run_evaluation/my_evaluation_run_13/gpt-5-mini/pytest-dev__pytest-7490/run_instance.log) for more information.
sympy__sympy-17655: >>>>> Patch Apply Failed:
patch unexpectedly ends in middle of line
patch: **** Only garbage was found in the patch input.

Check (logs/run_evaluation/my_evaluation_run_13/gpt-5-mini/sympy__sympy-17655/run_instance.log) for more information.
django__django-14053: >>>>> Patch Apply Failed:
patching file django-hashedfiles-fix-1.11.patch
patch unexpectedly ends in middle of line
patch: **** malformed patch at line 146:  


Check (logs/run_evaluation/my_evaluation_run_13/gpt-5-mini/django__django-14053/run_instance.log) for more information.
django__django-14011: >>>>> Patch Apply Failed:
patching file tests/utils/live_server_fix.py
patch unexpectedly ends in middle of line
patch: **** malformed patch at line 40:  


Check (logs/run_evaluation/my_evaluation_run_13/gpt-5-mini/django__django-14011/run_instance.log) for more information.
All instances run.
Cleaning cached images...
Removed 0 images.
Total instances: 20
Instances submitted: 19
Instances completed: 12
Instances incomplete: 1
Instances resolved: 0
Instances unresolved: 12
Instances with empty patches: 0
Instances with errors: 7
Unstopped containers: 0
Unremoved images: 0
Report written to gpt-5-mini.my_evaluation_run_13.json
